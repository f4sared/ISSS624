[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "hands_on_ex/ex_1/ex_1.html",
    "href": "hands_on_ex/ex_1/ex_1.html",
    "title": "Hand on ex 1 - Chap 1 Geodata wrangling",
    "section": "",
    "text": "Step 1: Load packages\n\npacman::p_load(sf,tidyverse)\n\n\n\nStep 2: Import Geo spatial Data\nImport shapefile into R as a polygon feature dataframe :\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\f4sared\\ISSS624\\hands_on_ex\\ex_1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nImport shapefile into R as a line feature dataframe :\n\ncyclingpath <- st_read(dsn = \"data/geospatial\", layer = \"CyclingPath\")\n\nReading layer `CyclingPath' from data source \n  `D:\\f4sared\\ISSS624\\hands_on_ex\\ex_1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 1625 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 12711.19 ymin: 28711.33 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nImport KML into R as a Point format:\n\npreschool <- st_read(\"data/geospatial/pre-schools-location-kml.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\f4sared\\ISSS624\\hands_on_ex\\ex_1\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nStep 3: Check content of the data frame\nThis function provides a simple overview of the dataframe:\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nThis function gives a detailed breakdown of the columns and the data within the column:\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nHere we will take a detailed look at the first 5 rows of the dataset:\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\nStep 4: Plotting the data\nBelow command will plot a map for each of the columns:\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nIn order to plot the whole map only, we use the following:\n\nplot(st_geometry(mpsz))\n\n\n\n\nAlso we can choose to plot based on a specific column or “feature”:\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\nNote***\nplot() is only meant for a quick look, for cartographic quality, we should use other packages such as tamp.\n\n\nStep 5: Working with projections\nProjection is important because we want to use geospatial data that are of similar coordinate system.\nThe following code will show how to project from one coordinate system to another coordinate system.\nCheck the coordinate reference system as follow:\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNote***\nEPSG stands for “European Petroleum Survey Group”\n\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nQuestion to self: Why is there a warning above ?\nBelow we will set the correct EPSG code to 3414:\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNext we will convert the projection of preschool from wsg84 to svy21:\nWe will take a loot at the CRS o the preschool:\n\nst_crs(preschool)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nNow we will convert:\n\npreschool3414 <- st_transform(preschool, crs=3414)\n\nWe will now take a look at the converted geometry dataframe:\n\nst_geometry(preschool3414)\n\nGeometry set for 1359 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11203.01 ymin: 25667.6 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (19997.26 32333.17 0)\n\n\nPOINT Z (19126.75 33114.35 0)\n\n\nPOINT Z (20345.12 31934.56 0)\n\n\nPOINT Z (20400.31 31952.36 0)\n\n\nPOINT Z (19810.78 33140.31 0)\n\n\nWe can see that after conversion, the values of the geometry are now different:\n\nglimpse(preschool)\n\nRows: 1,359\nColumns: 3\n$ Name        <chr> \"kml_1\", \"kml_2\", \"kml_3\", \"kml_4\", \"kml_5\", \"kml_6\", \"kml…\n$ Description <chr> \"<center><table><tr><th colspan='2' align='center'><em>Att…\n$ geometry    <POINT [°]> POINT Z (103.7614 1.308683 0), POINT Z (103.7536 1.3…\n\n\n\nglimpse(preschool3414)\n\nRows: 1,359\nColumns: 3\n$ Name        <chr> \"kml_1\", \"kml_2\", \"kml_3\", \"kml_4\", \"kml_5\", \"kml_6\", \"kml…\n$ Description <chr> \"<center><table><tr><th colspan='2' align='center'><em>Att…\n$ geometry    <POINT [m]> POINT Z (19997.26 32333.17 0), POINT Z (19126.75 331…\n\n\nJust for interest, we will plot the preschool data:\n\nplot(preschool3414)\n\n\n\n\n\n\nStep 6: Importing and Converting Aspatial Data\nWe first import the csv file:\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNext, we check if the files has been imported correctly:\n**Here, we will assume that the coordinate data is in the degree format & in wgs84 system\n**WGS stands for “World Geodetic System”\n\nlist(listings)\n\n[[1]]\n# A tibble: 4,252 × 16\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   178\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 5 275343 Conveni… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    52\n 6 275344 15 mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    40\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    72\n 8 301247 Nice ro… 1552002 Rahul   Centra… Geylang    1.32    104. Privat…    41\n 9 324945 20 Mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n10 330089 Accomo@… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n# … with 4,242 more rows, 6 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>, and\n#   abbreviated variable names ¹​host_name, ²​neighbourhood_group,\n#   ³​neighbourhood, ⁴​latitude, ⁵​longitude, ⁶​room_type\n\n\nNext, we will convert the imported csv file to a dataframe:\nWe will first convert listings into a dataframe, then convert/project accordingly.\n\nlistings_sf <- st_as_sf(listings, coords = c(\"longitude\",\"latitude\"), crs=4326) %>% st_transform(crs=3414)\n\nNext we will take a look at the features and columns:\n\nglimpse(listings_sf)\n\nRows: 4,252\nColumns: 15\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9), POINT (…\n\n\n\n\nStep 7: Geoprocessing with sf package\nIn this section, we will learn to use geo processing functions, buffering and point in polygon count.\n\nBuffering\n\nbuffer_cycling <- st_buffer(cyclingpath, dist = 5, nQuadSegs = 30)\n\nJust for interest, we will plot the buffered cycling path:\n\nplot(buffer_cycling)\n\n\n\n\nNext we calculate the area:\nWe will add this back to the main dataframe buffer_cycling\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nNext, we will get the sum:\n\nsum(buffer_cycling$AREA)\n\n773143.9 [m^2]\n\n\nWe will also take a look at the newly added column “AREA”\n\nglimpse(buffer_cycling)\n\nRows: 1,625\nColumns: 4\n$ CYL_PATH_C <chr> \"SBWG\", \"SBWG\", \"SBWG\", \"SBWG\", \"SBWG\", \"SBWG\", \"SBWG\", \"SB…\n$ CYL_PATH_1 <chr> \"Sembawang\", \"Sembawang\", \"Sembawang\", \"Sembawang\", \"Sembaw…\n$ geometry   <POLYGON [m]> POLYGON ((26829 47350.2, 26..., POLYGON ((26762.25 …\n$ AREA       [m^2] 547.08438 [m^2], 681.87931 [m^2], 432.75754 [m^2], 404.6815…\n\n\n\n\nPoint in polygon count\nWe first check the dataframe:\nOur dataframe consists of 323 areas\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nPerform first intersection:\nThis will produce a dataframe with 323 rows. In each of the rows, we will get the index of the preschool whose coordinates fall into our polygon area.\n\nintersect <- st_intersects(mpsz3414, preschool3414)\n\nStore the counts into the main dataframe\n\nmpsz3414$`PreSch Count`<- lengths(intersect)\n\nCheck the summary statistics:\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   4.207   6.000  37.000 \n\n\nNext, we will list the top 3 planning zone with most number of preschools using the function below:\n\ntop_n(mpsz3414, 3, `PreSch Count`)\n\nSimple feature collection with 3 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 23449.05 ymin: 35966 xmax: 42940.57 ymax: 47996.47\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO            SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N\n1      189          2        TAMPINES EAST    TMSZ02      N   TAMPINES\n2      272          3 SENGKANG TOWN CENTRE    SESZ03      N   SENGKANG\n3      290          3       WOODLANDS EAST    WDSZ03      N  WOODLANDS\n  PLN_AREA_C          REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         TM       EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55\n2         SE NORTH-EAST REGION      NER 5A2D0E9E6B285069 2014-12-05 35163.81\n3         WD      NORTH REGION       NR C90769E43EE6B0F2 2014-12-05 24506.64\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1 37392.39  10180.624    4339824 MULTIPOLYGON (((42196.76 38...           33\n2 41501.14   5216.401    1455508 MULTIPOLYGON (((35615.75 40...           25\n3 46991.63   6603.608    2553464 MULTIPOLYGON (((24786.75 46...           37\n\n\nCalculate and save the area:\n\nmpsz3414$Area <- mpsz3414 %>% st_area()\n\n\ntesting <- mpsz3414 %>% st_area()\nhead(testing, n=20)\n\nUnits: [m^2]\n [1]  1630379.3   559816.2   160807.5   595428.9   387429.4  1030378.8\n [7]   551732.0   290184.7  1084792.3   631644.3  1826848.6   293706.4\n[13]  1844060.7   392563.3   506589.0 36707720.9  4207271.1  4963787.1\n[19]  2206319.5  4919132.4\n\n\nUse the mutate function:\n\nmpsz3414 <- mpsz3414 %>% mutate(`PreSch Density` = (`PreSch Count`/Area)*1000000)\n\n\nFor fun and learning, we will try to plot a specific area such as queens town\n\nspecific_plot <- mpsz3414 %>% filter(PLN_AREA_C == \"MS\")\nplot(specific_plot[\"PLN_AREA_N\"])\n\n\n\nplot(st_geometry(specific_plot))\n\n\n\n\n\n\n\n\nStep 8: EDA Exploratory Data Analysis\nCreate a histogram to show the preschool density:\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nTo get better plot, we will use ggplot:\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`), y= as.numeric(`PreSch Count`)))+ geom_point()+\n    labs(title = \"Scatter Plot\",\n       subtitle= \"My Plot\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Preschool Counts\")\n\n\n\n\n```"
  },
  {
    "objectID": "hands_on_ex/ex_1/ex_1_2.html#step-1-import-packages",
    "href": "hands_on_ex/ex_1/ex_1_2.html#step-1-import-packages",
    "title": "Hand on ex 1 - Chap 2 Choropleth Mapping with R",
    "section": "Step 1: Import Packages",
    "text": "Step 1: Import Packages\nAs usual, we first import all the packages:\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "hands_on_ex/ex_1/ex_1_2.html#step-2-import-the-data",
    "href": "hands_on_ex/ex_1/ex_1_2.html#step-2-import-the-data",
    "title": "Hand on ex 1 - Chap 2 Choropleth Mapping with R",
    "section": "Step 2: Import the data",
    "text": "Step 2: Import the data\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\f4sared\\ISSS624\\hands_on_ex\\ex_1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the contents:\n\nhead(mpsz, n=1)\n\nSimple feature collection with 1 feature and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 30794.28 ymin: 28369.47 xmax: 32362.39 ymax: 30140.01\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO    SUBZONE_N SUBZONE_C CA_IND   PLN_AREA_N PLN_AREA_C\n1        1          1 MARINA SOUTH    MSSZ01      Y MARINA SOUTH         MS\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84 29220.19\n  SHAPE_Leng SHAPE_Area                       geometry\n1   5267.381    1630379 MULTIPOLYGON (((31495.56 30...\n\n\nNext, we import the csv attribute data into R:\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nData Wrangling:\nBelow we will prepare the new dataframe.\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nConvert some data into upper case:\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\nNext we will join the tables together:\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020, by = c(\"SUBZONE_N\" = \"SZ\"))\n\nSave the table:\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "hands_on_ex/ex_1/ex_1_2.html#step-3-plotting-with-various-tools",
    "href": "hands_on_ex/ex_1/ex_1_2.html#step-3-plotting-with-various-tools",
    "title": "Hand on ex 1 - Chap 2 Choropleth Mapping with R",
    "section": "Step 3: Plotting with various tools",
    "text": "Step 3: Plotting with various tools\n\nUsing qtm()\nMake our first plot based on the column “Dependency”.\nHowever, a disadvantage of qtm() is that i makes individual layers harder to control.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\n\n\nUsing tm_shape()\nWith the disadvantage of the qtm(), we will next try tm_shape() to get better professional quality:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\nDrawing a base map\nUisng tm_shape() as the basic building block.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\nWe can also draw according to each column feature with tm_polygon:\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\ntm_polygon is a wrapper of tm_fill, just that it is missing the borders:\n\ntm_shape(mpsz_pop2020)+tm_fill(\"DEPENDENCY\")\n\n\n\n\nso now, we will add the borders in:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\nData Classification Methods: Using Different Styles\nNote: tmap has a total of ten data classification methods !\nHere we will use classification quantile of 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nAnother option is to make each bin range equal as follow:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nDIY_1: Here we try out some different styles:\n\nA <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"DEPENDENCY\", \n              style = \"jenks\", \n              palette = \"Blues\")+\n    tm_layout(main.title = \"jenks\")\n\nB <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"DEPENDENCY\", \n              style = \"quantile\", \n              palette = \"Blues\")+\n  tm_layout(main.title = \"quantile\")\n\nC <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"DEPENDENCY\", \n              style = \"sd\", \n              palette = \"Blues\")+\n  tm_layout(main.title = \"sd\")\n\nD <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"DEPENDENCY\", \n              style = \"equal\", \n              palette = \"Blues\")+\n  tm_layout(main.title = \"equal\")\n\ntmap_arrange(A, B, C, D, asp=2, ncol=2)\n\n\n\n\nThe three basic methods are quantile, sd (standard deviation) and equal. One of the most informative plot would be the “quantile” classification style. As shown above, this styles provides the most distinct visual classification that is more informative.\nThe “equal” style provides the least information since each bin is separated into equal range.\nUsing the style “quantile” allows us to take into account the distribution of the data.\nAs shown below, majority of the values are below 5.\n\nggplot(data=mpsz_pop2020, \n       aes(x= as.numeric(`DEPENDENCY`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Distribution of DEPENDENCY\",\n      x = \"DEPENDENCY\",\n      y = \"Frequency\")\n\nWarning: Removed 92 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\nDIY_2: Data Classification Methods: Using different number of classes\nFor this section, we will use jenks !\nwhere n = 2, 6, 10 , 20\n\nA <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"DEPENDENCY\", \n              n=2,\n              style = \"jenks\", \n              palette = \"Blues\")+\n    tm_layout(main.title = \"n=2\")\n\nB <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"DEPENDENCY\", \n              n=6,\n              style = \"jenks\", \n              palette = \"Blues\")+\n  tm_layout(main.title = \"n=6\")\n\nC <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"DEPENDENCY\", \n              n=10,\n              style = \"jenks\", \n              palette = \"Blues\")+\n  tm_layout(main.title = \"n=10\")\n\nD <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"DEPENDENCY\", \n              n=20,\n              style = \"jenks\", \n              palette = \"Blues\")+\n  tm_layout(main.title = \"n=20\")\n\ntmap_arrange(A, B, C, D, asp=2, ncol=2)\n\n\n\n\nFrom what we can see above, as the number of classes get bigger and bigger, more and more details are revealed ! Previous regions with similar colors are now further differentiated with better gradient spread."
  },
  {
    "objectID": "hands_on_ex/ex_1/ex_1_2.html#step-4-color-scheme",
    "href": "hands_on_ex/ex_1/ex_1_2.html#step-4-color-scheme",
    "title": "Hand on ex 1 - Chap 2 Choropleth Mapping with R",
    "section": "Step 4: Color scheme",
    "text": "Step 4: Color scheme\nHere, we will assign a new color !\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can also reverse the color shading as follow:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "hands_on_ex/ex_1/ex_1_2.html#step-5-map-layouts-and-styles",
    "href": "hands_on_ex/ex_1/ex_1_2.html#step-5-map-layouts-and-styles",
    "title": "Hand on ex 1 - Chap 2 Choropleth Mapping with R",
    "section": "Step 5: Map Layouts and styles",
    "text": "Step 5: Map Layouts and styles\nApparently we can add even more customization options to our map plots !\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can even change the map style and appearance !\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\""
  },
  {
    "objectID": "hands_on_ex/ex_1/ex_1_2.html#step-6-add-cartographic-furniture-to-the-map",
    "href": "hands_on_ex/ex_1/ex_1_2.html#step-6-add-cartographic-furniture-to-the-map",
    "title": "Hand on ex 1 - Chap 2 Choropleth Mapping with R",
    "section": "Step 6: Add Cartographic Furniture to the map",
    "text": "Step 6: Add Cartographic Furniture to the map\nWe can further add more useful features to the generated map\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "hands_on_ex/ex_1/ex_1_2.html#step-7-multiple-map",
    "href": "hands_on_ex/ex_1/ex_1_2.html#step-7-multiple-map",
    "title": "Hand on ex 1 - Chap 2 Choropleth Mapping with R",
    "section": "Step 7: Multiple map",
    "text": "Step 7: Multiple map\nHere we will attempt to plot multiple plots together:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nWe can even mix and match 2 different maps with different styles and fearures\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nWe can further make facet plots of different regions:\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\nCreate multiple standalone maps:\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\nSelect areas that meets criterion:\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#minor-notes",
    "href": "hands_on_ex/ex_2/ex_2.html#minor-notes",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Minor notes:",
    "text": "Minor notes:\nUseful Links:\n\nhttps://bookdown.org/nicohahn/making_maps_with_r5/docs/tmap.html\nhttps://www.rdocumentation.org/packages/classInt/versions/0.4-8/topics/classIntervals\n\nstyle = pretty: Rounds interval boundaries to whole numbers. Default setting.\nstyle = equal: Splits the variable into intervals of equal length. Should only be used if the variable follows an uniform distribution.\nstyle = quantile: Splits the variable into quantiles. Consequently there are the same number of observations in each interval.\nstyle = jenks: Identifies groups with similar values and maximizes the difference between them.\nstyle = cont: Displays many colors over a continuous palette.\nstyle = cat: Colors each category individually for categorical data."
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#morans-i-test",
    "href": "hands_on_ex/ex_2/ex_2.html#morans-i-test",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran’s I Test:",
    "text": "Moran’s I Test:\n**moran.test() belongs to spdep\n**Are we testing against randomization or normality ?\n\nmoran.test(hunan$GDPPC, listw=rswm_q, zero.policy = TRUE, na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nUseful Link:\n\nhttps://bookdown.org/lexcomber/brunsdoncomber2e/morans-i-an-index-of-autocorrelation.html >> Moran’ I eigen value code\nhttps://www.youtube.com/watch?v=_FtR878eic4 >> Moran’s I explained\nhttps://www.youtube.com/watch?v=MPcNT0KUym0 >> Moran’s I ranging with eigen values\n\nWhen Moran’s I is 0, it means the points are distributed randomly across the space.\nWhen Moran’s I is 1, it means that similar values tend to cluster.\nOur P-value is 0.000001, which is really significant.\nWe calculate the Moran’s I eigen value range:\n**Note: The Moran’s I range is dependent on the inputs !\n\nmoran.range <- function(lw) {\n  wmat <- listw2mat(lw)\n  return(range(eigen((wmat + t(wmat))/2)$values))\n}\nmoran.range(rswm_q)\n\n[1] -0.733384  1.032489\n\n\nOur Moran’s estimate is 0.300 which is closer to 1.032 than -0.733."
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#monte-carlo-morans-i",
    "href": "hands_on_ex/ex_2/ex_2.html#monte-carlo-morans-i",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Monte Carlo Moran’s I:",
    "text": "Monte Carlo Moran’s I:\n\nset.seed(1234)\nbperm <- moran.mc(hunan$GDPPC, listw = rswm_q, nsim = 999, zero.policy = TRUE, na.action = na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nHere we observe a similar Moran’s I value above.\nHowever, the p-value is now less significant as compared to the first test.\n\nPlot the Monte Carlo Moran’s I:\n**Why Monte Carlo ?\n**Monte Carlo is a statistical method that generates multiple datasets using random sampling.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\nPlot using ggplot:\nUseful Links:\n\nhttps://sparkbyexamples.com/r-programming/convert-list-to-r-dataframe/\nhttps://www.projectpro.io/recipes/change-column-headers-of-dataframe-r#:~:text=How%20to%20change%20column%20headers%20of%20a%20data%2Dframe%20in,can%20be%20changed%20at%20once.\n\nCreate a dataframe:\n\nxx <- data.frame(bperm$res)\n\n\ncolnames(xx)[1]  <- \"res\" \n\nPlot using ggplot:\n\nggplot(data=xx, aes(x= as.numeric(`res`)))+\n    geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n    labs(title = \"Distribution of DEPENDENCY\",\n      x = \"Moran's I\",\n      y = \"Frequency\")"
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#gearys-c-test",
    "href": "hands_on_ex/ex_2/ex_2.html#gearys-c-test",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Geary’s C test:",
    "text": "Geary’s C test:\n\ngeary.test(hunan$GDPPC, listw = rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nHere we see a small p-value of 0.0001 which makes it statistically significant.\nFor Geary’s C, 1 means pure randomization. < 1 means clustering. > 1 means dispersed.\nOur value is 0.69, which tends towards some clustering."
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#monte-carlo-gearys-c",
    "href": "hands_on_ex/ex_2/ex_2.html#monte-carlo-gearys-c",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Monte Carlo Geary’s C:",
    "text": "Monte Carlo Geary’s C:\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nHere, we see a higher P-Value which is less statistically significant.\nThe statistic value remains to be similar.\n\nPlot the Monte Carlo:\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#morans-i",
    "href": "hands_on_ex/ex_2/ex_2.html#morans-i",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran’s I",
    "text": "Moran’s I\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAs we increase the order of lag, the Moran’s I value decreases. From a lag value of 3 onwards, we observe less indication of clustering."
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#gearys-c",
    "href": "hands_on_ex/ex_2/ex_2.html#gearys-c",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Geary’s C",
    "text": "Geary’s C\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAs we increase the lag, the C value increases, which shows less clustering. From a lag of 3 onwards, we observe less clustering."
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#plot-morans-scatterplot",
    "href": "hands_on_ex/ex_2/ex_2.html#plot-morans-scatterplot",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Plot Moran’s scatterplot:",
    "text": "Plot Moran’s scatterplot:\nUseful link:\n\nhttps://www.youtube.com/watch?v=G_l0xkuQUSs\n\nMoran’s plot is interesting because it plots the variable under study as the X-Axis, while the lagged variable will be plotted as the Y-Axis. The lagged variable in our cases is the average value of the neighbor surrounding our individual polygon. If the average neighbor value is close to the own value, the point will then fall on a straight line. The straight line is our Moran’s I.\nTake note that the top left quadrant and the bottom right signals to us that the variable of a polygon is not similar to the values the neighbor.\n\nnci <- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")"
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#plot-morans-scatterplot-with-standardized-variable",
    "href": "hands_on_ex/ex_2/ex_2.html#plot-morans-scatterplot-with-standardized-variable",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Plot Moran’s scatterplot with standardized variable:",
    "text": "Plot Moran’s scatterplot with standardized variable:\nWhy do we need to do this ? What is the use ?\n\nhunan$Z.GDPPC <- scale(hunan$GDPPC) %>% as.vector \n\n\nnci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#preparing-lisa-map-classes",
    "href": "hands_on_ex/ex_2/ex_2.html#preparing-lisa-map-classes",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Preparing LISA map classes:",
    "text": "Preparing LISA map classes:\nWe create a empty vector based on the number of rows in the localMI:\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\n\nCenter the variable of interest around the mean:\n\nDV <- hunan$GDPPC - mean(hunan$GDPPC)  \n\nCenter the local Moran’s I around the mean:\n\nC_mI <- localMI[,1] - mean(localMI[,1])    \n\nSet the statistical significance level for the local Moran:\n\nsignif <- 0.05       \n\nPerform the first filter:\n**Note the order here is questionable, need to clarify further\n\nquadrant[DV >0 & C_mI>0] <- 4      \nquadrant[DV <0 & C_mI<0] <- 1      \nquadrant[DV <0 & C_mI>0] <- 2\nquadrant[DV >0 & C_mI<0] <- 3\n\nPlace non-significant Moran in category 0:\n\nquadrant[localMI[,5]>signif] <- 0"
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#plotting-the-lisa-map",
    "href": "hands_on_ex/ex_2/ex_2.html#plotting-the-lisa-map",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Plotting the LISA Map:",
    "text": "Plotting the LISA Map:\nInterpreting the LISA Map:\n\nhttps://www.e-education.psu.edu/geog586/node/673\n\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)"
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#deriving-spatial-weight-matrix",
    "href": "hands_on_ex/ex_2/ex_2.html#deriving-spatial-weight-matrix",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Deriving Spatial Weight Matrix",
    "text": "Deriving Spatial Weight Matrix\n\nDistance Based Matrix\nGet Centroid:\nValue 1:\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nValue 2:\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nBind the coordinate into 1 object:\n\ncoords <- cbind(longitude, latitude)\n\nDetermine the cutoff distance using the k nearest neighbors:\n\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nCompute the fixed distance weight matrix:\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nConvert into spatial weights object\n\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\nAdaptive distance weight Matrix\nHere we will enforce the condition that the number of neighbor for each polygon has to be 8:\n\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nConvert to spatial weight object:\n\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#computing-gi-statistics",
    "href": "hands_on_ex/ex_2/ex_2.html#computing-gi-statistics",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Gi Statistics",
    "text": "Computing Gi Statistics\n\nUsing Fixed Distance\n\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nJoin the data to dataframe:\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nWe observe high level of significance of spatial concentration in the most central area highlighted by the red zone. However, we observe a steep change in the significance gradient of the local Gi score.\n\n\nUsing adaptive distance:\nCompute using adaptive weights:\n\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nAgain, we observe a high level of spatial concentration significance in the areas highlighted in red. However, this time, we get a larger patch and a more gentle gradient distribution."
  },
  {
    "objectID": "hands_on_ex/ex_2/ex_2.html#thoughts",
    "href": "hands_on_ex/ex_2/ex_2.html#thoughts",
    "title": "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation",
    "section": "Thoughts:",
    "text": "Thoughts:\nSo apparently using different measures of distance weight matrix can have quite a big effect on the interpretation of the hotspot analysis. The question then lies in the motivation for selecting the different kinds of spatial weight matrix since they can produce different results."
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#prepare-the-data",
    "href": "hands_on_ex/ex_3/ex_3.html#prepare-the-data",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Prepare the data",
    "text": "Prepare the data\nWe select the clustering variables now. Notice we use the st_set_geometry(NULL) to exclude the geometry column:\n\ncluster_vars <- shan_sf %>%\n  st_set_geometry(NULL) %>%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNext, we will change the names of the row:\n\nrow.names(cluster_vars) <- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNext we will delete the TS.x row:\n\nshan_ict <- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#data-standardization",
    "href": "hands_on_ex/ex_3/ex_3.html#data-standardization",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Data Standardization",
    "text": "Data Standardization\nSince different variables are used, their range is different. Thus we need to standardize them.\n\nMin Max\nWe do min-max 0-1 as follow:\n\nshan_ict.std <- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\n\nZ-Score\nNext, we perform Z-score standardization as follow:\n\nshan_ict.z <- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nAfter doing this step, the mean and std dev are now 0 and 1 respectively.\n\n\n\nVisualize the standardized variables\nNext we visualize the variables:\n\nr <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nshan_ict_s_df <- as.data.frame(shan_ict.std)\ns <- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df <- as.data.frame(shan_ict.z)\nz <- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#compute-proximity-matrix",
    "href": "hands_on_ex/ex_3/ex_3.html#compute-proximity-matrix",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Compute Proximity Matrix",
    "text": "Compute Proximity Matrix\nWe will use dist() of R to compute the proximity matrix:\n\nproxmat <- dist(shan_ict, method = 'euclidean')"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#compute-hierarchical-clustering",
    "href": "hands_on_ex/ex_3/ex_3.html#compute-hierarchical-clustering",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Compute Hierarchical Clustering",
    "text": "Compute Hierarchical Clustering\nUsing hclust() of R stats, we will input the proximity matrix. The putout is a class of hclust that describes a tree that is produced:\n\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the result as follow:\n\nplot(hclust_ward, cex = 0.8)"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#determine-optimal-clustering-algorithm",
    "href": "hands_on_ex/ex_3/ex_3.html#determine-optimal-clustering-algorithm",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Determine optimal clustering algorithm",
    "text": "Determine optimal clustering algorithm\nSince there are many algorithms, it makes sense to try them all. We will get the agglomeration coefficient which measures the amount of clustering structure found.\nFirst we will make a simple list:\n\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nWe will use the agnes() function of cluster package as follow:\n\nac <- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#determine-optimal-clusters",
    "href": "hands_on_ex/ex_3/ex_3.html#determine-optimal-clusters",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Determine optimal clusters",
    "text": "Determine optimal clusters\nGap statistic compares the intra-cluster variation for different numbers of clusters k.\nWe will compute the gap statistic using clusGap() of cluster package:\n“hcut” is from factoextra package.\n\nset.seed(12345)\ngap_stat <- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nNow, using fviz_gap_stat() of factoextra package to find the optimal cluster:\n\nfviz_gap_stat(gap_stat)"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#interpreting-the-dendrograms",
    "href": "hands_on_ex/ex_3/ex_3.html#interpreting-the-dendrograms",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Interpreting the dendrograms",
    "text": "Interpreting the dendrograms\nNext we will redraw the dendrograms with the optimal number of clusters. This is done using rect.hclust() of R:\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\nQuestion: How does the algorithm know which cluster to break up ?"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#visually-driven-hierarchical-clustering-analysis",
    "href": "hands_on_ex/ex_3/ex_3.html#visually-driven-hierarchical-clustering-analysis",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Visually driven hierarchical clustering analysis:",
    "text": "Visually driven hierarchical clustering analysis:\nUsing the function heatmaply() we will build a cluster heat map.\nFirst we need to transform the dataframe into a matrix in order to be able to plot:\n\nshan_ict_mat <- data.matrix(shan_ict)\n\nNext we will use function heatmaply() of heatmaply to plot:\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\nQuestion:\nWhy do you show all 5 variables ? Is the segmentation based on all 5 variables ?"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#mapping-the-cluster-formed",
    "href": "hands_on_ex/ex_3/ex_3.html#mapping-the-cluster-formed",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Mapping the cluster formed",
    "text": "Mapping the cluster formed\nWe will use cutree() of R to prune the tree to that we have 6 cluster:\n\ngroups <- as.factor(cutree(hclust_ward, k=6))\n\nNext, we will convert the groups into a matrix before combining it to shan_sf:\n\nshan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nFinally, we will plot the outcome:\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nAs shown from the output above, we see that all our cluster appear to be fragmented. This is because a non-spatial method is being used."
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#convert-to-spatial-polygons-dataframe",
    "href": "hands_on_ex/ex_3/ex_3.html#convert-to-spatial-polygons-dataframe",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Convert to spatial polygons dataframe",
    "text": "Convert to spatial polygons dataframe\nFirst we need to convert the shan_sf from sf object to the sp object.\nWe do this via the as_spatial() of sf package:\n\nshan_sp <- as_Spatial(shan_sf)"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#compute-the-neighbor-list",
    "href": "hands_on_ex/ex_3/ex_3.html#compute-the-neighbor-list",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Compute the neighbor list",
    "text": "Compute the neighbor list\nUsing poly2nd() of spdep, we will then compute the neighbor list:\n\nshan.nb <- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nQuestion: How is the neighbor computed here ? Queen ???"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#plot-the-neighbors-relationship-on-a-map",
    "href": "hands_on_ex/ex_3/ex_3.html#plot-the-neighbors-relationship-on-a-map",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Plot the neighbors relationship on a map",
    "text": "Plot the neighbors relationship on a map\n\nplot(shan_sp, \n     border=grey(.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"blue\", \n     add=TRUE)"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#compute-the-minimum-spanning-tree",
    "href": "hands_on_ex/ex_3/ex_3.html#compute-the-minimum-spanning-tree",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Compute the minimum spanning tree",
    "text": "Compute the minimum spanning tree\n\nCompute the edge cost\nTo compute the edge cost , we will use nbcosts() of the spdep package:\n\nlcosts <- nbcosts(shan.nb, shan_ict)\n\nWhat happens above is that the pairwise dissimilarity is calculated for the five variables between the 2 neighbors. This is the notion of a generalized weight for a spatial weight matrix.\n\nNext, we will get the spatial weight matrix using nb2list(). This time we will input the neighbor list from above along with the “lcost” take note that we have to use “binary” and not row-standardization.\nWe run the code as follow:\n\nshan.w <- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\nCompute the Minimum Spanning Tree\nWe compute the tree using mstree() of the spdep package:\n\nshan.mst <- mstree(shan.w)\n\nWe then check the class and dimension:\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\nNote the dimension is 54 instead of 55 since minimum spanning tree consist of n-1 edges.\n\nNext, we will display the head:\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   31   25 229.44658\n[2,]   25   10 163.95741\n[3,]   10    1 144.02475\n[4,]   10    9 157.04230\n[5,]    9    8  90.82891\n[6,]    8    6 140.01101\n\n\nFinally, we can visualize the plot as follow:\n\nplot(shan_sp, border=gray(.5))\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\nNote: As you can see, all the ploygons here are now part of the tree and connected in some way."
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#computing-spatially-constrained-clusters-using-the-skater-method",
    "href": "hands_on_ex/ex_3/ex_3.html#computing-spatially-constrained-clusters-using-the-skater-method",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Computing spatially constrained clusters using the SKATER method",
    "text": "Computing spatially constrained clusters using the SKATER method\nEarlier we plotted the minimum spanning tree, now we will make use of it further.\nWe will compute the spatially compute cluster using skater() of spdep package:\n\nclust6 <- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nNote:\nOnly the first 2 column of the MST is being used. In addition, we will need need the dataframe with the derived variables. Also the number of cuts is one less than the number of clusters. The above code will then produce a object of class skater.\n\nWe can examine the contents with the following:\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 31 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 31 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nWe can check the cluster assignment as follow:\n\nccs6 <- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can also check the number of assignment as follow:\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nFinally, we will be able to visualize the pruned tree as follow:\n\nplot(shan_sp, border=gray(.5))\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter"
  },
  {
    "objectID": "hands_on_ex/ex_3/ex_3.html#visualizing-the-clusters-in-choropleth-map",
    "href": "hands_on_ex/ex_3/ex_3.html#visualizing-the-clusters-in-choropleth-map",
    "title": "Hand on ex 3 - Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Visualizing the clusters in choropleth map",
    "text": "Visualizing the clusters in choropleth map\nThe newly derived cluster is then visualized as follow:\n\ngroups_mat <- as.matrix(clust6$groups)\nshan_sf_spatialcluster <- cbind(shan_sf_cluster, as.factor(groups_mat)) %>%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\nFor comparison, we will place it alongside the earlier map:\n\nhclust.map <- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map <- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#boundary-data",
    "href": "hands_on_ex/ex_4/ex_4.html#boundary-data",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Boundary data:",
    "text": "Boundary data:\nFirst using the here function, we will generate the path\n\nboundary_file <- here(\"data\",\"dataSingapore\",\"geospatial\")\nboundary_file\n\n[1] \"D:/f4sared/ISSS624/data/dataSingapore/geospatial\"\n\n\nUsing st_read of the sf package, we read the boundary data:\n\nmpsz = st_read(dsn = boundary_file, layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\f4sared\\ISSS624\\data\\dataSingapore\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\ntm_shape(mpsz)+\n  tm_polygons() \n\n\n\n\nUsing the function st_crs() of the sf package, we check the data:\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nCheck the bounding box with st_bbox(mpsz):\n\nst_bbox(mpsz) \n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\nSo here the EPSG is wrong, we need to transform it to 3414\nWe use st_transform() of the sf package for this:\n\nmpsz_svy21 <- st_transform(mpsz, 3414)\n\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() \n\n\n\n\nWe check the CRS once again:\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nFinally we check the bounding box:\n\nst_bbox(mpsz_svy21) \n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#aspatial-data",
    "href": "hands_on_ex/ex_4/ex_4.html#aspatial-data",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Aspatial Data:",
    "text": "Aspatial Data:\nWe generate file path:\n\ncsv_file <- here(\"data\",\"dataSingapore\",\"aspatial\", \"Condo_resale_2015.csv\")\ncsv_file\n\n[1] \"D:/f4sared/ISSS624/data/dataSingapore/aspatial/Condo_resale_2015.csv\"\n\n\nRead the csv with read_csv() from readr package of the tidyverse, import as tibble frame:\n\ncondo_resale = read_csv(csv_file)\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nUse glimpse() of dplyr to check the data:\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nCheck long data:\n\nhead(condo_resale$LONGITUDE)\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\nCheck lat data:\n\nhead(condo_resale$LATITUDE)\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nUse summary of base R to get the tibble frame summary statistics:\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#convert-aspatial-tibble-dataframe-to-sf-object",
    "href": "hands_on_ex/ex_4/ex_4.html#convert-aspatial-tibble-dataframe-to-sf-object",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Convert Aspatial tibble dataframe to sf object:",
    "text": "Convert Aspatial tibble dataframe to sf object:\nWe use the st_as_sf() function of the sf package to convert:\n(need the name of the long and lat column, the order matters !)\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\nCheck the outcome:\n\nst_crs(condo_resale.sf) \n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nCheck the data with head():\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#correcting-skewness-of-dependent-var",
    "href": "hands_on_ex/ex_4/ex_4.html#correcting-skewness-of-dependent-var",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Correcting skewness of dependent var",
    "text": "Correcting skewness of dependent var\nQuestion: why do we only fix the dependent variables and not the independent variables ?\nWe use ggplot to visualize the histogram of the selling price:\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nSince the selling price is right skewed, we need to perform a log transformation. For the left skew, we will need to use power transformation.\nUsing mutate() of the dplyr function, we will do a log transformation:\n\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nWe then plot the log selling price as follow:\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nWe observed that the data skewness has slightly improved."
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#histogram-of-independent-variables",
    "href": "hands_on_ex/ex_4/ex_4.html#histogram-of-independent-variables",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Histogram of independent variables:",
    "text": "Histogram of independent variables:\nUsing ggarrange, we will plot the histogram of mutilple independent variables:\n\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#statistical-point-map",
    "href": "hands_on_ex/ex_4/ex_4.html#statistical-point-map",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Statistical Point Map",
    "text": "Statistical Point Map\nWe do the settings as follow:\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntmap_options(check.and.fix = TRUE)\n\nUsing tm_dots() we will plot the points of each row on the map:\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +\n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\nSet back to plot mode:\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#simple-linear-regression",
    "href": "hands_on_ex/ex_4/ex_4.html#simple-linear-regression",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Simple Linear Regression:",
    "text": "Simple Linear Regression:\nWe use the function lm() of the R stats package to build a linear regression model:\n\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns the class of “lm” for sinlge or “mlm” for multiple.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\nFrom the above, the gradient is 14719.0 and the intercept is -258121.1. P value is significant enough that we can reject the null hypothesis that the points are random. R square is 45% meaning that model is able to explain 45% of the resale prices.\nDraw scatterplot with gradient line with “lm” as a method:\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#check-correlation",
    "href": "hands_on_ex/ex_4/ex_4.html#check-correlation",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Check Correlation:",
    "text": "Check Correlation:\nBefore building the multiple linear regression, we need to check for correlation and remove some independent variables.\nWe will use corrplot as follow:\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\nLease_99 year will be removed since it is highly correlated to freehold."
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#multiple-linear-regression-method",
    "href": "hands_on_ex/ex_4/ex_4.html#multiple-linear-regression-method",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Multiple linear regression method:",
    "text": "Multiple linear regression method:\nAgain we use the lm() of the R stats package to build a model:\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#preparing-publication-quality-table-olsrr",
    "href": "hands_on_ex/ex_4/ex_4.html#preparing-publication-quality-table-olsrr",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Preparing publication quality table: olsrr",
    "text": "Preparing publication quality table: olsrr\nQuestion: what does olsrr do ? it seems to be generating only a report.\nAfter removing the insignificant independent variable we calibrate using olsrr:\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#preparing-publication-quality-table-gtsummary",
    "href": "hands_on_ex/ex_4/ex_4.html#preparing-publication-quality-table-gtsummary",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Preparing publication quality table: gtsummary",
    "text": "Preparing publication quality table: gtsummary\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#check-for-multicollinearity",
    "href": "hands_on_ex/ex_4/ex_4.html#check-for-multicollinearity",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Check for multicollinearity",
    "text": "Check for multicollinearity\nUsing ols_vif_tol() function from olsrr, we test for signs of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince VIF are all below value of 10, there are no signs of multicollinearity."
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#perform-linearity-assumption-test",
    "href": "hands_on_ex/ex_4/ex_4.html#perform-linearity-assumption-test",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Perform linearity assumption test:",
    "text": "Perform linearity assumption test:\nIn multiple linear regression, it is important to test the assumption for linearity.\nWe use the ols_plot_resid_fit() of the olsrr package to perform the test:\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nSince most of the points are scattered around the zero line, the relationships between dependent and independent variables are thus linear."
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#test-for-normality",
    "href": "hands_on_ex/ex_4/ex_4.html#test-for-normality",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Test for normality",
    "text": "Test for normality\nWe can also plot the histogram of the residuals with ols_plot_resid_hist():\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\nAlternatively we can also use ols_test_normality () :\n\nols_test_normality(condo.mlr1)\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#testing-for-spatial-auto-correlation",
    "href": "hands_on_ex/ex_4/ex_4.html#testing-for-spatial-auto-correlation",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Testing for spatial auto correlation:",
    "text": "Testing for spatial auto correlation:\nSave the residuals as a dataframe:\n\nmlr.output <- as.data.frame(condo.mlr1$residuals)\n\nJoin the newly created dataframe with sf:\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nConvert the new dataframe to spatial format:\n\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nSet interactive mode:\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntmap_options(check.and.fix = TRUE)\n\nPlot the interactive map:\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\nset back to plot mode:\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#morans-i-test",
    "href": "hands_on_ex/ex_4/ex_4.html#morans-i-test",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Moran’s I test",
    "text": "Moran’s I test\nThis time there is no need to compute the centroid of each ploygon, instead, we will use directly the points:\nWe use the dnearneigh() of the spdep to compute the neighbor by distance:\n\nnb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nThe neighbor list is then converted to spatial weights:\n\nnb_lw <- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nThe Moran’s I test is then performed with lm.morantest() function of spdep:\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#fixed-bandwidth",
    "href": "hands_on_ex/ex_4/ex_4.html#fixed-bandwidth",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Fixed bandwidth",
    "text": "Fixed bandwidth\n\nCompute Fixed Bandwidth\nTo identify the optimal fixed bandwidth, we use the bw.gwr() of the GWmodel package.\nWe will specify the dependent variable followed by the independent variables:\n\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\n\n\nCalibrate GWR model with fixed bandwidth\nUsing the output bw.fixed generated earlier, we will now calibrate the model:\n\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nWe can check the output as follow:\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-17 23:25:20 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2022-12-17 23:25:21 \n\n\nQuestion: Why is the adjusted R square value much better compared to R value of the multiple linear regression ?"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#adaptive-bandwidth",
    "href": "hands_on_ex/ex_4/ex_4.html#adaptive-bandwidth",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Adaptive bandwidth",
    "text": "Adaptive bandwidth\n\nCompute adaptive bandwidth:\nSimilar to the code above, we now change the “adaptive” setting to TRUE:\n\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nCalibrate GWR model with adaptive bandwidth:\n\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nWe display the model output as follow:\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-17 23:25:29 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2022-12-17 23:25:30"
  },
  {
    "objectID": "hands_on_ex/ex_4/ex_4.html#visualizing-gwr-output",
    "href": "hands_on_ex/ex_4/ex_4.html#visualizing-gwr-output",
    "title": "Hand on ex 4 + In Class ex 4 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Visualizing GWR output",
    "text": "Visualizing GWR output\nQuestion: Why is this chunk of code here ?\n\n# condo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n#   st_transform(crs=3414)\n\nQuestion: Why is this chunk of code here ?\n\n# condo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\n# condo_resale.sf.adaptive.svy21  \n\nCreate the dataframe for plotting:\n\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nVisualize Local R2:\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nVisualizing coefficient estimates through creating Interactive point symbol map:\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nAREA_SQM_SE <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nBy URA Planning Region:\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)\n\nWarning: The shape mpsz_svy21[mpsz_svy21$REGION_N == \"CENTRAL REGION\", ] is\ninvalid. See sf::st_is_valid"
  },
  {
    "objectID": "Hands_on_ex1.html",
    "href": "Hands_on_ex1.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Hello ! Here is my second page"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624_Licheng_Yan_Learning_Journal",
    "section": "",
    "text": "This Netlify site is a documentation of my learning journey for geospatial analytics and Rstudio\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n50 + 50\n\n[1] 100"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#queen",
    "href": "in_class/ex_1/in_class_ex_1.html#queen",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Queen:",
    "text": "Queen:\nCompute the (QUEEN) contiguity based neighbors weight matrix:\n\nwm_q <- poly2nb(hunan, queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nNext we want to see the neighbor for the first polygon:\n**Note: Both syntax below seem to work\n\nwm_q[1]\n\n[[1]]\n[1]  2  3  4 57 85\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nNext we will retrieve the name of polygon 1:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nWe will next reveal the neighbouring counties of Anxiang:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can also retrieve the neighbouring GDPPC of the five countries by code chunk below:\n**Note: we can save the neighbor as a list.\n**Then we will just use that as the input for filtering\n\nnb_1 <- wm_q[[1]]\nnb_1 <- hunan$GDPPC[nb_1]\nnb_1\n\n[1] 20981 34592 24473 21311 22879\n\n\nUsing str(), we will then display the complete weight matrix:\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#rook",
    "href": "in_class/ex_1/in_class_ex_1.html#rook",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Rook:",
    "text": "Rook:\nCreate the weight matrix based on the ROOK:\n\nwm_r <- poly2nb(hunan, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#data-preparation",
    "href": "in_class/ex_1/in_class_ex_1.html#data-preparation",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Data preparation:",
    "text": "Data preparation:\nStore the longitude:\n**~ means shorthand for writing a function\n** .x means a vector input\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nStore the latitude:\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nBind the 2 above together:\n\ncoords <- cbind(longitude, latitude)\n\nCheck the head of the newly created data:\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#plot-queen",
    "href": "in_class/ex_1/in_class_ex_1.html#plot-queen",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Plot QUEEN:",
    "text": "Plot QUEEN:\nNext we will plot the contiguity based neighbors map:\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#plot-rook",
    "href": "in_class/ex_1/in_class_ex_1.html#plot-rook",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Plot ROOK:",
    "text": "Plot ROOK:\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\nPlotting both maps together:\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\", main=\"Rook Contiguity\")"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#compute-the-neighbors",
    "href": "in_class/ex_1/in_class_ex_1.html#compute-the-neighbors",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Compute the neighbors:",
    "text": "Compute the neighbors:\nCalculate the nearest neighbor:\n**k is default value 1\n\nk1 <- knn2nb(knearneigh(coords))\n\nHere we see that each polygon only has 1 neighbor:\n\nstr(k1)\n\nList of 88\n $ : int 3\n $ : int 78\n $ : int 1\n $ : int 5\n $ : int 4\n $ : int 69\n $ : int 67\n $ : int 46\n $ : int 84\n $ : int 70\n $ : int 72\n $ : int 63\n $ : int 12\n $ : int 17\n $ : int 13\n $ : int 22\n $ : int 16\n $ : int 20\n $ : int 21\n $ : int 82\n $ : int 19\n $ : int 16\n $ : int 41\n $ : int 54\n $ : int 81\n $ : int 81\n $ : int 29\n $ : int 49\n $ : int 27\n $ : int 33\n $ : int 24\n $ : int 50\n $ : int 28\n $ : int 45\n $ : int 47\n $ : int 34\n $ : int 42\n $ : int 44\n $ : int 43\n $ : int 39\n $ : int 23\n $ : int 37\n $ : int 44\n $ : int 43\n $ : int 34\n $ : int 47\n $ : int 46\n $ : int 51\n $ : int 28\n $ : int 52\n $ : int 48\n $ : int 54\n $ : int 55\n $ : int 52\n $ : int 50\n $ : int 36\n $ : int 58\n $ : int 57\n $ : int 87\n $ : int 13\n $ : int 63\n $ : int 61\n $ : int 12\n $ : int 57\n $ : int 76\n $ : int 68\n $ : int 7\n $ : int 66\n $ : int 6\n $ : int 10\n $ : int 74\n $ : int 11\n $ : int 70\n $ : int 71\n $ : int 55\n $ : int 65\n $ : int 38\n $ : int 2\n $ : int 45\n $ : int 34\n $ : int 25\n $ : int 21\n $ : int 12\n $ : int 9\n $ : int 5\n $ : int 74\n $ : int 61\n $ : int 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 1\n - attr(*, \"class\")= chr \"nb\"\n\n\ncompute the distance between all neighbors:\n\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nSummary report shows that the max value is 61.79, so this value will be used as the upper threshold"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#compute-the-weight-matrix",
    "href": "in_class/ex_1/in_class_ex_1.html#compute-the-weight-matrix",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Compute the weight matrix:",
    "text": "Compute the weight matrix:\nWe compute the distance weight matrix as follow:\n**0 is min threshold\n**62 is max threshold\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n**Average number of links here refers to the average number of nearest neighbor per polygon\nDisplay the weight matrix:\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAn alternative way to present the data:\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\nFind number of disjoint sub graph:\nhttps://r4gdsa.netlify.app/chap03.html#computing-distance-based-neighbours\n\nn_comp <- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#plot-the-distance-based-weight-matrix",
    "href": "in_class/ex_1/in_class_ex_1.html#plot-the-distance-based-weight-matrix",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Plot the distance based weight matrix:",
    "text": "Plot the distance based weight matrix:\nPlot the distance based neighbor + K1 nearest neighbor:\n**Note it is an overlap of 2 plots on 1\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\nPlot the distance based + K nearest neighbor on 2 separate plots:\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08, main=\"1st nearest neighbours\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6, main=\"Distance link\")"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#compute-adaptive-distance-weight-matrix",
    "href": "in_class/ex_1/in_class_ex_1.html#compute-adaptive-distance-weight-matrix",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Compute adaptive distance weight matrix:",
    "text": "Compute adaptive distance weight matrix:\nRecalculate the N nearest neighbors, this time using K = 6\n\nknn6 <- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nCheck the output:\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nPlot the new K = 6:\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"black\")"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#spatial-lag-with-row-standardized-weights",
    "href": "in_class/ex_1/in_class_ex_1.html#spatial-lag-with-row-standardized-weights",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Spatial lag with row-standardized weights:",
    "text": "Spatial lag with row-standardized weights:\nCompute the spatial lag:\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\n\nThe lag for the first polygon is:\n\nGDPPC.lag[1]\n\n[1] 24847.2\n\n\nThe GDPPC of the first polygon’s neighbor are:\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nTheir total is:\n\nsum(nb1)\n\n[1] 124236\n\n\nTheir average is:\n\nsum(nb1)/5\n\n[1] 24847.2\n\n\nSo their weighted averaged is the value of the lag of the first polygon.\nAppend the values:\n\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\nJoining, by = \"NAME_3\"\n\n\n\nhead(hunan)\n\nSimple feature collection with 6 features and 36 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Leng Shape_Area  County    City\n1 Changde 21098 Anxiang      County   1.869074 0.10056190 Anxiang Changde\n2 Changde 21100 Hanshou      County   2.360691 0.19978745 Hanshou Changde\n3 Changde 21101  Jinshi County City   1.425620 0.05302413  Jinshi Changde\n4 Changde 21102      Li      County   3.474325 0.18908121      Li Changde\n5 Changde 21103   Linli      County   2.289506 0.11450357   Linli Changde\n6 Changde 21104  Shimen      County   4.171918 0.37194707  Shimen Changde\n  avg_wage deposite     FAI Gov_Rev Gov_Exp     GDP GDPPC     GIO   Loan  NIPCR\n1    31935   5517.2  3541.0  243.64  1779.5 12482.0 23667  5108.9 2806.9 7693.7\n2    32265   7979.0  8665.0  386.13  2062.4 15788.0 20981 13491.0 4550.0 8269.9\n3    28692   4581.7  4777.0  373.31  1148.4  8706.9 34592 10935.0 2242.0 8169.9\n4    32541  13487.0 16066.0  709.61  2459.5 20322.0 24473 18402.0 6748.0 8377.0\n5    32667    564.1  7781.2  336.86  1538.7 10355.0 25554  8214.0  358.0 8143.1\n6    33261   8334.4 10531.0  548.33  2178.8 16293.0 27137 17795.0 6026.5 6156.0\n   Bed    Emp  EmpR EmpRT Pri_Stu Sec_Stu Household Household_R NOIP Pop_R\n1 1931 336.39 270.5 205.9  19.584  17.819     148.1       135.4   53 346.0\n2 2560 456.78 388.8 246.7  42.097  33.029     240.2       208.7   95 553.2\n3  848 122.78  82.1  61.7   8.723   7.592      81.9        43.7   77  92.4\n4 2038 513.44 426.8 227.1  38.975  33.938     268.5       256.0   96 539.7\n5 1440 307.36 272.2 100.8  23.286  18.943     129.1       157.2   99 246.6\n6 2502 392.05 329.6 193.8  29.245  26.104     190.6       184.7  122 399.2\n    RSCG Pop_T    Agri Service Disp_Inc      RORP    ROREmp lag GDPPC\n1 3957.9 528.3 4524.41   14100    16610 0.6549309 0.8041262  24847.20\n2 4460.5 804.6 6545.35   17727    18925 0.6875466 0.8511756  22724.80\n3 3683.0 251.8 2562.46    7525    19498 0.3669579 0.6686757  24143.25\n4 7110.2 832.5 7562.34   53160    18985 0.6482883 0.8312558  27737.50\n5 3604.9 409.3 3583.91    7031    18604 0.6024921 0.8856065  27270.25\n6 6490.7 600.5 5266.51    6981    19275 0.6647794 0.8407091  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nPlot the lag GDPPPC:\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#spatial-lag-as-sum-of-neighbouring-values",
    "href": "in_class/ex_1/in_class_ex_1.html#spatial-lag-as-sum-of-neighbouring-values",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Spatial lag as sum of neighbouring values:",
    "text": "Spatial lag as sum of neighbouring values:\nCalculate the weights:\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nCompute lag variable:\n\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nExamine the output:\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nJoin the data:\n\nhunan <- left_join(hunan, lag.res)\n\nJoining, by = \"NAME_3\"\n\n\nPlot the lag sum:\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#spatial-window-average",
    "href": "in_class/ex_1/in_class_ex_1.html#spatial-window-average",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Spatial window average:",
    "text": "Spatial window average:\nAssign to new variable:\n\nwm_q1 <- wm_q\n\nNext we will use include.self() to set the attribute to include self in neighbor calculation.\n\ninclude.self(wm_q1)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nObtain the weights:\n\nwm_q1 <- nb2listw(wm_q1)\nwm_q1\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nCreate lag variable:\n\nlag_w_avg_gpdpc <- lag.listw(wm_q1, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nConvert to dataframe:\n\nlag.list.wm_q1 <- list(hunan$NAME_3, lag.listw(wm_q1, hunan$GDPPC))\nlag_wm_q1.res <- as.data.frame(lag.list.wm_q1)\ncolnames(lag_wm_q1.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nJoin to mainframe:\n\nhunan <- left_join(hunan, lag_wm_q1.res)\n\nJoining, by = \"NAME_3\"\n\n\nPlot the outcome:\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(gdppc, w_avg_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1.html#spatial-window-sum",
    "href": "in_class/ex_1/in_class_ex_1.html#spatial-window-sum",
    "title": "In Class ex 1 - Chap 3 Spatial Weights and Applications",
    "section": "Spatial Window Sum:",
    "text": "Spatial Window Sum:\nWe will not proceed without row standardized weights:\nCopy new variable\n\nwm_q1 <- wm_q\n\nSet attribute:\n\ninclude.self(wm_q1)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\nwm_q1\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\n\nApply function:\n\nb_weights <- lapply(wm_q1, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1\n\n\nGet weight values:\n\nb_weights2 <- nb2listw(wm_q1, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nCompute lag variable:\n\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nConvert result into dataframe:\n\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\n\nJoin to main frame:\n\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\nJoining, by = \"NAME_3\"\n\n\nPlot the results:\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class/ex_1/in_class_ex_1_old.html",
    "href": "in_class/ex_1/in_class_ex_1_old.html",
    "title": "in_class_ex_1",
    "section": "",
    "text": "This is xxx\nGetting Started\nInstall and load the tidyverse and sf packages.\n\npacman::p_load(sf, tidyverse, spdep)\n\nImport Geo spatial data\nImport Polygon\n\nhunan_sf <- st_read(dsn = \"dataH/geospatial\", \n                  layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\f4sared\\ISSS624\\in_class\\ex_1\\dataH\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nImporting and transforming using a nested piping\n\nhunan <- read_csv(\"dataH/aspatial/Hunan_2012.csv\") \n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "in_class/ex_2/ex_2.html#import-nigeria-water-point-data-file",
    "href": "in_class/ex_2/ex_2.html#import-nigeria-water-point-data-file",
    "title": "In-Class Ex 2 - Loading data + prepare data for take home Ex 1",
    "section": "Import Nigeria water point data-file:",
    "text": "Import Nigeria water point data-file:\nGenerate a path:\nWe use the here function to generate a specific file path on the root folder.\n\nshapefile_path <- here(\"data\", \"dataNigeria\", \"geospatial\")\nshapefile_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria/geospatial\"\n\n\nSome useful link for the CRS:\n\nhttps://datacarpentry.org/organization-geospatial/03-crs/\nhttps://www.nceas.ucsb.edu/sites/default/files/2020-04/OverviewCoordinateReferenceSystems.pdf\n\nst_read() belongs to the sf package. It reads simple features from file or database. Simple features or simple feature access refers to formal standard ISO 19125-1:2004 that describes how real world data can be represented in computers, with emphasis on the spatial geometry of these objects. Link below:\nhttps://cran.r-project.org/web/packages/sf/vignettes/sf1.html#:~:text=Simple%20features%20or%20simple%20feature,spatial%20geometry%20of%20these%20objects.\nTo find the CRS of the shapefile, open the .prj file as a text. It will tell you which projection system is being used.\nRead the shapefile using st_read() belonging to the sf package:\nThe data read will be saved as a simple feature data table.\nWe will use the filter() function of dplyr package to filter only rows for Nigeria\n\n# wp <- st_read(\n#   dsn = shapefile_path,\n#   layer = \"geo_export\",\n#   crs = 4326) %>%\n#   filter(clean_coun == \"Nigeria\")\n\nGenerate the save path using here function:\n\nsavefile_path <- here(\"data\", \"dataNigeria\", \"geospatial\", \"wp_nga.rds\")\nsavefile_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria/geospatial/wp_nga.rds\"\n\n\nWe will next save the file using write_rds() of the tidyverse package:\nrds is a native data format of R.\n\n# wp_ng <- write_rds(wp, savefile_path)"
  },
  {
    "objectID": "in_class/ex_2/ex_2.html#import-nigeria-geo-boundary-file",
    "href": "in_class/ex_2/ex_2.html#import-nigeria-geo-boundary-file",
    "title": "In-Class Ex 2 - Loading data + prepare data for take home Ex 1",
    "section": "Import Nigeria geo-boundary file:",
    "text": "Import Nigeria geo-boundary file:\nNext we will make the path to the geo boundary file:\n\nshapefile_path <- here(\"data\", \"dataNigeria\", \"boundary\")\nshapefile_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria/boundary\"\n\n\nNext we will Import the Nigeria LGA Boundary Data with st_read() function:\nThe imported data will be saved as a simple features dataset.\n\nnga <- st_read(\n  dsn = shapefile_path,\n  layer = \"geoBoundaries-NGA-ADM2\",\n  crs = 4326)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `D:\\f4sared\\ISSS624\\data\\dataNigeria\\boundary' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "in_class/ex_2/ex_2.html#downsize-further-the-wp_nga-data",
    "href": "in_class/ex_2/ex_2.html#downsize-further-the-wp_nga-data",
    "title": "In-Class Ex 2 - Loading data + prepare data for take home Ex 1",
    "section": "Downsize further the wp_nga data:",
    "text": "Downsize further the wp_nga data:\nLoad the previously saved data:\nWe will select specific columns using select().\n\n# final <- read_rds(rdsfile_path) %>% select(1:2, 14:17, 23)\n\nCreate the path for saving the file\n\n# savefile_path <- here(\"data\", \"dataNigeria\", \"geospatial\", \"wp_nga_v2.rds\")\n# savefile_path\n\nSave the file:\n\n# write_rds(final, savefile_path)"
  },
  {
    "objectID": "in_class/ex_2/ex_2.html#visualize-initial-distribution",
    "href": "in_class/ex_2/ex_2.html#visualize-initial-distribution",
    "title": "In-Class Ex 2 - Loading data + prepare data for take home Ex 1",
    "section": "Visualize Initial distribution",
    "text": "Visualize Initial distribution\nGenerate path to rds file saved previously:\n\nrdsfile_path <- here(\"data\", \"dataNigeria\", \"geospatial\",\"wp_nga_v2.rds\")\nrdsfile_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria/geospatial/wp_nga_v2.rds\"\n\n\nLoad the rds file with read_rds() function of the tidyverse package:\nWe will also make use of the piping to replace the “na” values with “unknown”.\nmutate() is a function of the dplyr package.\n\nwp_nga <- read_rds(rdsfile_path) %>%\n  mutate(status_cle = replace_na(status_cle, \"Unknown\"))\n\nCheck the CRS of the spatial datafile with st_crs():\n\nst_crs(wp_nga)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\nUse the freq() of the funModeling package to show the distribution percentage of status_cle:\n\nfreq(data=wp_nga,\n     input = 'status_cle')\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n                        status_cle frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                          Unknown     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00"
  },
  {
    "objectID": "in_class/ex_2/ex_2.html#filter-for-functional-water-points",
    "href": "in_class/ex_2/ex_2.html#filter-for-functional-water-points",
    "title": "In-Class Ex 2 - Loading data + prepare data for take home Ex 1",
    "section": "Filter for functional water-points:",
    "text": "Filter for functional water-points:\nHere we will use the filter() function from the dplyr package to select “functional” rows only:\nWe use the %in% to denote the membership in the group of strings.\n\nwpt_functional <- wp_nga %>%\n  filter(status_cle %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nThen we will plot with freq() function from funModeling to show the distribution:\n\nfreq(data=wpt_functional, \n     input = 'status_cle')\n\n\n\n\n                   status_cle frequency percentage cumulative_perc\n1                  Functional     45883      87.99           87.99\n2 Functional but needs repair      4579       8.78           96.77\n3   Functional but not in use      1686       3.23          100.00"
  },
  {
    "objectID": "in_class/ex_2/ex_2.html#filter-for-non-functional",
    "href": "in_class/ex_2/ex_2.html#filter-for-non-functional",
    "title": "In-Class Ex 2 - Loading data + prepare data for take home Ex 1",
    "section": "Filter for non-functional",
    "text": "Filter for non-functional\nFilter for non-functional rows:\nUse %in% for to select rows that fall into the specific categories.\n\nwpt_nonfunctional <- wp_nga %>%\n  filter(status_cle %in%\n           c(\"Abandoned/Decommissioned\", \n             \"Abandoned\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\",\n             \"Non-Functional due to dry season\"))\n\nPlot the distribution with the freq() function:\n\nfreq(data=wpt_nonfunctional, \n     input = 'status_cle')\n\n\n\n\n                        status_cle frequency percentage cumulative_perc\n1                   Non-Functional     29385      91.25           91.25\n2 Non-Functional due to dry season      2403       7.46           98.71\n3         Abandoned/Decommissioned       234       0.73           99.44\n4                        Abandoned       175       0.54           99.98\n5 Non functional due to dry season         7       0.02          100.00"
  },
  {
    "objectID": "in_class/ex_2/ex_2.html#filter-for-unknown",
    "href": "in_class/ex_2/ex_2.html#filter-for-unknown",
    "title": "In-Class Ex 2 - Loading data + prepare data for take home Ex 1",
    "section": "Filter for unknown:",
    "text": "Filter for unknown:\nLastly we filter for the rows that have unknown status:\n\nwpt_unknown <- wp_nga %>%\n  filter(status_cle == \"Unknown\")"
  },
  {
    "objectID": "in_class/ex_2/ex_2.html#perform-data-manipulation",
    "href": "in_class/ex_2/ex_2.html#perform-data-manipulation",
    "title": "In-Class Ex 2 - Loading data + prepare data for take home Ex 1",
    "section": "Perform data manipulation:",
    "text": "Perform data manipulation:\nUsing st_intersects, we will be able to create a list of rows from wp_nga that intersects each row of nga.\nFor the intersection to work, st_intersect will check if each point falls within the polygon of nga.\nNext we use the lengths() function to count the number of instances. Then we append to a new column.\nWe repeat this step across all 3 categories of Functional, Non-Functional & Unknown\n\nnga_wp <- nga %>%\n  mutate(`total wpt` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wpt functional` = lengths(\n    st_intersects(nga, wpt_functional))) %>%\n  mutate(`wpt non-functional` = lengths(\n    st_intersects(nga, wpt_nonfunctional))) %>%\n  mutate(`wpt unknown` = lengths(\n    st_intersects(nga, wpt_unknown)))\n\nNext, using the mutate() function of dplyr, we will create 2 new columns:\n\npct_functional = `wpt functional`/`total wpt`\npct_non-functional = `wpt non-functional`/`total wpt`\n\nWe will then use select() of dplyr to retain the fields that we require.\n\nnga_wp <- nga_wp %>%\n  mutate(pct_functional = `wpt functional`/`total wpt`) %>%\n  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`) \n# select(3:4, 9:10, 18:23)\n\nWe will then create a save file path:\n\nsavefile_path <- here(\"data\", \"dataNigeria\", \"geospatial\", \"nga_wp.rds\")\nsavefile_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria/geospatial/nga_wp.rds\"\n\n\nNext we will save this final dataframe using write_rds of tidyverse package:\n\nwrite_rds(nga_wp, savefile_path)"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#prepare-the-data",
    "href": "in_class/ex_3/ex_3.html#prepare-the-data",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Prepare the data",
    "text": "Prepare the data\nWe select the clustering variables now. Notice we use the st_set_geometry(NULL) to exclude the geometry column:\n\ncluster_vars <- shan_sf %>%\n  st_set_geometry(NULL) %>%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNext, we will change the names of the row:\n\nrow.names(cluster_vars) <- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNext we will delete the TS.x row:\n\nshan_ict <- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#data-standardization",
    "href": "in_class/ex_3/ex_3.html#data-standardization",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Data Standardization",
    "text": "Data Standardization\nSince different variables are used, their range is different. Thus we need to standardize them.\n\nMin Max\nWe do min-max 0-1 as follow:\n\nshan_ict.std <- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\n\nZ-Score\nNext, we perform Z-score standardization as follow:\n\nshan_ict.z <- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nAfter doing this step, the mean and std dev are now 0 and 1 respectively.\n\n\n\nVisualize the standardized variables\nNext we visualize the variables:\n\nr <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nshan_ict_s_df <- as.data.frame(shan_ict.std)\ns <- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df <- as.data.frame(shan_ict.z)\nz <- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#compute-proximity-matrix",
    "href": "in_class/ex_3/ex_3.html#compute-proximity-matrix",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Compute Proximity Matrix",
    "text": "Compute Proximity Matrix\nWe will use dist() of R to compute the proximity matrix:\n\nproxmat <- dist(shan_ict, method = 'euclidean')"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#compute-hierarchical-clustering",
    "href": "in_class/ex_3/ex_3.html#compute-hierarchical-clustering",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Compute Hierarchical Clustering",
    "text": "Compute Hierarchical Clustering\nUsing hclust() of R stats, we will input the proximity matrix. The putout is a class of hclust that describes a tree that is produced:\n\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the result as follow:\n\nplot(hclust_ward, cex = 0.8)"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#determine-optimal-clustering-algorithm",
    "href": "in_class/ex_3/ex_3.html#determine-optimal-clustering-algorithm",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Determine optimal clustering algorithm",
    "text": "Determine optimal clustering algorithm\nSince there are many algorithms, it makes sense to try them all. We will get the agglomeration coefficient which measures the amount of clustering structure found.\nFirst we will make a simple list:\n\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nWe will use the agnes() function of cluster package as follow:\n\nac <- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#determine-optimal-clusters",
    "href": "in_class/ex_3/ex_3.html#determine-optimal-clusters",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Determine optimal clusters",
    "text": "Determine optimal clusters\nGap statistic compares the intra-cluster variation for different numbers of clusters k.\nWe will compute the gap statistic using clusGap() of cluster package:\n“hcut” is from factoextra package.\n\nset.seed(12345)\ngap_stat <- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nNow, using fviz_gap_stat() of factoextra package to find the optimal cluster:\n\nfviz_gap_stat(gap_stat)"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#interpreting-the-dendrograms",
    "href": "in_class/ex_3/ex_3.html#interpreting-the-dendrograms",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Interpreting the dendrograms",
    "text": "Interpreting the dendrograms\nNext we will redraw the dendrograms with the optimal number of clusters. This is done using rect.hclust() of R:\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\nQuestion: How does the algorithm know which cluster to break up ?"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#visually-driven-hierarchical-clustering-analysis",
    "href": "in_class/ex_3/ex_3.html#visually-driven-hierarchical-clustering-analysis",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Visually driven hierarchical clustering analysis:",
    "text": "Visually driven hierarchical clustering analysis:\nUsing the function heatmaply() we will build a cluster heat map.\nFirst we need to transform the dataframe into a matrix in order to be able to plot:\n\nshan_ict_mat <- data.matrix(shan_ict)\n\nNext we will use function heatmaply() of heatmaply to plot:\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\nQuestion:\nWhy do you show all 5 variables ? Is the segmentation based on all 5 variables ?"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#mapping-the-cluster-formed",
    "href": "in_class/ex_3/ex_3.html#mapping-the-cluster-formed",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Mapping the cluster formed",
    "text": "Mapping the cluster formed\nWe will use cutree() of R to prune the tree to that we have 6 cluster:\n\ngroups <- as.factor(cutree(hclust_ward, k=6))\n\nNext, we will convert the groups into a matrix before combining it to shan_sf:\n\nshan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nFinally, we will plot the outcome:\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nAs shown from the output above, we see that all our cluster appear to be fragmented. This is because a non-spatial method is being used."
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#convert-to-spatial-polygons-dataframe",
    "href": "in_class/ex_3/ex_3.html#convert-to-spatial-polygons-dataframe",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Convert to spatial polygons dataframe",
    "text": "Convert to spatial polygons dataframe\nFirst we need to convert the shan_sf from sf object to the sp object.\nWe do this via the as_spatial() of sf package:\n\nshan_sp <- as_Spatial(shan_sf)"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#compute-the-neighbor-list",
    "href": "in_class/ex_3/ex_3.html#compute-the-neighbor-list",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Compute the neighbor list",
    "text": "Compute the neighbor list\nUsing poly2nd() of spdep, we will then compute the neighbor list:\n\nshan.nb <- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nQuestion: How is the neighbor computed here ? Queen ???"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#plot-the-neighbors-relationship-on-a-map",
    "href": "in_class/ex_3/ex_3.html#plot-the-neighbors-relationship-on-a-map",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Plot the neighbors relationship on a map",
    "text": "Plot the neighbors relationship on a map\n\nplot(shan_sp, \n     border=grey(.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"blue\", \n     add=TRUE)"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#compute-the-minimum-spanning-tree",
    "href": "in_class/ex_3/ex_3.html#compute-the-minimum-spanning-tree",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Compute the minimum spanning tree",
    "text": "Compute the minimum spanning tree\n\nCompute the edge cost\nTo compute the edge cost , we will use nbcosts() of the spdep package:\n\nlcosts <- nbcosts(shan.nb, shan_ict)\n\nWhat happens above is that the pairwise dissimilarity is calculated for the five variables between the 2 neighbors. This is the notion of a generalized weight for a spatial weight matrix.\n\nNext, we will get the spatial weight matrix using nb2list(). This time we will input the neighbor list from above along with the “lcost” take note that we have to use “binary” and not row-standardization.\nWe run the code as follow:\n\nshan.w <- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\nCompute the Minimum Spanning Tree\nWe compute the tree using mstree() of the spdep package:\n\nshan.mst <- mstree(shan.w)\n\nWe then check the class and dimension:\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\nNote the dimension is 54 instead of 55 since minimum spanning tree consist of n-1 edges.\n\nNext, we will display the head:\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   31   25 229.44658\n[2,]   25   10 163.95741\n[3,]   10    1 144.02475\n[4,]   10    9 157.04230\n[5,]    9    8  90.82891\n[6,]    8    6 140.01101\n\n\nFinally, we can visualize the plot as follow:\n\nplot(shan_sp, border=gray(.5))\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\nNote: As you can see, all the ploygons here are now part of the tree and connected in some way."
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#computing-spatially-constrained-clusters-using-the-skater-method",
    "href": "in_class/ex_3/ex_3.html#computing-spatially-constrained-clusters-using-the-skater-method",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Computing spatially constrained clusters using the SKATER method",
    "text": "Computing spatially constrained clusters using the SKATER method\nEarlier we plotted the minimum spanning tree, now we will make use of it further.\nWe will compute the spatially compute cluster using skater() of spdep package:\n\nclust6 <- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nNote:\nOnly the first 2 column of the MST is being used. In addition, we will need need the dataframe with the derived variables. Also the number of cuts is one less than the number of clusters. The above code will then produce a object of class skater.\n\nWe can examine the contents with the following:\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 31 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 31 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nWe can check the cluster assignment as follow:\n\nccs6 <- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can also check the number of assignment as follow:\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nFinally, we will be able to visualize the pruned tree as follow:\n\nplot(shan_sp, border=gray(.5))\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#visualizing-the-clusters-in-choropleth-map",
    "href": "in_class/ex_3/ex_3.html#visualizing-the-clusters-in-choropleth-map",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Visualizing the clusters in choropleth map",
    "text": "Visualizing the clusters in choropleth map\nThe newly derived cluster is then visualized as follow:\n\ngroups_mat <- as.matrix(clust6$groups)\nshan_sf_spatialcluster <- cbind(shan_sf_cluster, as.factor(groups_mat)) %>%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\nFor comparison, we will place it alongside the earlier map:\n\nhclust.map <- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map <- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#ward-like-hierarchical-clustering-clustgeo",
    "href": "in_class/ex_3/ex_3.html#ward-like-hierarchical-clustering-clustgeo",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Ward-like hierarchical clustering: ClustGeo",
    "text": "Ward-like hierarchical clustering: ClustGeo\nUsing the hclustgeo() of the ClustGeo package, we will create a cluster with the earlier proximity matrix:\n\nnongeo_cluster <- hclustgeo(proxmat)\n\nNext, we will plot the deprogram as follow:\n(we will set k=6 for 6 clusters)\n\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\nWe create a group factor as follow:\n\ngroups <- as.factor(cutree(nongeo_cluster, k=6))\n\nNext we will convert the earlier created object to a matrix and add it to the main data:\n\nshan_sf_ngeo_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can then plot the cluster as follow:\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")"
  },
  {
    "objectID": "in_class/ex_3/ex_3.html#spatially-constrained-hierarchical-clustering",
    "href": "in_class/ex_3/ex_3.html#spatially-constrained-hierarchical-clustering",
    "title": "In-Class ex 3 - Adding in ClustGeo for Chap 5 Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Spatially constrained Hierarchical Clustering:",
    "text": "Spatially constrained Hierarchical Clustering:\nWe first need to derive a spatial distance matrix with the st_distance() of the sf package:\n\ndist <- st_distance(shan_sf, shan_sf)\n\nNext, we will convert the earlier output to a matrix:\n\ndistmat <- as.dist(dist)\n\nNext, we will use the choicealpha() to determine the optimal “alpha” value to be used:\n\ncr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\nOnce we have chosen the alpha = 0.3, we will use hclustgeo() once more:\n\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nThen we derive the cluster object:\n\ngroups <- as.factor(cutree(clustG, k=6))\n\nWe then join the value back to the dataframe:\n\nshan_sf_Gcluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can then plot the newly delineated spatially constrained clusters:\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "in_class/ex_5/ex_5.html",
    "href": "in_class/ex_5/ex_5.html",
    "title": "In Class Ex5 - Spatially Weighted Regression",
    "section": "",
    "text": "Packages used:\n\nhere: used to generate the file path to a specific folder\ntidyverse\n\nreadr: for reading rectangular files\n\nsf: Used to handle spatial dataframes\nfunModeling: Used for plotting and EDA\ntmap: Use for plotting geo spatial maps\nskimr: provides summary statistics about variables in the dataframe\ncorrplot: Used for performing correlation analysis\nblorr: Used to generate a report for our logistic regression model"
  },
  {
    "objectID": "in_class/ex_5/ex_5.html#logistic-regression-model",
    "href": "in_class/ex_5/ex_5.html#logistic-regression-model",
    "title": "In Class Ex5 - Spatially Weighted Regression",
    "section": "Logistic Regression Model",
    "text": "Logistic Regression Model\nUsing the glm() of the R statistics, we build a logistic regression model as follow:\n\nmodel <- glm(status ~ distance_to_primary_road +\n               distance_to_secondary_road + \n               distance_to_tertiary_road + \n               distance_to_city + \n               distance_to_town + \n               is_urban +\n               usage_capacity + \n               water_source_clean + \n               water_point_population + \n               local_population_1km,\n             # data = osun_wp_sf_clean,\n             data = osun_wp, \n             family = binomial(link = \"logit\"))"
  },
  {
    "objectID": "in_class/ex_5/ex_5.html#model-report",
    "href": "in_class/ex_5/ex_5.html#model-report",
    "title": "In Class Ex5 - Spatially Weighted Regression",
    "section": "Model Report",
    "text": "Model Report\nNext we use blr_regress() of blorr to provide us a report on our model:\n\nblr_regress(model)\n\n                             Model Overview                              \n------------------------------------------------------------------------\nData Set    Resp Var    Obs.    Df. Model    Df. Residual    Convergence \n------------------------------------------------------------------------\n  data       status     4756      4755           4744           TRUE     \n------------------------------------------------------------------------\n\n                    Response Summary                     \n--------------------------------------------------------\nOutcome        Frequency        Outcome        Frequency \n--------------------------------------------------------\n   0             2114              1             2642    \n--------------------------------------------------------\n\n                                 Maximum Likelihood Estimates                                   \n-----------------------------------------------------------------------------------------------\n               Parameter                    DF    Estimate    Std. Error    z value     Pr(>|z|) \n-----------------------------------------------------------------------------------------------\n              (Intercept)                   1      0.3887        0.1124      3.4588       5e-04 \n        distance_to_primary_road            1      0.0000        0.0000     -0.7153      0.4744 \n       distance_to_secondary_road           1      0.0000        0.0000     -0.5530      0.5802 \n       distance_to_tertiary_road            1      1e-04         0.0000      4.6708      0.0000 \n            distance_to_city                1      0.0000        0.0000     -4.7574      0.0000 \n            distance_to_town                1      0.0000        0.0000     -4.9170      0.0000 \n              is_urbanTRUE                  1     -0.2971        0.0819     -3.6294       3e-04 \n           usage_capacity1000               1     -0.6230        0.0697     -8.9366      0.0000 \nwater_source_cleanProtected Shallow Well    1      0.5040        0.0857      5.8783      0.0000 \n   water_source_cleanProtected Spring       1      1.2882        0.4388      2.9359      0.0033 \n         water_point_population             1      -5e-04        0.0000    -11.3686      0.0000 \n          local_population_1km              1      3e-04         0.0000     19.2953      0.0000 \n-----------------------------------------------------------------------------------------------\n\n Association of Predicted Probabilities and Observed Responses  \n---------------------------------------------------------------\n% Concordant          0.7347          Somers' D        0.4693   \n% Discordant          0.2653          Gamma            0.4693   \n% Tied                0.0000          Tau-a            0.2318   \nPairs                5585188          c                0.7347   \n---------------------------------------------------------------\n\n\nThe report shows us that at 95% confidence level, all the variables are significant except distance to primary road and the distance to secondary road.\nNote from class:\n\nCategorical variable z value: +ve value implies above average correlation while -ve value implies a below average correlation.\nContinuous variable z value: +ve value implies direct correlation while -ve value implies inverse correlation."
  },
  {
    "objectID": "in_class/ex_5/ex_5.html#confusion-matrix",
    "href": "in_class/ex_5/ex_5.html#confusion-matrix",
    "title": "In Class Ex5 - Spatially Weighted Regression",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\nNext, using blr_confusion_matrix() of blorr, we generate a confusion matrix as follow:\n\nblr_confusion_matrix(model, cutoff=0.5)\n\nConfusion Matrix and Statistics \n\n          Reference\nPrediction FALSE TRUE\n         0  1301  738\n         1   813 1904\n\n                Accuracy : 0.6739 \n     No Information Rate : 0.4445 \n\n                   Kappa : 0.3373 \n\nMcNemars's Test P-Value  : 0.0602 \n\n             Sensitivity : 0.7207 \n             Specificity : 0.6154 \n          Pos Pred Value : 0.7008 \n          Neg Pred Value : 0.6381 \n              Prevalence : 0.5555 \n          Detection Rate : 0.4003 \n    Detection Prevalence : 0.5713 \n       Balanced Accuracy : 0.6680 \n               Precision : 0.7008 \n                  Recall : 0.7207 \n\n        'Positive' Class : 1\n\n\nNotes from class:\nThe cutoff value of 0.5 means that any probability above 0.5 gets classified as true, while other values get classified as false. The default value we generally use is 0.5.\n\nSensitivity: TP/(TP/FN) >> 0.7207\nSpecificity: TN/(TN+FP) >> 0.6154\nAccuracy: (TP+TN)/(TP+FP+TN+FN)\n\nSince sensitivity is higher than the specificity, our model is better at catching true positives than catching true negatives."
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#import-nigeria-water-point-data-file",
    "href": "take_home_ex/ex_1/ex_1.html#import-nigeria-water-point-data-file",
    "title": "Take Home Ex-1",
    "section": "Import Nigeria water point data-file:",
    "text": "Import Nigeria water point data-file:\nGenerate a path:\nWe use the here function to generate a specific file path on the root folder.\n\nshapefile_path <- here(\"data\", \"dataNigeria\", \"geospatial\")\nshapefile_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria/geospatial\"\n\n\nSome useful link for the CRS:\n\nhttps://datacarpentry.org/organization-geospatial/03-crs/\nhttps://www.nceas.ucsb.edu/sites/default/files/2020-04/OverviewCoordinateReferenceSystems.pdf\n\nst_read() belongs to the sf package. It reads simple features from file or database. Simple features or simple feature access refers to formal standard ISO 19125-1:2004 that describes how real world data can be represented in computers, with emphasis on the spatial geometry of these objects. Link below:\nhttps://cran.r-project.org/web/packages/sf/vignettes/sf1.html#:~:text=Simple%20features%20or%20simple%20feature,spatial%20geometry%20of%20these%20objects.\nTo find the CRS of the shapefile, open the .prj file as a text. It will tell you which projection system is being used.\nRead the shapefile using st_read() belonging to the sf package:\nThe data read will be saved as a simple feature data table.\nWe will use the filter() function of dplyr package to filter only rows for Nigeria\n\n# wp <- st_read(\n#   dsn = shapefile_path,\n#   layer = \"geo_export\",\n#   crs = 4326) %>%\n#   filter(clean_coun == \"Nigeria\")\n\nGenerate the save path using here function:\n\nsavefile_path <- here(\"data\", \"dataNigeria\", \"geospatial\", \"wp_nga.rds\")\nsavefile_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria/geospatial/wp_nga.rds\"\n\n\nWe will next save the file using write_rds() of the tidyverse package:\nrds is a native data format of R.\n\n# wp_ng <- write_rds(wp, savefile_path)"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#import-nigeria-geo-boundary-file",
    "href": "take_home_ex/ex_1/ex_1.html#import-nigeria-geo-boundary-file",
    "title": "Take Home Ex-1",
    "section": "Import Nigeria geo-boundary file:",
    "text": "Import Nigeria geo-boundary file:\nNext we will make the path to the geo boundary file:\n\nshapefile_path <- here(\"data\", \"dataNigeria\", \"boundary\")\nshapefile_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria/boundary\"\n\n\nNext we will Import the Nigeria LGA Boundary Data with st_read() function:\nThe imported data will be saved as a simple features dataset.\n\nnga <- st_read(\n  dsn = shapefile_path,\n  layer = \"geoBoundaries-NGA-ADM2\",\n  crs = 4326)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `D:\\f4sared\\ISSS624\\data\\dataNigeria\\boundary' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#downsize-further-the-wp_nga-data",
    "href": "take_home_ex/ex_1/ex_1.html#downsize-further-the-wp_nga-data",
    "title": "Take Home Ex-1",
    "section": "Downsize further the wp_nga data:",
    "text": "Downsize further the wp_nga data:\nLoad the previously saved data:\nWe will select specific columns using select().\n\n# final <- read_rds(rdsfile_path) %>% select(1:2, 14:17, 23)\n\nCreate the path for saving the file\n\n# savefile_path <- here(\"data\", \"dataNigeria\", \"geospatial\", \"wp_nga_v2.rds\")\n# savefile_path\n\nSave the file:\n\n# write_rds(final, savefile_path)"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#visualize-initial-distribution",
    "href": "take_home_ex/ex_1/ex_1.html#visualize-initial-distribution",
    "title": "Take Home Ex-1",
    "section": "Visualize Initial distribution",
    "text": "Visualize Initial distribution\nGenerate path to rds file saved previously:\n\nrdsfile_path <- here(\"data\", \"dataNigeria\", \"geospatial\",\"wp_nga_v2.rds\")\nrdsfile_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria/geospatial/wp_nga_v2.rds\"\n\n\nLoad the rds file with read_rds() function of the tidyverse package:\nWe will also make use of the piping to replace the “na” values with “unknown”.\nmutate() is a function of the dplyr package.\n\nwp_nga <- read_rds(rdsfile_path) %>%\n  mutate(status_cle = replace_na(status_cle, \"Unknown\"))\n\nCheck the CRS of the spatial datafile with st_crs():\n\nst_crs(wp_nga)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\nUse the freq() of the funModeling package to show the distribution percentage of status_cle:\n\nfreq(data=wp_nga,\n     input = 'status_cle')\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n                        status_cle frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                          Unknown     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#filter-for-functional-water-points",
    "href": "take_home_ex/ex_1/ex_1.html#filter-for-functional-water-points",
    "title": "Take Home Ex-1",
    "section": "Filter for functional water-points:",
    "text": "Filter for functional water-points:\nHere we will use the filter() function from the dplyr package to select “functional” rows only:\nWe use the %in% to denote the membership in the group of strings.\n\nwpt_functional <- wp_nga %>%\n  filter(status_cle %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nThen we will plot with freq() function from funModeling to show the distribution:\n\nfreq(data=wpt_functional, \n     input = 'status_cle')\n\n\n\n\n                   status_cle frequency percentage cumulative_perc\n1                  Functional     45883      87.99           87.99\n2 Functional but needs repair      4579       8.78           96.77\n3   Functional but not in use      1686       3.23          100.00"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#filter-for-non-functional",
    "href": "take_home_ex/ex_1/ex_1.html#filter-for-non-functional",
    "title": "Take Home Ex-1",
    "section": "Filter for non-functional",
    "text": "Filter for non-functional\nFilter for non-functional rows:\nUse %in% for to select rows that fall into the specific categories.\n\nwpt_nonfunctional <- wp_nga %>%\n  filter(status_cle %in%\n           c(\"Abandoned/Decommissioned\", \n             \"Abandoned\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\",\n             \"Non-Functional due to dry season\"))\n\nPlot the distribution with the freq() function:\n\nfreq(data=wpt_nonfunctional, \n     input = 'status_cle')\n\n\n\n\n                        status_cle frequency percentage cumulative_perc\n1                   Non-Functional     29385      91.25           91.25\n2 Non-Functional due to dry season      2403       7.46           98.71\n3         Abandoned/Decommissioned       234       0.73           99.44\n4                        Abandoned       175       0.54           99.98\n5 Non functional due to dry season         7       0.02          100.00"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#filter-for-unknown",
    "href": "take_home_ex/ex_1/ex_1.html#filter-for-unknown",
    "title": "Take Home Ex-1",
    "section": "Filter for unknown:",
    "text": "Filter for unknown:\nLastly we filter for the rows that have unknown status:\n\nwpt_unknown <- wp_nga %>%\n  filter(status_cle == \"Unknown\")"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#perform-data-manipulation-point-in-polygon",
    "href": "take_home_ex/ex_1/ex_1.html#perform-data-manipulation-point-in-polygon",
    "title": "Take Home Ex-1",
    "section": "Perform data manipulation (Point-In-Polygon):",
    "text": "Perform data manipulation (Point-In-Polygon):\nUsing st_intersects, we will be able to create a list of rows from wp_nga that intersects each row of nga.\nFor the intersection to work, st_intersect will check if each point falls within the polygon of nga.\nNext we use the lengths() function to count the number of instances. Then we append to a new column.\nWe repeat this step across all 3 categories of Functional, Non-Functional & Unknown:\n\nnga_wp <- nga %>%\n  mutate(`total wpt` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wpt functional` = lengths(\n    st_intersects(nga, wpt_functional))) %>%\n  mutate(`wpt non-functional` = lengths(\n    st_intersects(nga, wpt_nonfunctional))) %>%\n  mutate(`wpt unknown` = lengths(\n    st_intersects(nga, wpt_unknown)))\n\nNext, using the mutate() function of dplyr, we will create 2 new columns:\n\npct_functional = `wpt functional`/`total wpt`\npct_non-functional = `wpt non-functional`/`total wpt`\n\nWe will then use select() of dplyr to retain the fields that we require.\n\nnga_wp <- nga_wp %>%\n  mutate(pct_functional = `wpt functional`/`total wpt`) %>%\n  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`) \n\nWe will then create a save file path:\n\nsavefile_path <- here(\"data\", \"dataNigeria\", \"geospatial\", \"nga_wp.rds\")\nsavefile_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria/geospatial/nga_wp.rds\"\n\n\nNext we will save this final dataframe using write_rds() of tidyverse package:\n\nwrite_rds(nga_wp, savefile_path)"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#plotting-with-qtm",
    "href": "take_home_ex/ex_1/ex_1.html#plotting-with-qtm",
    "title": "Take Home Ex-1",
    "section": "Plotting with qtm()",
    "text": "Plotting with qtm()\nSet the tmap mode to “view” for interactive mode. Else set to “plot”.\nqtm() represents quick plotting with tmap package:\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(nga_wp_26391, \n    fill = \"wpt non-functional\")"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#plotting-with-tmap",
    "href": "take_home_ex/ex_1/ex_1.html#plotting-with-tmap",
    "title": "Take Home Ex-1",
    "section": "Plotting with tmap()",
    "text": "Plotting with tmap()\n\nJenks:\nJenks: Identify groups with similar values and maximizes the difference between them.\nUsing interactive tmap(), we will plot using “jenks” classification:\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(nga_wp_26391)+\n  tm_fill(c(\"wpt non-functional\", \"wpt functional\"),\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing the “jenks” style, we are able to identify visually some areas with high value already.\n\n\n\nQuantile:\nSplits variables in quantiles, Consequently there are same number of observations in each interval.\nUsing interactive tmap(), we will plot using “quantile” classification:\n\ntm_shape(nga_wp_26391)+\n  tm_fill(c(\"wpt non-functional\", \"wpt functional\"),\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen using “quantile” style, we observed a surge in the darker area. Having a closer look at the quantile, we can see that the last quantile has a much bigger band, this mean that quantile may not be too suitable.\n\n\n\nEqual:\nWe will then consider an alternative “equal”:\n\ntm_shape(nga_wp_26391)+\n  tm_fill(c(\"wpt non-functional\", \"wpt functional\"),\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis distribution above matches that of the “jenks” style. We can spot similar patterns on the plot.\n\nWe will use bbox to get better visuals:\nhttps://stackoverflow.com/questions/60892033/how-do-you-position-the-title-and-legend-in-tmap\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n# make some bbox magic\nbbox_new <- st_bbox(nga_wp_26391)\nxrange <- bbox_new$xmax - bbox_new$xmin # range of x values\nyrange <- bbox_new$ymax - bbox_new$ymin # range of y values\n# bbox_new[1] <- bbox_new[1] - (0.25 * xrange) # xmin - left\nbbox_new[3] <- bbox_new[3] + (0.75 * xrange) # xmax - right\n# bbox_new[2] <- bbox_new[2] - (0.25 * yrange) # ymin - bottom\nbbox_new[4] <- bbox_new[4] + (0.01 * yrange) # ymax - top\nbbox_new <- bbox_new %>%  # take the bounding box ...\n  st_as_sfc() # ... and make it a sf polygon\n\n\ntm_shape(nga_wp_26391, bbox = bbox_new)+\n  tm_fill(\"wpt non-functional\", \n          style = \"jenks\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(alpha = 0.5) + \n  tm_layout(main.title = \"Jenks Plot of WPT Non-Functional\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"center\"),\n            frame = TRUE) + \n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.2, position= c(\"center\", \"bottom\")) +\n  tm_grid(lwd = 0.1, alpha = 0.2) \n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n# make some bbox magic\nbbox_new <- st_bbox(nga_wp_26391)\nxrange <- bbox_new$xmax - bbox_new$xmin # range of x values\nyrange <- bbox_new$ymax - bbox_new$ymin # range of y values\n# bbox_new[1] <- bbox_new[1] - (0.25 * xrange) # xmin - left\nbbox_new[3] <- bbox_new[3] + (0.75 * xrange) # xmax - right\n# bbox_new[2] <- bbox_new[2] - (0.25 * yrange) # ymin - bottom\nbbox_new[4] <- bbox_new[4] + (0.01 * yrange) # ymax - top\nbbox_new <- bbox_new %>%  # take the bounding box ...\n  st_as_sfc() # ... and make it a sf polygon\n\n\ntm_shape(nga_wp_26391, bbox = bbox_new)+\n  tm_fill(\"wpt functional\", \n          style = \"jenks\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(alpha = 0.5) + \n  tm_layout(main.title = \"Jenks Plot of WPT Non-Functional\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"center\"),\n            frame = TRUE) + \n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.2, position= c(\"center\", \"bottom\")) +\n  tm_grid(lwd = 0.1, alpha = 0.2)"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#prepare-the-coordinates",
    "href": "take_home_ex/ex_1/ex_1.html#prepare-the-coordinates",
    "title": "Take Home Ex-1",
    "section": "Prepare the coordinates",
    "text": "Prepare the coordinates\nIn order to work with fixed distance weight matrix, we need to prepare the coordinates of the center of gravity (COG) for all the polygons.\nTo achieve this, we will need to pass the column “geometry” into the function st_centroid() from the sf package. This function will calculate the COG and return us the coordinates accordingly. We will also make use of the map_dbl() function from the purrr package to apply the st_centroid() function to row.\nLongitude:\n\nlongitude <- map_dbl(nga_wp_26391$geometry, ~st_centroid(.x)[[1]])\n\nLatitude:\n\nlatitude <- map_dbl(nga_wp_26391$geometry, ~st_centroid(.x)[[2]])\n\nNext, we will use the function of cbind() from the base package to bind our coordinates together.\nBind long & lat:\n\ncoords <- cbind(longitude, latitude)\n\nCheck if output is correct:\n\nhead(coords)\n\n     longitude  latitude\n[1,]  549364.0  123694.9\n[2,]  547123.4  120376.5\n[3,] 1189496.9 1059770.9\n[4,]  489057.4  534262.6\n[5,]  593718.2  113824.1\n[6,]  642618.7  251222.3"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#determine-cut-off-distance",
    "href": "take_home_ex/ex_1/ex_1.html#determine-cut-off-distance",
    "title": "Take Home Ex-1",
    "section": "Determine cut off distance:",
    "text": "Determine cut off distance:\nIn order to ensure that each polygon has at least 1 neighbor, we need to determine the cut off distance. To do this, we will first run the k-nearest neighbor with k=1. This is achieved with the function of knearneigh() of the spdep package.\nWe run the code as follow:\n\nk1 <- knn2nb(knearneigh(coords))\n\nAfter obtaining k1, a list of 774 polygons where each row shows the nearest neighbor polygon ID, we next need to calculate the distance between all of them using nbdists() of spdep.\nNext, in order to calculate the summary, we need then to unlist() the output of nbdists(). This is then followed by using the summary() function which reports to us the max distance for us to use.\nWe run the code as follow:\n\nk1dists <- unlist(nbdists(k1, coords, longlat = FALSE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2669   12834   20304   22084   27783   72139 \n\n\nFrom the above summary, it shows that the minimum distance for every polygon to have a neighbor is 71.661, thus we will use the value 72140."
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#compute-the-fixed-distance-neighbor-list",
    "href": "take_home_ex/ex_1/ex_1.html#compute-the-fixed-distance-neighbor-list",
    "title": "Take Home Ex-1",
    "section": "Compute the fixed distance neighbor list:",
    "text": "Compute the fixed distance neighbor list:\nWith the above information, we will then compute the fixed distance weight matrix using dnearneigh() function from spdep. For this to work, we will need the coordinate of the polygons, min dist & max dist.\nWe will run the code as follow, this will give us a nb (neighbor) object data wm_d72:\n\nnb_d72 <- dnearneigh(coords, 0, 72140, longlat = FALSE)\nnb_d72\n\nNeighbour list object:\nNumber of regions: 774 \nNumber of nonzero links: 18130 \nPercentage nonzero weights: 3.026327 \nAverage number of links: 23.42377 \n\n\nNext, we will display our results for viewing:\n\nstr(nb_d72)\n\nList of 774\n $ : int [1:63] 2 5 10 25 55 66 68 103 122 181 ...\n $ : int [1:62] 1 5 10 25 55 66 68 103 122 181 ...\n $ : int [1:2] 261 447\n $ : int [1:10] 12 20 257 263 446 454 466 641 690 695\n $ : int [1:56] 1 2 55 66 104 136 137 169 184 202 ...\n $ : int [1:21] 9 14 18 19 56 170 217 218 330 337 ...\n $ : int [1:19] 8 15 22 176 177 214 281 282 283 295 ...\n $ : int [1:32] 7 15 22 49 176 177 214 275 276 277 ...\n $ : int [1:26] 6 18 19 56 66 77 103 104 217 218 ...\n $ : int [1:64] 1 2 23 25 66 103 181 190 191 203 ...\n $ : int [1:22] 26 27 43 68 126 157 190 191 204 336 ...\n $ : int [1:11] 4 135 257 263 401 417 429 446 454 690 ...\n $ : int [1:13] 31 37 38 40 94 211 320 393 436 471 ...\n $ : int [1:24] 6 170 193 194 195 217 309 310 311 362 ...\n $ : int [1:27] 7 8 22 32 49 51 62 82 176 177 ...\n $ : int [1:37] 30 38 39 41 44 45 70 71 120 124 ...\n $ : int [1:34] 28 29 35 72 172 173 178 179 182 275 ...\n $ : int [1:29] 6 9 19 56 66 77 103 104 217 218 ...\n $ : int [1:41] 6 9 18 25 56 66 77 103 104 181 ...\n $ : int [1:7] 4 106 239 263 419 454 466\n $ : int [1:9] 60 61 162 269 484 520 578 596 626\n $ : int [1:31] 7 8 15 32 49 51 62 82 176 177 ...\n $ : int [1:64] 10 25 52 53 54 56 58 77 78 79 ...\n $ : int [1:5] 123 476 527 673 761\n $ : int [1:68] 1 2 10 19 23 54 56 66 77 103 ...\n $ : int [1:30] 11 27 43 68 157 190 191 204 336 370 ...\n $ : int [1:24] 11 26 43 68 157 191 204 336 370 371 ...\n $ : int [1:43] 17 29 35 70 71 124 172 173 178 179 ...\n $ : int [1:45] 17 28 35 70 71 124 172 173 178 179 ...\n $ : int [1:30] 16 38 39 40 41 44 45 175 185 186 ...\n $ : int [1:13] 13 37 94 158 210 211 212 289 308 561 ...\n $ : int [1:28] 15 22 49 51 62 82 177 196 207 214 ...\n $ : int [1:29] 47 111 130 142 145 155 166 219 227 233 ...\n $ : int [1:11] 42 86 104 136 137 213 375 553 559 733 ...\n $ : int [1:33] 17 28 29 72 172 173 178 179 182 275 ...\n $ : int [1:8] 50 107 247 408 432 455 681 759\n $ : int [1:21] 13 31 38 39 40 41 186 192 197 198 ...\n $ : int [1:25] 13 16 30 37 39 40 41 44 186 192 ...\n $ : int [1:27] 16 30 37 38 40 41 44 185 186 192 ...\n $ : int [1:21] 13 30 37 38 39 41 44 186 192 211 ...\n $ : int [1:22] 16 30 37 38 39 40 44 45 186 192 ...\n $ : int [1:20] 34 86 136 137 184 202 285 286 375 499 ...\n $ : int [1:19] 11 26 27 68 122 126 157 190 191 246 ...\n $ : int [1:27] 16 30 38 39 40 41 45 70 175 186 ...\n $ : int [1:27] 16 30 41 44 70 175 187 188 192 290 ...\n $ : int [1:12] 119 380 387 417 423 429 438 459 521 656 ...\n $ : int [1:24] 33 111 127 130 155 166 227 234 238 242 ...\n $ : int [1:12] 64 65 74 113 131 265 386 407 428 482 ...\n $ : int [1:30] 8 15 22 32 51 62 82 176 177 207 ...\n $ : int [1:4] 36 107 409 432\n $ : int [1:27] 15 22 32 49 62 82 177 207 214 284 ...\n $ : int [1:47] 23 53 54 57 58 77 78 79 80 165 ...\n $ : int [1:37] 23 52 54 57 58 78 79 80 165 189 ...\n $ : int [1:58] 23 25 52 53 56 57 58 77 78 79 ...\n $ : int [1:33] 1 2 5 68 122 157 169 184 190 208 ...\n $ : int [1:51] 6 9 18 19 23 25 54 66 77 78 ...\n $ : int [1:35] 52 53 54 58 78 79 80 165 189 197 ...\n $ : int [1:37] 23 52 53 54 57 78 79 165 189 197 ...\n $ : int [1:5] 128 129 493 700 748\n $ : int [1:14] 21 61 158 269 310 311 561 563 578 589 ...\n $ : int [1:11] 21 60 162 268 269 484 578 589 592 596 ...\n $ : int [1:28] 15 22 32 49 51 82 177 196 207 214 ...\n $ : int [1:5] 384 416 467 765 772\n $ : int [1:7] 48 65 74 113 131 265 407\n $ : int [1:11] 48 64 74 109 113 265 386 407 683 701 ...\n $ : int [1:47] 1 2 5 9 10 18 19 25 56 103 ...\n $ : int [1:26] 72 120 124 179 182 304 305 339 346 347 ...\n $ : int [1:30] 1 2 11 26 27 43 55 122 157 190 ...\n $ : int [1:8] 140 146 248 274 473 500 512 513\n $ : int [1:44] 16 28 29 44 45 71 120 124 172 173 ...\n $ : int [1:50] 16 28 29 70 120 124 172 173 175 178 ...\n $ : int [1:19] 17 35 67 182 361 374 378 404 566 567 ...\n $ : int [1:6] 361 374 377 404 665 666\n $ : int [1:14] 48 64 65 109 113 116 251 265 672 683 ...\n $ : int [1:15] 110 229 255 258 272 373 382 398 422 433 ...\n $ : int [1:9] 254 287 427 459 470 547 647 677 751\n $ : int [1:55] 9 18 19 23 25 52 54 56 78 79 ...\n $ : int [1:51] 23 52 53 54 56 57 58 77 79 80 ...\n $ : int [1:57] 23 52 53 54 56 57 58 77 78 80 ...\n $ : int [1:39] 23 52 53 54 57 77 78 79 165 189 ...\n $ : int [1:19] 99 145 227 233 242 255 270 426 449 483 ...\n $ : int [1:21] 15 22 32 49 51 62 177 207 214 297 ...\n $ : int [1:6] 132 258 383 414 529 767\n $ : int [1:3] 148 437 692\n $ : int [1:38] 101 105 130 142 145 155 156 219 235 242 ...\n $ : int [1:17] 34 42 136 137 184 202 285 286 499 538 ...\n $ : int [1:19] 147 149 151 221 226 245 267 399 410 415 ...\n $ : int [1:5] 150 489 648 700 714\n $ : int [1:11] 100 107 159 260 408 463 542 674 676 681 ...\n $ : int 237\n $ : int [1:3] 160 271 406\n $ : int [1:11] 95 119 390 391 392 423 487 642 656 668 ...\n $ : int [1:3] 354 607 665\n $ : int [1:7] 13 31 158 436 561 596 709\n $ : int [1:10] 92 390 391 392 405 423 469 656 708 770\n $ : int [1:17] 97 108 139 167 168 350 389 403 412 420 ...\n $ : int [1:13] 96 108 114 139 147 168 389 403 420 451 ...\n $ : int [1:4] 153 231 432 696\n $ : int [1:18] 81 145 154 167 227 233 255 270 426 449 ...\n  [list output truncated]\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:774] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 72140, longlat = FALSE)\n - attr(*, \"dnn\")= num [1:2] 0 72140\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#plot-the-fixed-distance-neighbor-list",
    "href": "take_home_ex/ex_1/ex_1.html#plot-the-fixed-distance-neighbor-list",
    "title": "Take Home Ex-1",
    "section": "Plot the fixed distance neighbor list:",
    "text": "Plot the fixed distance neighbor list:\nUsing the plot() function, we will then visualize the neighbors that we have identified.\n\nplot(nga_wp_26391$geometry, border=\"black\", axes = TRUE)\nplot(nb_d72, coords, add=TRUE, col=\"red\")"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#create-row-standardized-weight-matrix",
    "href": "take_home_ex/ex_1/ex_1.html#create-row-standardized-weight-matrix",
    "title": "Take Home Ex-1",
    "section": "Create row standardized weight matrix",
    "text": "Create row standardized weight matrix\nWe will use the nb2listw() function of spdep package to convert the nb list to weights. We set the style to “W” in order to perform the row-standardized steps.\nWe run the code as follow:\n\nswm_d72<- nb2listw(nb_d72, style=\"W\", zero.policy = TRUE)"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#compute-spatial-lag-with-row-standardized-weights",
    "href": "take_home_ex/ex_1/ex_1.html#compute-spatial-lag-with-row-standardized-weights",
    "title": "Take Home Ex-1",
    "section": "Compute spatial lag with row-standardized weights",
    "text": "Compute spatial lag with row-standardized weights\nNow we will use the lag.listw() function from spdep to return us the lag list. As an input, we will provide the row-standardized weight matrix and the variables “wpt non-functional” & wpt functional.\n\nLag for non-functional\nWe run the code as follow:\n\nlag.list <- list(nga_wp_26391$shapeName, lag.listw(swm_d72, nga_wp_26391$`wpt non-functional`))\nlag.res_NF <- as.data.frame(lag.list)\ncolnames(lag.res_NF) <- c(\"shapeName\", \"lag_NF\")\nnga_wp_26391$lag_NF <- lag.res_NF$lag_NF\n\nWe will then plot the lagged variable:\n\nnon_func <- qtm(nga_wp_26391, \"wpt non-functional\") +\ntm_layout(main.title = \"WPT Non-Functional\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.width = 0.3,\n            legend.height = 0.25,\n            frame = TRUE)\nlag_non_func <- qtm(nga_wp_26391, \"lag_NF\")+\ntm_layout(main.title = \"Lagged WPT Non-Functional\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.width = 0.3,\n            legend.height = 0.25,\n            frame = TRUE)\ntmap_arrange(non_func, lag_non_func, asp=1, ncol=2)\n\n\n\n\n\n\nLag for functional\nWe run the code as follow:\n\nlag.list <- list(nga_wp_26391$shapeName, lag.listw(swm_d72, nga_wp_26391$`wpt functional`))\nlag.res_F <- as.data.frame(lag.list)\ncolnames(lag.res_F) <- c(\"shapeName\", \"lag_F\")\nnga_wp_26391$lag_F <- lag.res_F$lag_F\n\n\nnon_func <- qtm(nga_wp_26391, \"wpt functional\") +\ntm_layout(main.title = \"WPT Functional\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.width = 0.3,\n            legend.height = 0.25,\n            frame = TRUE)\nlag_non_func <- qtm(nga_wp_26391, \"lag_F\")+\ntm_layout(main.title = \"Lagged WPT Functional\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            legend.width = 0.3,\n            legend.height = 0.25,\n            frame = TRUE)\ntmap_arrange(non_func, lag_non_func, asp=1, ncol=2)"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#global-morans-i",
    "href": "take_home_ex/ex_1/ex_1.html#global-morans-i",
    "title": "Take Home Ex-1",
    "section": "Global Moran’s I",
    "text": "Global Moran’s I\nTo get an indication of the global spatial clustering auto-correlation, we will perform the Moran’s I test. This is an analytic approach.\nWPT Non-Functional Moran’s I test:\n\nmoran.test(nga_wp_26391$`wpt non-functional`,\n           listw=swm_d72,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  nga_wp_26391$`wpt non-functional`  \nweights: swm_d72    \n\nMoran I statistic standard deviate = 22.437, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.3264059335     -0.0012936611      0.0002133094 \n\n\nThe global Moran’s I statistic is >> 0 and the p-value is statistically significant. This shows that there is indication of clustering of the non-functional water point.\n\nWPT Functional Moran’s I test:\n\nmoran.test(nga_wp_26391$`wpt functional`,\n           listw=swm_d72,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  nga_wp_26391$`wpt functional`  \nweights: swm_d72    \n\nMoran I statistic standard deviate = 34.908, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.5041687788     -0.0012936611      0.0002096643 \n\n\nThe global Moran’s I statistic is >> 0 and the p-value is statistically significant. This shows that there is indication of clustering of the functional water point."
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#monte-carlo-morans-i",
    "href": "take_home_ex/ex_1/ex_1.html#monte-carlo-morans-i",
    "title": "Take Home Ex-1",
    "section": "Monte Carlo Moran’s I",
    "text": "Monte Carlo Moran’s I\nWhile the Moran’s I test is fast since it works analytically, we will need to perform Monte Carlo Moran’s I. This method allows us to perform simulation by generating many random datasets across multiple simulations.\nOur Moran’s I should fall to either extremes of the Moran’s I histogram from the simulation. This shows that our Moran’s I value did not occur because of randomization.\nFor the Monte Carlo Moran’s I test, we will use the moran.mc() function from the spdep package.\nWPT Non-Functional Moran’s I test:\n\nset.seed(1234)\nbperm_NF= moran.mc(nga_wp_26391$`wpt non-functional`, \n                listw=swm_d72, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm_NF\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  nga_wp_26391$`wpt non-functional` \nweights: swm_d72  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.32641, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nHere we can see that our results are statistically significant with p value of 0.001. Also the Moran’s I calculated is similar to the analytic test.\nWe will visualize the simulation results from Monte Carlo as follow:\n\nhist(bperm_NF$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I for Non-Functional\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\nWPT Functional Moran’s I test:\n\nset.seed(1234)\nbperm_F= moran.mc(nga_wp_26391$`wpt functional`, \n                listw=swm_d72, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm_F\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  nga_wp_26391$`wpt functional` \nweights: swm_d72  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.50417, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nHere we can see that our results are statistically significant with p value of 0.001. Also the Moran’s I calculated is similar to the analytic test.\nWe will visualize the simulation results from Monte Carlo as follow:\n\nhist(bperm_F$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I for Non-Functional\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#non-functional-water-points-local-morans-i",
    "href": "take_home_ex/ex_1/ex_1.html#non-functional-water-points-local-morans-i",
    "title": "Take Home Ex-1",
    "section": "Non-Functional Water Points (Local Moran’s I)",
    "text": "Non-Functional Water Points (Local Moran’s I)\nWe will use the function order() to create an ordered name list of the areas. This is then followed by the function localmoran() from spdep. Our variable of interest and row-standardized weight matrix is required.\n\nlocalMI_NF <- localmoran(nga_wp_26391$`wpt non-functional`, swm_d72)\nhead(localMI_NF)\n\n            Ii          E.Ii       Var.Ii       Z.Ii Pr(z != E(Ii))\n1  0.361394136 -9.995243e-04 1.128237e-02  3.4117747   0.0006454144\n2  0.074414950 -4.092463e-05 4.705097e-04  3.4325327   0.0005979717\n3  1.258199847 -1.627684e-03 6.280738e-01  1.5896655   0.1119102304\n4 -0.006652507 -5.427505e-05 4.151689e-03 -0.1024036   0.9184363392\n5  0.082615173 -2.590965e-04 3.325093e-03  1.4372021   0.1506605779\n6  0.006672593 -1.538445e-07 5.523369e-06  2.8392431   0.0045220690\n\n\n\nlocalMI_NF <- data.frame(localMI_NF)\ncolnames(localMI_NF)[5] =\"Pr\"\nnga_wp_26391$lc_Ii_NF <- localMI_NF$'Ii'\nnga_wp_26391$lc_Pr_NF <- localMI_NF$'Pr'\n\n\nlocalMI.map_NF <- tm_shape(nga_wp_26391) +\n  tm_fill(col = \"lc_Ii_NF\", \n          style = \"jenks\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Plot of Local Moran's I\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = TRUE)\n\npvalue.map_NF <- tm_shape(nga_wp_26391) +\n  tm_fill(col = \"lc_Pr_NF\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Plot of Local Moran's I P-Value\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = TRUE)\n\ntmap_arrange(localMI.map_NF, pvalue.map_NF, asp=1, ncol=2)\n\nVariable(s) \"lc_Ii_NF\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#functional-water-points-local-morans-i",
    "href": "take_home_ex/ex_1/ex_1.html#functional-water-points-local-morans-i",
    "title": "Take Home Ex-1",
    "section": "Functional Water Points (Local Moran’s I)",
    "text": "Functional Water Points (Local Moran’s I)\nWe perform the same steps for Functional water points:\n\nlocalMI_F <- localmoran(nga_wp_26391$`wpt functional`, swm_d72)\nhead(localMI_F)\n\n          Ii          E.Ii      Var.Ii      Z.Ii Pr(z != E(Ii))\n1 0.43151603 -7.191834e-04 0.008120236 4.7966255   1.613609e-06\n2 0.27475350 -2.904635e-04 0.003338620 4.7601280   1.934703e-06\n3 0.69235062 -8.956670e-04 0.345864093 1.1787856   2.384836e-01\n4 0.05590525 -3.884365e-04 0.029702941 0.3266329   7.439455e-01\n5 0.33277612 -3.884365e-04 0.004984321 4.7190630   2.369335e-06\n6 0.05909213 -4.231402e-05 0.001519106 1.5172126   1.292130e-01\n\n\n\nlocalMI_F <- data.frame(localMI_F)\ncolnames(localMI_F)[5] =\"Pr\"\nnga_wp_26391$lc_Ii_F <- localMI_F$'Ii'\nnga_wp_26391$lc_Pr_F <- localMI_F$'Pr'\n\n\nlocalMI.map_F <- tm_shape(nga_wp_26391) +\n  tm_fill(col = \"lc_Ii_F\", \n          style = \"jenks\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Plot of Local Moran's I\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = TRUE)\n\npvalue.map_F <- tm_shape(nga_wp_26391) +\n  tm_fill(col = \"lc_Pr_F\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Plot of Local Moran's I P-Value\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = TRUE)\n\ntmap_arrange(localMI.map_F, pvalue.map_F, asp=1, ncol=2)\n\nVariable(s) \"lc_Ii_F\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#scatterplot-for-non-functional-water-points",
    "href": "take_home_ex/ex_1/ex_1.html#scatterplot-for-non-functional-water-points",
    "title": "Take Home Ex-1",
    "section": "Scatterplot for Non-Functional water points",
    "text": "Scatterplot for Non-Functional water points\nTo plot the Moran’s I scatterplot, we will use the moran.plot() function from spdep. We will need to provide the sf dataframe with the variable column along with the weight matrix. In this case, we will use our row-standardized weight matrix.\n\nNF_scatter <- moran.plot(nga_wp_26391$`wpt non-functional`, swm_d72,\n                  labels=as.character(nga_wp_26391$shapeName), \n                  xlab=\"wpt non-functional\", \n                  ylab=\"Spatially lagged wpt non-functional\")\n\n\n\n\nTo help with comparison and ease of reading the scatterplot, it helps to perform some scaling. For this we will use the scale() function with divides the column by the largest value. We then use the piping function to save it as a vector before adding it to our dataframe.\nWe perform the following step:\n\nscaled_NF <- scale(nga_wp_26391$`wpt non-functional`) %>% as.vector \nnga_wp_26391$scaled_NF <- scaled_NF\n\nWe then plot the scatterplot once more:\n\nNF_scatter_scaled <- moran.plot(nga_wp_26391$scaled_NF, swm_d72,\n                  labels=as.character(nga_wp_26391$shapeName), \n                  xlab=\"wpt non-functional\", \n                  ylab=\"Spatially lagged wpt non-functional\")\n\n\n\n\nAfter scaling, we can see now that the axis is re-positioned to (0,0). From this scatterplot, we can see easily that there groups of polygons whose value exhibit clustering behavior. Interestingly, there are quite a number of outliers in the top-left and bottom right quadrant."
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#scatterplot-for-functional-water-points",
    "href": "take_home_ex/ex_1/ex_1.html#scatterplot-for-functional-water-points",
    "title": "Take Home Ex-1",
    "section": "Scatterplot for Functional water points",
    "text": "Scatterplot for Functional water points\nWe do the same for Functional water pints:\n\nF_scatter <- moran.plot(nga_wp_26391$`wpt functional`, swm_d72,\n                  labels=as.character(nga_wp_26391$shapeName),\n                  xlab=\"wpt functional\",\n                  ylab=\"Spatially lagged wpt functional\")\n\n\n\n\nWe perform scaling as follow:\n\nscaled_F <- scale(nga_wp_26391$`wpt functional`) %>% as.vector \nnga_wp_26391$scaled_F <- scaled_F\n\nWe plot the scaled Moran’s I scatterplot as follow:\n\nF_scatter_scaled <- moran.plot(nga_wp_26391$scaled_F, swm_d72,\n                  labels=as.character(nga_wp_26391$shapeName), \n                  xlab=\"wpt non-functional\", \n                  ylab=\"Spatially lagged wpt non-functional\")\n\n\n\n\nWe see here significant number of points in the top-left and bottom right quadrant which is indicative of the spatial auto correlation and clustering. Similarly, we also see outliers in the plot."
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#lisa-non-functional-water-point",
    "href": "take_home_ex/ex_1/ex_1.html#lisa-non-functional-water-point",
    "title": "Take Home Ex-1",
    "section": "LISA: Non-Functional water point",
    "text": "LISA: Non-Functional water point\nTo achieve this, we will first create a vector to hold the different categories. We do this with a the function vector(), there should be 774 reflecting 774 polygons:\n\nquadrant_NF <- vector(mode=\"numeric\",length=nrow(localMI_NF))\n\nPreviously in step 8, we have already computed the spatial lag based on row-standardized weight matrix. We view the value once more:\n\nnga_wp_26391$lag_NF[1:20]\n\n [1] 26.34921 26.08065  0.00000 42.80000 34.75000 64.28571 31.15789 28.18750\n [9] 46.53846 23.23438 13.90909 49.36364 52.38462 32.16667 19.74074 67.89189\n[17] 46.11765 40.75862 36.82927 43.57143\n\n\nWe then prepare a numeric vector to hold variable of interest that is mean adjusted:\n\nDV_NF <- nga_wp_26391$`wpt non-functional` - mean(nga_wp_26391$`wpt non-functional`) \n\nWe also prepare a numeric vector of the local Moran’s I value:\n\nLM_I_NF <- localMI_NF[,1] - mean(localMI_NF[,1])  \n\nWe will also set the significance level, that help us filter away rows with non-significant P values:\n\nsignif <- 0.05  \n\nNext we will work to fill up the value of the quadrant_NF:\n\nquadrant_NF[DV_NF <0 & LM_I_NF>0] <- 1\nquadrant_NF[DV_NF >0 & LM_I_NF<0] <- 2\nquadrant_NF[DV_NF <0 & LM_I_NF<0] <- 3  \nquadrant_NF[DV_NF >0 & LM_I_NF>0] <- 4   \n\nFor rows that are not statistically significant, we will set to 0:\n\nquadrant_NF[localMI_NF[,5]>signif] <- 0\n\nFinally we will add our vector quadrant_NF to our main sf data object nga_wp_26391. We then follow this with a tmap plot taking note to use the style of category this time.\nIn addition, we will make use of the earlier plotted local Moran’s I map for comparison, we do this by calling the function tamp_arrange:\n\nnga_wp_26391$quadrant_NF <- quadrant_NF\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISA_NF <- tm_shape(nga_wp_26391) +\n  tm_fill(col = \"quadrant_NF\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant_NF)))+1], \n          labels = clusters[c(sort(unique(quadrant_NF)))+1],\n          popup.vars = c(\"\")) +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = \"Plot of LISA Non Functional WP\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = TRUE)\n  tm_view(set.zoom.limits = c(11,17)) #This line is not needed since not using interactive\n\n$tm_layout\n$tm_layout$set.zoom.limits\n[1] 11 17\n\n$tm_layout$style\n[1] NA\n\n\nattr(,\"class\")\n[1] \"tm\"\n\ntmap_arrange(LISA_NF, localMI.map_NF, asp=1, ncol=2)\n\nVariable(s) \"lc_Ii_NF\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nFrom this LISA plot above, we can see a clear relationship between the local Moran’s I plot earlier and the newly plotted LISA plot. We can see 5 hots spots in red, these 5 regions correspond to areas with high local Moran’s I value."
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#lisa-functional-water-point",
    "href": "take_home_ex/ex_1/ex_1.html#lisa-functional-water-point",
    "title": "Take Home Ex-1",
    "section": "LISA: Functional Water Point",
    "text": "LISA: Functional Water Point\nSame as above, we create a vector:\n\nquadrant_F <- vector(mode=\"numeric\",length=nrow(localMI_F))\n\nWe check the earlier calculated lag values:\n\nnga_wp_26391$lag_F[1:20]\n\n [1] 20.50794 20.41935  0.00000 59.10000 18.19643 93.80952 37.36842 43.56250\n [9] 61.03846 17.04688 25.31818 58.63636 41.53846 50.29167 35.48148 63.18919\n[17] 67.73529 48.44828 40.53659 87.85714\n\n\nWe combine the earlier steps into a single chunk of code:\n\nDV_F <- nga_wp_26391$`wpt functional` - mean(nga_wp_26391$`wpt functional`) \nLM_I_F <- localMI_F[,1] - mean(localMI_F[,1])  \nquadrant_F[DV_F <0 & LM_I_F>0] <- 1\nquadrant_F[DV_F >0 & LM_I_F<0] <- 2\nquadrant_F[DV_F <0 & LM_I_F<0] <- 3  \nquadrant_F[DV_F >0 & LM_I_F>0] <- 4   \nquadrant_F[localMI_F[,5]>signif] <- 0\n\nOnce again, we will plot the value:\n\nnga_wp_26391$quadrant_F <- quadrant_F\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISA_F <- tm_shape(nga_wp_26391) +\n  tm_fill(col = \"quadrant_F\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant_F)))+1], \n          labels = clusters[c(sort(unique(quadrant_F)))+1],\n          popup.vars = c(\"\")) +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = \"Plot of LISA Functional WP\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = TRUE)\n  tm_view(set.zoom.limits = c(11,17)) #This line is not needed since not using interactive\n\n$tm_layout\n$tm_layout$set.zoom.limits\n[1] 11 17\n\n$tm_layout$style\n[1] NA\n\n\nattr(,\"class\")\n[1] \"tm\"\n\n# \ntmap_arrange(LISA_F, localMI.map_F, asp=1, ncol=2)\n\nVariable(s) \"lc_Ii_F\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nAgain, we see that the hotpsots from the LISA map matches the regions of high local Moran’s I for the functional water points."
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#non-functional-water-point-g",
    "href": "take_home_ex/ex_1/ex_1.html#non-functional-water-point-g",
    "title": "Take Home Ex-1",
    "section": "Non-Functional water point G*",
    "text": "Non-Functional water point G*\nWe compute the G* statistics using localG() function from spdep:\n\ngi_NF <- localG(nga_wp_26391$`wpt non-functional`, swm_d72)\nhead(gi_NF)\n\n[1] -3.4117747 -3.4325327 -1.5896655  0.1024036 -1.4372021  2.8392431\n\n\nNext we will append the calculated values to the main sf dataframe:\n\nnga_wp_26391$gi_NF <- gi_NF\n\nLastly, we will use the tmap package to plot the G* statistics along side the non-functioning water point. Here we will use the “jenks” style as it group values that are most similar together:\n\ngdppc_NF <- tm_shape(nga_wp_26391) +\n  tm_fill(col = \"wpt non-functional\", \n          style = \"jenks\", \n          title = \"No. of wpt non-functional\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"wpt non-functional\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = TRUE)\n\nGimap_NF <-tm_shape(nga_wp_26391) +\n  tm_fill(col = \"gi_NF\",\n          style = \"jenks\",\n          palette=\"-RdBu\",\n          title = \"local G*\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"wpt non-functional G*\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = TRUE)\n\ntmap_arrange(gdppc_NF, Gimap_NF, asp=1, ncol=2)\n\nVariable(s) \"gi_NF\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nWhen compared to the plot on the number of non-functioning waterpoints, we see that the G* captures the hotspot patterns greatly. In addition, it also pinpointed the region of cold spots on the map."
  },
  {
    "objectID": "take_home_ex/ex_1/ex_1.html#functional-water-point-g",
    "href": "take_home_ex/ex_1/ex_1.html#functional-water-point-g",
    "title": "Take Home Ex-1",
    "section": "Functional water point G*",
    "text": "Functional water point G*\nHere we will perform the same steps as above into 1 code chunk:\n\ngi_F <- localG(nga_wp_26391$`wpt functional`, swm_d72)\nnga_wp_26391$gi_F <- gi_F\n\nWe till then plot the G* for Functional water point as follow:\n\ngdppc_F <- tm_shape(nga_wp_26391) +\n  tm_fill(col = \"wpt functional\", \n          style = \"jenks\", \n          title = \"No. of wpt functional\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"wpt functional\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = TRUE)\n\nGimap_F <-tm_shape(nga_wp_26391) +\n  tm_fill(col = \"gi_F\",\n          style = \"jenks\",\n          palette=\"-RdBu\",\n          title = \"local G*\") +\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"wpt functional G*\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = TRUE)\n\ntmap_arrange(gdppc_F, Gimap_F, asp=1, ncol=2)\n\nVariable(s) \"gi_F\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nFrom this plot, we can see a clear hotspot at the top of the map. Interestingly we also observe a outer area with lower hotspot intensity."
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html",
    "href": "take_home_ex/ex_2/ex_2.html",
    "title": "Take Home Ex 2",
    "section": "",
    "text": "Files required for Take Home Ex 2:\nWater point attribute data (exported as CSV file):\nhttps://www.waterpointdata.org/access-data/\nClick on the button “Access WPdx+ Global Data Repository”\nThen click export button & download as CSV file\nNigeria Administrative Level 2 Boundary File:\nhttps://www.geoboundaries.org/\nEnter “Nigeria” in the name filter column.\nDownload Nigeria-NGA-ADM2-2022 under the column “geoBoundaries”\nColumn Description can be found at:\nhttps://www.waterpointdata.org/wp-content/uploads/2021/04/WPDx_Data_Standard.pdf"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#load-the-water-point-data",
    "href": "take_home_ex/ex_2/ex_2.html#load-the-water-point-data",
    "title": "Take Home Ex 2",
    "section": "Load the water point data:",
    "text": "Load the water point data:\nNow, using the read_rds of the readr package, we load the data as follow:\n-we rename all the columns for ease of work\n-we also replace all N/A values of the status with “Unknown”\n\nwp_nga <- read_rds(savefile_path) %>%\n    rename(`status`=`#status_clean`) %>%\n    rename(`adm1`=`#clean_adm1`) %>%\n    rename(`adm2`=`#clean_adm2`) %>% \n    rename(`tech_clean`=`#water_tech_clean`) %>%\n    rename(`tech_category`=`#water_tech_category`) %>%\n    mutate(status = replace_na(status, \"Unknown\")) %>%\n    mutate(tech_category = replace_na(tech_category, \"Unknown\")) %>% \n    mutate(tech_clean = replace_na(tech_clean, \"Unknown\"))\n\nWe will now use the st_geometry of the sf package to look at our data info:\n\nst_geometry(wp_nga)\n\nGeometry set for 95008 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT (5.12 7.98)\n\n\nPOINT (3.597668 6.964532)\n\n\nPOINT (7.92972 6.48694)\n\n\nPOINT (7.64867 6.72757)\n\n\nPOINT (7.66485 6.7799)\n\n\nWe will check the CRS of the loaded rds file using st_crs() from sf:\n\nst_crs(wp_nga)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\nWe will check the output:\n\nst_crs(wp_nga)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#load-the-geo-boundary-data",
    "href": "take_home_ex/ex_2/ex_2.html#load-the-geo-boundary-data",
    "title": "Take Home Ex 2",
    "section": "Load the Geo Boundary data:",
    "text": "Load the Geo Boundary data:\nOnce again, we need to generate the path as follow:\n\nboundary_path <- here(\"data\", \"dataNigeria_2\", \"boundary\")\nboundary_path\n\n[1] \"D:/f4sared/ISSS624/data/dataNigeria_2/boundary\"\n\n\nUsing the st_read() function of the sf package, we will load the boundary file:\n\nnga <- st_read(dsn = boundary_path,\n               layer = \"geoBoundaries-NGA-ADM2\",\n               crs = 4326) %>% select(shapeName)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `D:\\f4sared\\ISSS624\\data\\dataNigeria_2\\boundary' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nWe will check the CRS with st_crs() from sf package:\n\nst_crs(nga)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#handling-repeated-names",
    "href": "take_home_ex/ex_2/ex_2.html#handling-repeated-names",
    "title": "Take Home Ex 2",
    "section": "Handling Repeated Names",
    "text": "Handling Repeated Names\nWe refer to our classmates’ method:\nhttps://jordan-isss624-geospatial.netlify.app/posts/geo/geospatial_exercise/#data-wrangling\nGet the index of the rows that are duplicated\n\nbool_list <- duplicated(nga$shapeName)\nduplicated_names <- nga$shapeName[bool_list]\nindex_rows <- which(nga$shapeName %in% duplicated_names)\nindex_rows\n\n [1]  94  95 304 305 355 356 519 520 546 547 693 694\n\nduplicated_names\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\nSave the duplicated region as a new sf dataframe:\n\ndup_regions <- nga %>% filter(nga$shapeName %in% duplicated_names)\n\nSelect the rows from the waterpoint data whose adm 2 is part of the duplicated list\n\ndup_points <- wp_nga %>%\n  filter(adm2 %in%\n           c(\"Bassa\",\n             \"Ifelodun\",\n             \"Irepodun\",\n             \"Nasarawa\",\n             \"Obi\",\n             \"Surulere\"))\n\nPerform a simple intersection between the duplicated regions and the earlier filtered waterpoints:\n\ndup_intersect <- st_intersects(dup_regions, dup_points)\n\nNext, we will use the slice function to select rows that fall under each of the duplicated region, then we will display the column “adm1” which shows the sub name for that region.\nBassa 1:\n\n(dup_points %>% slice(unlist(dup_intersect[1])))$adm1 %>% head()\n\n[1] \"Kogi\" \"Kogi\" \"Kogi\" \"Kogi\" \"Kogi\" \"Kogi\"\n\n\nBassa 2:\n\n(dup_points %>% slice(unlist(dup_intersect[2])))$adm1 %>% head()\n\n[1] \"Plateau\" \"Plateau\" \"Plateau\" \"Plateau\" \"Plateau\" \"Plateau\"\n\n\nIfelodun 1:\n\n(dup_points %>% slice(unlist(dup_intersect[3])))$adm1 %>% head()\n\n[1] \"Kwara\" \"Kwara\" \"Kwara\" \"Kwara\" \"Kwara\" \"Kwara\"\n\n\nIfelodun 2:\n\n(dup_points %>% slice(unlist(dup_intersect[4])))$adm1 %>% head()\n\n[1] \"Osun\" \"Osun\" \"Osun\" \"Osun\" \"Osun\" \"Osun\"\n\n\nIrepodun 1:\n\n(dup_points %>% slice(unlist(dup_intersect[5])))$adm1 %>% head()\n\n[1] \"Kwara\" \"Kwara\" \"Kwara\" \"Kwara\" \"Kwara\" \"Kwara\"\n\n\nIrepodun 2:\n\n(dup_points %>% slice(unlist(dup_intersect[6])))$adm1 %>% head()\n\n[1] \"Osun\" \"Osun\" \"Osun\" \"Osun\" \"Osun\" \"Osun\"\n\n\nNasarawa 1:\n\n(dup_points %>% slice(unlist(dup_intersect[7])))$adm1 %>% head()\n\ncharacter(0)\n\n\nNasarawa 2:\n\n(dup_points %>% slice(unlist(dup_intersect[8])))$adm1 %>% head()\n\n[1] \"Nasarawa\" \"Nasarawa\" \"Nasarawa\" \"Nasarawa\" \"Nasarawa\" \"Nasarawa\"\n\n\nObi 1:\n\n(dup_points %>% slice(unlist(dup_intersect[9])))$adm1 %>% head()\n\n[1] \"Benue\" \"Benue\" \"Benue\" \"Benue\" \"Benue\" \"Benue\"\n\n\nObi 2:\n\n(dup_points %>% slice(unlist(dup_intersect[10])))$adm1 %>% head()\n\n[1] \"Nasarawa\" \"Nasarawa\" \"Nasarawa\" \"Nasarawa\" \"Nasarawa\" \"Nasarawa\"\n\n\nSurulere 1:\n\n(dup_points %>% slice(unlist(dup_intersect[11])))$adm1 %>% head()\n\n[1] \"Lagos\" \"Lagos\" \"Lagos\" \"Lagos\" \"Lagos\" \"Lagos\"\n\n\nSurulere 2:\n\n(dup_points %>% slice(unlist(dup_intersect[12])))$adm1 %>% head()\n\n[1] \"Oyo\" \"Oyo\" \"Oyo\" \"Oyo\" \"Oyo\" \"Oyo\"\n\n\nPlot the areas that are duplicated:\n\ntmap_mode(\"view\")\ntm_shape(dup_rows) + tm_polygons()\n\nRename the duplicated areas\n\nnga$shapeName[index_rows] <- c(\"Bassa_Kogi\", \"Bassa_Plateau\", \n                               \"Ifelodun_Kwara\", \"Ifelodun_Osun\",\n                               \"Irepodun_Kwara\", \"Irepodun_Osun\",\n                               \"Nasarawa_0\", \"Nasarawa_Nasarawa\",\n                               \"Obi_Benue\", \"Obi_Nasawara\",\n                               \"Surulere_Lagos\",\"Surulere_Oyo\")\n\nCheck to see if there are any repeated rows again:\n\nbool_list <- duplicated(nga$shapeName)\nduplicated_names <- nga$shapeName[bool_list]\nindex_rows <- which(nga$shapeName %in% duplicated_names)\nindex_rows\n\ninteger(0)\n\n\nWe use the rm() function to remove the environment variables to reduce clutter:\n\nrm(dup_intersect)\nrm(dup_points)\nrm(dup_regions)\nrm(bool_list)\nrm(duplicated_names)\nrm(index_rows)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#status-of-water-point",
    "href": "take_home_ex/ex_2/ex_2.html#status-of-water-point",
    "title": "Take Home Ex 2",
    "section": "Status of water point",
    "text": "Status of water point\nUsing the freq() from funModeling, we will check the distribution of status of the water points:\n\nfreq(data=wp_nga, input = 'status')\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n                            status frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                          Unknown     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00\n\n\n\nFunctional water point\n\nwpt_functional <- wp_nga %>%\n  filter(status %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\n\nfreq(data=wpt_functional, \n     input = 'status')\n\n\n\nNon Functional water point\n\nwpt_nonfunctional <- wp_nga %>%\n  filter(status %in%\n           c(\"Abandoned/Decommissioned\", \n             \"Abandoned\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\",\n             \"Non-Functional due to dry season\"))\n\n\nfreq(data=wpt_nonfunctional, \n     input = 'status')\n\n\n\nUnknown\n\nwpt_unknown <- wp_nga %>% filter(status == \"Unknown\")"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#water-point-technology",
    "href": "take_home_ex/ex_2/ex_2.html#water-point-technology",
    "title": "Take Home Ex 2",
    "section": "Water point Technology",
    "text": "Water point Technology\n\nwpt_hand_pump <- wp_nga %>% filter(tech_category == \"Hand Pump\")\n\n\nfreq(data=wp_nga, input = 'tech_category')"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#usage-capacity-1000",
    "href": "take_home_ex/ex_2/ex_2.html#usage-capacity-1000",
    "title": "Take Home Ex 2",
    "section": "Usage Capacity < 1000",
    "text": "Usage Capacity < 1000\nWe first use the freq() of the funModeling package to show the distribution of capacity:\n\nfreq(data=wp_nga, input = 'usage_capacity')\n\n\n\n\n  usage_capacity frequency percentage cumulative_perc\n1            300     68789      72.40           72.40\n2           1000     25644      26.99           99.39\n3            250       573       0.60           99.99\n4             50         2       0.00          100.00\n\n\nThe above plots shows us that majority of the values are either 300 or 1000.\nThis for our analysis, we will focus on values that are less than 1000\n\nwpt_1000 <- wp_nga %>% filter(usage_capacity < 1000)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#rural-waterpoints",
    "href": "take_home_ex/ex_2/ex_2.html#rural-waterpoints",
    "title": "Take Home Ex 2",
    "section": "Rural waterpoints",
    "text": "Rural waterpoints\n\nwpt_rural <- wp_nga %>% filter(is_urban == FALSE)\n\n\nfreq(data=wp_nga, input = 'is_urban')"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#point-in-polygon",
    "href": "take_home_ex/ex_2/ex_2.html#point-in-polygon",
    "title": "Take Home Ex 2",
    "section": "Point-in-Polygon",
    "text": "Point-in-Polygon\nSince each of the waterpoint in wp_nga belongs to a specific region, we need to allocated them into their own respective region, we do this using the the st_intersect() function of the sf package along with the mutate() function of the dplyr package.\nWe perform Point in polygon as follow:\n\nnga_wp <- nga %>%\n  mutate(`total_wpt` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wpt_functional` = lengths(\n    st_intersects(nga, wpt_functional))) %>%\n  mutate(`wpt_non_functional` = lengths(\n    st_intersects(nga, wpt_nonfunctional))) %>%\n  mutate(`wpt_unknown` = lengths(\n    st_intersects(nga, wpt_unknown))) %>% \n  mutate(`wpt_hand_pump` = lengths(\n    st_intersects(nga, wpt_hand_pump))) %>%\n  mutate(`wpt_1000` = lengths(\n    st_intersects(nga, wpt_1000))) %>% \n  mutate(`wpt_rural` = lengths(\n    st_intersects(nga, wpt_rural))) \n\nCalculate Percentage:\n\nnga_wp <- nga_wp %>%\n  mutate(pct_functional = `wpt_functional`/`total_wpt`) %>%\n  mutate(`pct_non_functional` = `wpt_non_functional`/`total_wpt`) %>% \n  mutate(`pct_hand_pump` = `wpt_hand_pump`/`total_wpt`) %>% \n  mutate(`pct_1000` = `wpt_1000`/`total_wpt`) %>%\n  mutate(`pct_rural` = `wpt_rural`/`total_wpt`)\n\nReplace NaN with 0\n\nNaN_list <- is.nan(nga_wp$pct_functional)\nnga_wp$pct_functional[NaN_list] <- 0\n\nNaN_list <- is.nan(nga_wp$pct_non_functional)\nnga_wp$pct_non_functional[NaN_list] <- 0\n\nNaN_list <- is.nan(nga_wp$pct_hand_pump)\nnga_wp$pct_hand_pump[NaN_list] <- 0\n\nNaN_list <- is.nan(nga_wp$pct_hand_pump)\nnga_wp$pct_hand_pump[NaN_list] <- 0\n\nNaN_list <- is.nan(nga_wp$pct_1000)\nnga_wp$pct_1000[NaN_list] <- 0\n\nNaN_list <- is.nan(nga_wp$pct_rural)\nnga_wp$pct_rural[NaN_list] <- 0\n\n\nqtm(nga_wp, fill = \"wpt hand pump\") + \n    tm_layout(legend.height = 0.4,legend.width = 0.4)\n\nOnce again, we now clean the environment of variables:\n\nrm(wpt_1000)\nrm(wpt_functional)\nrm(wpt_hand_pump)\nrm(wpt_nonfunctional)\nrm(wpt_rural)\nrm(wpt_unknown)\nrm(NaN_list)\nrm(wp_nga)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#performing-projection-to-26391",
    "href": "take_home_ex/ex_2/ex_2.html#performing-projection-to-26391",
    "title": "Take Home Ex 2",
    "section": "Performing Projection to 26391",
    "text": "Performing Projection to 26391\nWe will now use st_trasnform() function to project to the Nigeria CRS of 26391:\n\nnga_wp <- st_transform(nga_wp, crs = 26391)\n\nWe will also transform the boundary file:\n\nnga <- st_transform(nga, crs = 26391)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#spatial-mapping",
    "href": "take_home_ex/ex_2/ex_2.html#spatial-mapping",
    "title": "Take Home Ex 2",
    "section": "Spatial Mapping",
    "text": "Spatial Mapping\nFirst we will do a spatial plot with the functional & non-functional vars to check for any spatial patterns.\nWe will make use of the tmap package and the tmap_arrange() function:\n\nfunctional.map <- tm_shape(nga_wp) + \n                  tm_fill(col = \"wpt_functional\",\n                          n = 5,\n                          style = \"jenks\", \n                          title = \"wpt_functional\") + \n                  tm_borders(alpha = 0.9) +\n                  tm_layout(main.title = \"Functional water points distribution\",\n                          main.title.position = \"center\",\n                          main.title.size = 1.2,\n                          legend.height = 0.6,\n                          legend.width = 0.6,\n                          frame = TRUE) \n\nnon_functional.map <- tm_shape(nga_wp) + \n                    tm_fill(col = \"wpt_non_functional\",\n                            n = 5,\n                            style = \"jenks\", \n                            title = \"wpt_non_functional\") + \n                tm_borders(alpha = 0.9) +\n                tm_layout(main.title = \"Non-functional water points distribution\",\n                            main.title.position = \"center\",\n                            main.title.size = 1.2,\n                            legend.height = 0.6,\n                            legend.width = 0.6,\n                            frame = TRUE) \n\n\npct_functional.map <- tm_shape(nga_wp) + \n                  tm_fill(col = \"pct_functional\",\n                          n = 5,\n                          style = \"jenks\", \n                          title = \"pct_functional\") + \n                  tm_borders(alpha = 0.9) +\n                  tm_layout(main.title = \"Functional water points %\",\n                          main.title.position = \"center\",\n                          main.title.size = 1.2,\n                          legend.height = 0.6,\n                          legend.width = 0.6,\n                          frame = TRUE) \n\npct_non_functional.map <- tm_shape(nga_wp) + \n                  tm_fill(col = \"pct_non_functional\",\n                          n = 5,\n                          style = \"jenks\", \n                          title = \"pct_non_functional\") + \n                  tm_borders(alpha = 0.9) +\n                  tm_layout(main.title = \"Non-Functional water points %\",\n                          main.title.position = \"center\",\n                          main.title.size = 1.2,\n                          legend.height = 0.6,\n                          legend.width = 0.6,\n                          frame = TRUE) \n\ntmap_arrange(functional.map, non_functional.map,\n             pct_functional.map,pct_non_functional.map,\n             asp=NA, ncol=2)\n\n\n\n\nIn the top left and top right plot, we have the absolute number of functional and non-functional water point. We can see a clear indication of patterns where certain cluster of regions have higher absolute value.\nHowever, the magnitude of the variable does not tell the full story, thus we will also make a plot of the percentage of functional and non-functional water points in the lower left and right plots. From these two plots, we also notice a distinct pattern and clustering behavior of the variables.\nThus this is good evidence for us to look further.\n\nNext we further turn our attention to the remaining variables:\n\nhand_pump.map <- tm_shape(nga_wp) + \n                  tm_fill(col = \"pct_hand_pump\",\n                          n = 5,\n                          style = \"jenks\", \n                          title = \"pct_hand_pump\") + \n                  tm_borders(alpha = 0.9) +\n                  tm_layout(main.title = \"Handpump % distribution\",\n                          main.title.position = \"center\",\n                          main.title.size = 1.2,\n                          legend.height = 0.6,\n                          legend.width = 0.6,\n                          frame = TRUE)\n\npct_1000.map <- tm_shape(nga_wp) + \n                  tm_fill(col = \"pct_1000\",\n                          n = 5,\n                          style = \"jenks\", \n                          title = \"pct_1000\") + \n                  tm_borders(alpha = 0.9) +\n                  tm_layout(main.title = \"Capacity < 1000 % distribution\",\n                          main.title.position = \"center\",\n                          main.title.size = 1.2,\n                          legend.height = 0.6,\n                          legend.width = 0.6,\n                          frame = TRUE) \n\npct_rural.map <- tm_shape(nga_wp) + \n                  tm_fill(col = \"pct_rural\",\n                          n = 5,\n                          style = \"jenks\", \n                          title = \"pct_rural\") + \n                  tm_borders(alpha = 0.9) +\n                  tm_layout(main.title = \"Rural % distribution\",\n                          main.title.position = \"center\",\n                          main.title.size = 1.2,\n                          legend.height = 0.6,\n                          legend.width = 0.6,\n                          frame = TRUE) \n\ntmap_arrange(hand_pump.map, pct_1000.map, pct_rural.map,\n             asp=NA, ncol=2)\n\n\n\n\nFor the reaming variables, we observe clustering pattern for heat pump % and capacity < 1000 %. Interestingly, they seem to have similar spatial patterns which can suggest the possibility of correlation.\nFor the rural % however, the clustering pattern appears to be more fragmented.\nHousekeeping:\n\nrm(functional.map)\nrm(non_functional.map)\nrm(pct_functional.map)\nrm(pct_non_functional.map)\n\nrm(hand_pump.map)\nrm(pct_1000.map)\nrm(pct_rural.map)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#statistical",
    "href": "take_home_ex/ex_2/ex_2.html#statistical",
    "title": "Take Home Ex 2",
    "section": "Statistical",
    "text": "Statistical\nNext, we will make use of ggplot package to explore the distribution of values.\nWe will use geom_histogram() of the ggplot package to show the histogram of the variables:\n\nwpt_functional <- ggplot(data=nga_wp, \n             aes(x= `wpt_functional`)) +\n            geom_histogram(bins=20, \n                           color=\"black\", \n                           fill=\"light blue\")+\n            theme(axis.title=element_text(size=30,face=\"bold\"))\n\nwpt_non_functional <- ggplot(data=nga_wp, \n             aes(x= `wpt_non_functional`)) +\n            geom_histogram(bins=20, \n                           color=\"black\", \n                           fill=\"light blue\")+\n            theme(axis.title=element_text(size=30,face=\"bold\"))\n\npct_functional <- ggplot(data=nga_wp, \n             aes(x= `pct_functional`)) +\n            geom_histogram(bins=20, \n                           color=\"black\", \n                           fill=\"light blue\")+\n            theme(axis.title=element_text(size=30,face=\"bold\"))\n\npct_non_functional <- ggplot(data=nga_wp, \n             aes(x= `pct_non_functional`)) +\n            geom_histogram(bins=20, \n                           color=\"black\", \n                           fill=\"light blue\")+\n            theme(axis.title=element_text(size=30,face=\"bold\"))\n\nggarrange(wpt_functional, wpt_non_functional, pct_functional, pct_non_functional,\n          ncol = 2, \n          nrow = 2)\n\n\n\n\nWe can see that while this distribution of the functional and non-functional waterpoints are skewed, the % functional and % non-functional seems to follow a normal distribution.\nWe will use geom_histogram() of the ggplot package to show the histogram of remaining variables:\n\npct_handpump <- ggplot(data=nga_wp, \n             aes(x= `pct_hand_pump`)) +\n            geom_histogram(bins=20, \n                           color=\"black\", \n                           fill=\"light blue\")+\n            theme(axis.title=element_text(size=30,face=\"bold\"))\n\npct_1000 <- ggplot(data=nga_wp, \n             aes(x= `pct_1000`)) +\n            geom_histogram(bins=20, \n                           color=\"black\", \n                           fill=\"light blue\")+\n            theme(axis.title=element_text(size=30,face=\"bold\"))\n\npct_rural <- ggplot(data=nga_wp, \n             aes(x= `pct_rural`)) +\n            geom_histogram(bins=20, \n                           color=\"black\", \n                           fill=\"light blue\")+\n            theme(axis.title=element_text(size=30,face=\"bold\"))\n\nggarrange(pct_handpump, pct_1000, pct_rural,\n          ncol = 2, \n          nrow = 2)\n\n\n\n\nFrom the above plots, we observe a left skew in the distribution of regions with < 1000 capacity. We observe the same left skew for the distribution of rural waterpoints.\nHousekeeping:\n\nrm(wpt_functional)\nrm(wpt_non_functional)\nrm(pct_functional)\nrm(pct_non_functional)\n\nrm(hand_pump)\n\nWarning in rm(hand_pump): object 'hand_pump' not found\n\nrm(pct_1000)\nrm(pct_rural)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#extract-the-clustering-variables",
    "href": "take_home_ex/ex_2/ex_2.html#extract-the-clustering-variables",
    "title": "Take Home Ex 2",
    "section": "Extract the clustering variables",
    "text": "Extract the clustering variables\nTo perform the analysis, we need to extract the cluster variables without the geometric data. To do this, we we will use the function st_set_geometry(NULL) from sf package on our sf dataframe.\nWe run the code as follow:\n\ncluster_vars <- nga_wp %>%\n  st_set_geometry(NULL) %>%\n  select(\"shapeName\", \"wpt_functional\", \"wpt_non_functional\", \n         \"pct_functional\", \"pct_non_functional\", \n         \"pct_hand_pump\", \"pct_1000\", \"pct_rural\")\nhead(cluster_vars,3)\n\n  shapeName wpt_functional wpt_non_functional pct_functional pct_non_functional\n1 Aba North              7                  9      0.4117647          0.5294118\n2 Aba South             29                 35      0.4084507          0.4929577\n3    Abadam              0                  0      0.0000000          0.0000000\n  pct_hand_pump  pct_1000  pct_rural\n1    0.11764706 0.1764706 0.00000000\n2    0.09859155 0.1267606 0.05633803\n3    0.00000000 0.0000000 0.00000000\n\n\nNext, we need to change the row names using row.name() function from R base:\n\nrow.names(cluster_vars) <- cluster_vars$\"shapeName\"\nhead(cluster_vars,3)\n\n          shapeName wpt_functional wpt_non_functional pct_functional\nAba North Aba North              7                  9      0.4117647\nAba South Aba South             29                 35      0.4084507\nAbadam       Abadam              0                  0      0.0000000\n          pct_non_functional pct_hand_pump  pct_1000  pct_rural\nAba North          0.5294118    0.11764706 0.1764706 0.00000000\nAba South          0.4929577    0.09859155 0.1267606 0.05633803\nAbadam             0.0000000    0.00000000 0.0000000 0.00000000\n\n\nNow, we do not need the column shapeName & pct_1000 anymore, so we exclude it:\n\ncluster_vars <- select(cluster_vars, c(2:6, 8))\nhead(cluster_vars, 3)\n\n          wpt_functional wpt_non_functional pct_functional pct_non_functional\nAba North              7                  9      0.4117647          0.5294118\nAba South             29                 35      0.4084507          0.4929577\nAbadam                 0                  0      0.0000000          0.0000000\n          pct_hand_pump  pct_rural\nAba North    0.11764706 0.00000000\nAba South    0.09859155 0.05633803\nAbadam       0.00000000 0.00000000"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#data-standardization",
    "href": "take_home_ex/ex_2/ex_2.html#data-standardization",
    "title": "Take Home Ex 2",
    "section": "Data Standardization",
    "text": "Data Standardization\nFrom our dataframe “done_cluster_vars”, we can see that the columns wpt_functional and wpt_non_functional have much higher ranges since they are counts instead of percentages. Thus we need to perform standardization on these columns. This is because analysis results will be biased towards clustering variables with large values. Hence the need for standardization before cluster analysis\nWe will therefore perform the min-max standardization using the normalize() of the heatmaply package:\n(we use summary() of base R package to check the outcome)\n\nstd_cluster_vars <- normalize(cluster_vars)\nsummary(std_cluster_vars)\n\n wpt_functional    wpt_non_functional pct_functional   pct_non_functional\n Min.   :0.00000   Min.   :0.00000    Min.   :0.0000   Min.   :0.0000    \n 1st Qu.:0.02261   1st Qu.:0.04406    1st Qu.:0.3261   1st Qu.:0.2105    \n Median :0.06051   Median :0.12230    Median :0.4741   Median :0.3505    \n Mean   :0.08957   Mean   :0.14962    Mean   :0.4984   Mean   :0.3592    \n 3rd Qu.:0.11669   3rd Qu.:0.21853    3rd Qu.:0.6699   3rd Qu.:0.5076    \n Max.   :1.00000   Max.   :1.00000    Max.   :1.0000   Max.   :1.0000    \n pct_hand_pump      pct_rural     \n Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.1670   1st Qu.:0.5727  \n Median :0.5099   Median :0.8645  \n Mean   :0.4873   Mean   :0.7271  \n 3rd Qu.:0.7778   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#compute-the-proximity-matrix",
    "href": "take_home_ex/ex_2/ex_2.html#compute-the-proximity-matrix",
    "title": "Take Home Ex 2",
    "section": "Compute the proximity matrix",
    "text": "Compute the proximity matrix\nWhen calculating proximity matrix, there are a few options available for us:\n-Euclidean\n-Maximum\n-Manhattan / City Block Distance\n-Canberra\n-Binary\n-Minkowski\nWe will use Euclidean since it is the default.\nUsing the dist() of the base R package, we will compute the proximity matrix:\n\nproxmat <- dist(std_cluster_vars, method = 'euclidean')"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#compute-the-clustering",
    "href": "take_home_ex/ex_2/ex_2.html#compute-the-clustering",
    "title": "Take Home Ex 2",
    "section": "Compute the Clustering",
    "text": "Compute the Clustering\nThere are 2 forms of clustering methods:\n\nAgglomerative-AGNES: This is a bottom up manner where each point starts as a cluster\nDivise Analysis-DIANA: This is a top down approach. At each step, most heterogeneous is split.\n\nThere are a total of eight clustering algorithms for AGNES:\n-ward.D\n-ward.D2\n-single\n-complete\n-average(UPGMA)\n-mcquitty(WPGMA)\n-median(WPGMC)\n-centroid(UPGMC)\nWe will start off with “ward.D”\nUsing hclust() of the base R package, we will compute the cluster as follow:\n\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n\nWe will then get an object hclust_ward which contains the detaiLED information on the structure of the cluster tree. This will allow the later plot() function to know how to plot the structure correctly."
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#plotting-the-dendrogram",
    "href": "take_home_ex/ex_2/ex_2.html#plotting-the-dendrogram",
    "title": "Take Home Ex 2",
    "section": "Plotting the Dendrogram:",
    "text": "Plotting the Dendrogram:\nTo view the outcome, we save the output as a png and then load it as a picture:\nhttps://stackoverflow.com/questions/11444743/how-to-adjust-sizes-of-x-axis-in-dendrogram-r\nEach time the code is run, the .png object will be updated. For better resolution, we increase the width and height of the .png file. The “cex” is adjusted such that the names of each region is just visible when we zoom in on the .png object.\nAdditional parameters:\n\nlwd: Line width\nmain: Title\nline: Position of title\ncex.main: Size of title\n\nWe run the code as follow\n\npng(\"plotdendogram.png\",width=12800,height=3200)\nplot(hclust_ward, cex = 1.2, lwd=3.0, main=\"Dendrogram\", line = -20, cex.main=20)\n\nWarning in graphics:::plotHclust(n1, merge, height, order(x$order), hang, :\n\"line\" is not a graphical parameter\n\nWarning in graphics:::plotHclust(n1, merge, height, order(x$order), hang, :\n\"line\" is not a graphical parameter\n\ndev.off()\n\npng \n  2 \n\n\nPlease open the png in a new tab and then zoom in:"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#selecting-the-optimal-clustering-algorithm",
    "href": "take_home_ex/ex_2/ex_2.html#selecting-the-optimal-clustering-algorithm",
    "title": "Take Home Ex 2",
    "section": "Selecting the optimal clustering algorithm:",
    "text": "Selecting the optimal clustering algorithm:\nIn order the measure the strength of the clustering structure, we will need to measure the agglomerative coefficient. If we compare the aforementioned coefficient across various clustering algorithms, we will be able to select the algorithm that gives us the best clustering structure.\nThe function agnes() functions similar to the hclust() function with the addition of a coefficient:\nhttps://rdrr.io/cran/cluster/man/agnes.html\nWe now use the agnes() function from the cluster package:\n\nagnes_result <- agnes(std_cluster_vars, method = \"ward\")\nagnes_result$ac\n\n[1] 0.990276\n\n\nThe results are stored in the output data structure under the name agnes_result$ac. The higher the magnitude of this value, the better the clustering structure. In this case, “ward” gets a score of 0.990276 which shows strong clustering structure.\nWe will need to test all 4 of the clustering algorithms to determine which is the best to apply.\nFirst, we need to create a data structure to hold the names of the clustering algorithms:\n\nalgorithms <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(algorithms) <- c( \"average\", \"single\", \"complete\", \"ward\")\nalgorithms\n\n   average     single   complete       ward \n \"average\"   \"single\" \"complete\"     \"ward\" \n\n\nNext we write a simple function “test” that takes in the name of the clustering algorithm and then outputs the score of the clustering structure:\n\ntest <- function(x) {\n  agnes(std_cluster_vars, method = x)$ac\n}\n\nFinally, using the map_dbl() function from the purr package, we will map the name of each algorithm to the input of the functions:\n\nmap_dbl(algorithms, test)\n\n  average    single  complete      ward \n0.9114067 0.7819154 0.9440637 0.9902760 \n\n\nOf the clustering algorithms, we can see that “ward” methods gives us the best clustering structure. Hence we will use this for the rest of the analysis.\nWe perform house keeping:\n\nrm(cluster_vars)\nrm(agnes_result)\nrm(algorithms)\n# rm(proxmat)\nrm(test)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#determine-optimal-clusters",
    "href": "take_home_ex/ex_2/ex_2.html#determine-optimal-clusters",
    "title": "Take Home Ex 2",
    "section": "Determine optimal clusters",
    "text": "Determine optimal clusters\nIn order to perform meaningful analysis, we need to select the optimal amount of cluster. Too little clusters, we won’t be able to draw meaningful insights. Too many clusters, and we will also fail to draw meaning.\nThere are 3 methods to do this:\n\nElbow method\nAverage silhouette method\nGap statistic\n\nFor this, we will make use of the tool called the gap statistic:\nhttps://hastie.su.domains/Papers/gap.pdf\nThe gap statistic is a measure of intra-cluster variation. The larger this value, the bigger the indication that the clustering behaviour is far from the random distribution of points. As we increase the number of cluster, we want to get a highest gap statistic number possible. The minimum number of clusters that we accept is 3 cluster for meaningful analysis.\nThere are a few methods to determine clusters:\n\nfirstSEmax\nTibs2001SEmax\nglobalSEmax\nfirstmax\nglobalmax\n\nUseful links:\nhttps://stats.stackexchange.com/questions/95290/how-should-i-interpret-gap-statistic\nhttps://stat.ethz.ch/R-manual/R-devel/library/cluster/html/clusGap.html\nTo do this, we use the clusGap() function from the cluster package:\n(for predictability, we need to set a specific random seed)\n\nset.seed(2022)\ngap_stat <- clusGap(std_cluster_vars, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 25, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"Tibs2001SEmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = std_cluster_vars, FUNcluster = hcut, K.max = 25, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..25; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'Tibs2001SEmax', SE.factor=1): 4\n          logW   E.logW       gap      SE.sim\n [1,] 5.000512 5.537541 0.5370297 0.006640580\n [2,] 4.838605 5.435522 0.5969167 0.010174498\n [3,] 4.675903 5.364424 0.6885215 0.011084303\n [4,] 4.585719 5.307609 0.7218895 0.010288092\n [5,] 4.533596 5.262031 0.7284345 0.011096225\n [6,] 4.487042 5.225343 0.7383019 0.010516894\n [7,] 4.452088 5.193566 0.7414780 0.011305457\n [8,] 4.411099 5.166658 0.7555587 0.010852306\n [9,] 4.372379 5.144079 0.7717004 0.010651529\n[10,] 4.342018 5.123315 0.7812978 0.009989005\n[11,] 4.305545 5.104442 0.7988971 0.009588659\n[12,] 4.274778 5.086947 0.8121689 0.009324876\n[13,] 4.254300 5.070183 0.8158832 0.009123792\n[14,] 4.228367 5.054393 0.8260260 0.009010597\n[15,] 4.205874 5.039250 0.8333759 0.009009316\n[16,] 4.184087 5.024765 0.8406782 0.009149193\n[17,] 4.160961 5.010952 0.8499907 0.009199555\n[18,] 4.136993 4.997904 0.8609109 0.009114803\n[19,] 4.114595 4.985161 0.8705663 0.009126652\n[20,] 4.095154 4.972999 0.8778457 0.009019012\n[21,] 4.074534 4.961102 0.8865674 0.008938229\n[22,] 4.058345 4.949750 0.8914045 0.008921074\n[23,] 4.044721 4.938825 0.8941047 0.008809354\n[24,] 4.026319 4.928110 0.9017906 0.008750836\n[25,] 4.015433 4.917798 0.9023651 0.008647470\n\n\nNext, we will plot the Gap Statistics as follow:\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nFrom the graph we see that the gradient of the Gap Statistic decreases greatly from the 4th cluster onwards. Therefore, we will opt to keep 5 clusters"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#interpreting-the-dendrograms",
    "href": "take_home_ex/ex_2/ex_2.html#interpreting-the-dendrograms",
    "title": "Take Home Ex 2",
    "section": "Interpreting the Dendrograms",
    "text": "Interpreting the Dendrograms\n\npng(\"plotdendogram_0.png\",width=12800,height=3200)\nplot(hclust_ward, cex = 1.2, lwd=3.0, main=\"Dendrogram\", line = -20, cex.main=20)\n\nWarning in graphics:::plotHclust(n1, merge, height, order(x$order), hang, :\n\"line\" is not a graphical parameter\n\nWarning in graphics:::plotHclust(n1, merge, height, order(x$order), hang, :\n\"line\" is not a graphical parameter\n\nrect.hclust(hclust_ward, k = 5, border = 2:5)\ndev.off()\n\npng \n  2 \n\n\nTo zoom in, right click and open picture on a new tab:"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#visual-hierarchical-clustering-analysis",
    "href": "take_home_ex/ex_2/ex_2.html#visual-hierarchical-clustering-analysis",
    "title": "Take Home Ex 2",
    "section": "Visual Hierarchical clustering Analysis",
    "text": "Visual Hierarchical clustering Analysis\nIn order to plot the heatmap, we need to convert the dataframe into a data matrix:\n\nmat_std_cluster_vars <- data.matrix(std_cluster_vars)\n\nNext using heatmaply() of the heatmaply package, we can plot the interactive as follow:\n\nheatmaply(mat_std_cluster_vars,\n          Colv=NA,\n          showticklabels = c(TRUE, FALSE),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Nigeria LGA\"\n          )"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#mapping-the-clusters",
    "href": "take_home_ex/ex_2/ex_2.html#mapping-the-clusters",
    "title": "Take Home Ex 2",
    "section": "Mapping the clusters",
    "text": "Mapping the clusters\nWe first use the function cutree() of R base to prune the clusters to 5:\n\ngroups <- as.factor(cutree(hclust_ward, k=5))\n\nWe will create a new sf dataframe nga_final which includes the geometry and the variables:\n\nnga_final <- nga_wp %>%\n  select(\"shapeName\", \"wpt_functional\", \"wpt_non_functional\", \n         \"pct_functional\", \"pct_non_functional\", \n         \"pct_hand_pump\", \"pct_1000\", \"pct_rural\")\n\nNext, we will use cbind() from base R to save the clustering group as a column:\n\nbind_std_cluster_vars <- cbind(nga_final, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nHere we will do a simple filtering to allow us to get the group number of a specific region\n\nbind_std_cluster_vars %>% filter(shapeName == \"Kanke\")\n\nSimple feature collection with 1 feature and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 776977.8 ymin: 576111.2 xmax: 812592.4 ymax: 616431.6\nProjected CRS: Minna / Nigeria West Belt\n  shapeName wpt_functional wpt_non_functional pct_functional pct_non_functional\n1     Kanke            217                 89       0.484375          0.1986607\n  pct_hand_pump  pct_1000 pct_rural CLUSTER                       geometry\n1     0.6160714 0.9330357         1       2 MULTIPOLYGON (((779281.4 61...\n\n\nUsing qtm() of the tmap, we will perform a quick plot as follow:\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(bind_std_cluster_vars) + \n  tm_fill(\"CLUSTER\") + \n  tm_borders(alpha = 0.9) + \n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_layout(main.title = \"Cluster Distribution of Nigeria\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) \n\n\n\n\nFrom the above plot, we can see that if we do clustering without consideration for geographic location, we get a cluster map that has clusters that are highly fragmented.\n\nHousekeeping to remove variables from environment:\n\nrm(gap_stat)\nrm(hclust_ward)\nrm(mat_std_cluster_vars)\nrm(groups)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#check-for-regions-without-neighbors",
    "href": "take_home_ex/ex_2/ex_2.html#check-for-regions-without-neighbors",
    "title": "Take Home Ex 2",
    "section": "Check for regions without neighbors:",
    "text": "Check for regions without neighbors:\nUsing the summary function, we will check if all polygons have a neighbor:\n\nsummary(poly2nb(nga))\n\nNeighbour list object:\nNumber of regions: 774 \nNumber of nonzero links: 4440 \nPercentage nonzero weights: 0.7411414 \nAverage number of links: 5.736434 \n1 region with no links:\n86\nLink number distribution:\n\n  0   1   2   3   4   5   6   7   8   9  10  11  12  14 \n  1   2  14  57 125 182 140 122  72  41  12   4   1   1 \n2 least connected regions:\n138 560 with 1 link\n1 most connected region:\n508 with 14 links\n\n\nIt appears that polygon from row 86 does not have a neighbor:\n\npoly2nb(nga)[86]\n\n[[1]]\n[1] 0"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#remove-regions-without-neighbors",
    "href": "take_home_ex/ex_2/ex_2.html#remove-regions-without-neighbors",
    "title": "Take Home Ex 2",
    "section": "Remove regions without neighbors:",
    "text": "Remove regions without neighbors:\nWe remove row 86 from boundary file:\n\nnga <- nga[c(1:85, 87:774),]\n\nWe do the same for the clustering variables:\n\nbind_std_cluster_vars <- bind_std_cluster_vars[c(1:85, 87:774),]\nnga_wp <- nga_wp[c(1:85, 87:774),]\nstd_cluster_vars <- std_cluster_vars[c(1:85, 87:774),]\nnga_final <- nga_final[c(1:85, 87:774),]"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#compute-the-neighbors-and-the-cost",
    "href": "take_home_ex/ex_2/ex_2.html#compute-the-neighbors-and-the-cost",
    "title": "Take Home Ex 2",
    "section": "Compute the neighbors and the cost:",
    "text": "Compute the neighbors and the cost:\n\nNeighbor\nWe will convert the boundary file to a spatial file and then feed it to the function poly2nb():\n\nnga_sp <- as_Spatial(nga)\nnga.nb <- poly2nb(nga_sp)\nsummary(nga.nb)\n\nNeighbour list object:\nNumber of regions: 773 \nNumber of nonzero links: 4440 \nPercentage nonzero weights: 0.7430602 \nAverage number of links: 5.743855 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  14 \n  2  14  57 125 182 140 122  72  41  12   4   1   1 \n2 least connected regions:\n138 560 with 1 link\n1 most connected region:\n508 with 14 links\n\n\nWe can then plot the neighbor relationship:\n\nplot(nga_sp, \n     border=grey(.5), main=\"Neighbor Map\", cex.main=4)\nplot(nga.nb, \n     coordinates(nga_sp), \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\nEdge cost and weights\nNext we will use the neighbor list and the clustering variables to compute the edge cost\nusing nbcosts() of spdep package:\n\nlcosts <- nbcosts(nga.nb, std_cluster_vars)\n\nNext we need to construct the weights taking into account the edge cost and the neighbors:\n(We need to use “B” for binary here since we want the edge cost)\n\nnga.w <- nb2listw(nga.nb, \n                   lcosts, \n                   style=\"B\")\n\nWarning in nb2listw(nga.nb, lcosts, style = \"B\"): zero sum general weights\n\nsummary(nga.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 773 \nNumber of nonzero links: 4440 \nPercentage nonzero weights: 0.7430602 \nAverage number of links: 5.743855 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  14 \n  2  14  57 125 182 140 122  72  41  12   4   1   1 \n2 least connected regions:\n138 560 with 1 link\n1 most connected region:\n508 with 14 links\n\nWeights style: B \nWeights constants summary:\n    n     nn       S0       S1       S2\nB 773 597529 2109.869 2666.155 28614.43"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#construct-minimum-spanning-tree",
    "href": "take_home_ex/ex_2/ex_2.html#construct-minimum-spanning-tree",
    "title": "Take Home Ex 2",
    "section": "Construct Minimum Spanning Tree",
    "text": "Construct Minimum Spanning Tree\nNow, using mstree() of the spdep package, we will construct the minimum spanning tree:\n\nnga.mst <- mstree(nga.w)\n\nWe now check the class:\n\nclass(nga.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\nWe also check the dimension:\n\ndim(nga.mst)\n\n[1] 772   3\n\n\nWe can check the contents of the minimum spanning tree:\n\nhead(nga.mst)\n\n     [,1] [,2]      [,3]\n[1,]  296   49 0.2877620\n[2,]  296  325 0.3152240\n[3,]  325  622 0.1296126\n[4,]  622  514 0.1773219\n[5,]  514  461 0.1267727\n[6,]  514  681 0.1891041\n\n\nFinally we can plot the minimum spanning tree as follow:\n(We will set the size of label to be small so we can see the tree)\n\nplot(nga_sp, border=gray(.5), main=\"Minimum Spanning Tree\", cex.main=4)\nplot.mst(nga.mst,\n         coordinates(nga_sp),\n         col=\"blue\",\n         cex.lab=0.1,\n         cex.circles=0.005,\n         add=TRUE)\n\n\n\n\nHousekeeping\n\nrm(lcosts)\nrm(nga.w)\nrm(nga.nb)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#compute-spatially-constrained-clusters-with-skater-method",
    "href": "take_home_ex/ex_2/ex_2.html#compute-spatially-constrained-clusters-with-skater-method",
    "title": "Take Home Ex 2",
    "section": "Compute Spatially constrained clusters with SKATER method",
    "text": "Compute Spatially constrained clusters with SKATER method\nNow that we have the minimum spanning tree, we can then compute the spatially constrained cluster using the skater() package of spdep. We will be needing the minimum spanning tree computed earlier as well as the standardized cluster variables.\nNote: the number of cuts is not equal to the number of clusters. For cluster 5, the number of cuts required is actually 4.\nWe run the code as follow:\n\nclust5 <- spdep::skater(edges = nga.mst[,1:2], \n                 data = std_cluster_vars, \n                 method = \"euclidean\", \n                 ncuts = 4)\n\n\nccs5 <- clust5$groups\n\nNext we will plot our the lines for each individual cluster:\n\nplot(nga_sp, border=gray(.1), main=\"SKATER Clusters\", cex.main=4)\nplot(clust5, \n     coordinates(nga_sp), \n     cex.lab=0.1,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"black\"),\n     cex.circles=0.005, lwd=3.0,\n     add=TRUE)\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1],\ncoords[id2, : \"add\" is not a graphical parameter\n\n\n\n\n\nLastly we can visualize our outcome with qtm() of the tmap:\n\ngroups_mat <- as.matrix(clust5$groups)\nnga_sf_spatialcluster <- cbind(nga_final, as.factor(groups_mat)) %>%\n    rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\n\ntm_shape(nga_sf_spatialcluster) + \n  tm_fill(\"SP_CLUSTER\") + \n  tm_borders(alpha = 0.9) + \n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_layout(main.title = \"Cluster Distribution of Nigeria\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) \n\n\n\n\nAfter applying the SKATER method, we not see that the clusters becomes much less fragmented. as compared to earlier.\nWe can easily compare the difference using tmap_arrange() from the tmap package:\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nnormal_cluster.map <- tm_shape(bind_std_cluster_vars) + \n                      tm_fill(\"CLUSTER\") + \n                      tm_borders(alpha = 1.0) + \n                      tm_compass(type=\"8star\", size = 2) +\n                      tm_scale_bar() +\n                      tm_grid(alpha =0.2) +\n                      tm_layout(main.title = \"Cluster Distribution of Nigeria\",\n                                main.title.position = \"center\",\n                                main.title.size = 1.2,\n                                legend.height = 0.45, \n                                legend.width = 0.35,\n                                frame = TRUE) \n\nskater_cluster.map <- tm_shape(nga_sf_spatialcluster) + \n                      tm_fill(\"SP_CLUSTER\") + \n                      tm_borders(alpha = 1.0) + \n                      tm_compass(type=\"8star\", size = 2) +\n                      tm_scale_bar() +\n                      tm_grid(alpha =0.2) +\n                      tm_layout(main.title = \"SKATER Distribution of Nigeria\",\n                                main.title.position = \"center\",\n                                main.title.size = 1.2,\n                                legend.height = 0.45, \n                                legend.width = 0.35,\n                                frame = TRUE) \n\ntmap_arrange(normal_cluster.map, skater_cluster.map,\n             asp=NA, ncol=2)\n\n\n\n\n\nHousekeeping\n\nrm(clust5)\nrm(groups_mat)\nrm(normal_cluster.map)\n# rm(skater_cluster.map)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#traditional-ward-like-clustering-with-clustgeo",
    "href": "take_home_ex/ex_2/ex_2.html#traditional-ward-like-clustering-with-clustgeo",
    "title": "Take Home Ex 2",
    "section": "Traditional Ward-Like clustering with ClustGeo",
    "text": "Traditional Ward-Like clustering with ClustGeo\nClustGeo also offers a non-spatially constrained clustering with hclustgeo() as follow:\n\nnon_geo_cluster <- hclustgeo(proxmat)\n\npng(\"plotdendogram_1.png\",width=12800,height=3200)\nplot(non_geo_cluster, cex = 1.2, lwd=3.0, main=\"Dendrogram\", \n     line = -20, cex.main=20)\n\nWarning in graphics:::plotHclust(n1, merge, height, order(x$order), hang, :\n\"line\" is not a graphical parameter\n\nWarning in graphics:::plotHclust(n1, merge, height, order(x$order), hang, :\n\"line\" is not a graphical parameter\n\nrect.hclust(non_geo_cluster, k = 5, border = 2:5)\ndev.off()\n\npng \n  2 \n\n\n\nHousekeeping:\n\nrm(non_geo_cluster)"
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#preparing-spatially-constrained-hierarchical-clustering",
    "href": "take_home_ex/ex_2/ex_2.html#preparing-spatially-constrained-hierarchical-clustering",
    "title": "Take Home Ex 2",
    "section": "Preparing Spatially Constrained Hierarchical Clustering",
    "text": "Preparing Spatially Constrained Hierarchical Clustering\nTo perform the clustering, we need 3 ingredients:\n-Distance Matrix: Represents the spatial domain\n-Proximity Matrix: Represents the variable domain\n-Mixing variable Alpha: This is required for denoting the degree of mix\n\nDistance Matrix\nWe will use st_distance() of the sf package to compute the distance matrix:\n\ndist <- st_distance(nga_final, nga_final)\ndistmat <- as.dist(dist)\n\n\n\nProximity Matrix\nSame as earlier, we will use dist() of the base R package to compute the variable proximity matrix:\n\nproxmat <- dist(std_cluster_vars, method = 'euclidean')\n\n\n\nMixing Variable Alpha\nUsing the above 2 ingredients, we can now get the third ingredient.\nWe use the function choicealpha() from the ClustGeo package as follow:\n\ncr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, \n                  graph = TRUE)\n\n\n\n\n\n\n\nFrom the graph plotted, we observe that the optimal Qnorm value is at 0.5, we will now use this as the mixing variable."
  },
  {
    "objectID": "take_home_ex/ex_2/ex_2.html#spatially-constrained-hierarchical-clustering",
    "href": "take_home_ex/ex_2/ex_2.html#spatially-constrained-hierarchical-clustering",
    "title": "Take Home Ex 2",
    "section": "Spatially Constrained Hierarchical Clustering",
    "text": "Spatially Constrained Hierarchical Clustering\nOnce the mixing variable has been determined, we can then compute the clusters using hclustgeo():\n\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.5)\n\nNow that the clusters have been calculated, we will then use cutree() to limit number of clusters to 5:\n\ngroups <- as.factor(cutree(clustG, k=5))\n\nWe will then append the cluster ID of each region to the nga_final dataframe and save as a new sf:\n\nnga_sf_Gcluster <- cbind(nga_final, as.matrix(groups)) %>%\n                  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nclustgeo_cluster.map <- tm_shape(nga_sf_Gcluster) + \n                      tm_fill(\"CLUSTER\") + \n                      tm_borders(alpha = 1.0) + \n                      tm_compass(type=\"8star\", size = 2) +\n                      tm_scale_bar() +\n                      tm_grid(alpha =0.2) +\n                      tm_layout(main.title = \"ClustGeo Distribution of Nigeria\",\n                                main.title.position = \"center\",\n                                main.title.size = 1.2,\n                                legend.height = 0.45, \n                                legend.width = 0.35,\n                                frame = TRUE) \nclustgeo_cluster.map\n\n\n\n\nUsing tmap_arrange(), we will do a comparison:\n\ntmap_arrange(skater_cluster.map, clustgeo_cluster.map,\n             asp=NA, ncol=2)\n\n\n\n\nComparing the SKATER and the clustGeo, we see that clustGeo is less strict on geographical relationship."
  }
]