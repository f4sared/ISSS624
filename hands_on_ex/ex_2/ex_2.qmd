---
title: "Hand on ex 2 - Chap 4 Global and Local Measures of Spatial Autocorrelation"
editor: visual
---

# Overview:

# Step 1: Check and load packages

\*\*We will use the additional "here" package

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse, here)
```

# Step 2: Loading Data into R

We first generate the shape file path:

```{r}
shapefile_path <- here("data", "dataHunan", "geospatial")
shapefile_path
```

Next we load in the shape file using the path generated:

```{r}
hunan <- st_read(dsn = shapefile_path, layer = "Hunan")

```

We check the loaded shapefile:

```{r}
glimpse(hunan)
```

We generate the csv file path:

```{r}
csv_path <- here("data", "dataHunan", "aspatial", "Hunan_2012.csv")
csv_path
```

We then load the csv file:

```{r}
hunan_2012 <- read_csv(csv_path)
```

# Step 3: Prepare the data

We perform a relational join:

\*\*Auto detect, join by "County"

```{r}
hunan <- left_join(hunan, hunan_2012)
```

Step 3: Visualize the Regional Development Indicator

\*\*Note: qtm() belongs to tmap

\*\*qtm() offers less control, for more professional option, use tm_shape instead

```{r}
equal <- tm_shape(hunan)+
          tm_fill("GDPPC", n=5, style = "equal")+
          tm_borders(alpha = 0.5)+
          tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(hunan)+
          tm_fill("GDPPC", n=5, style = "quantile")+
          tm_borders(alpha=0.5)+
          tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

## Minor notes:

Useful Links:

-   <https://bookdown.org/nicohahn/making_maps_with_r5/docs/tmap.html>

-   <https://www.rdocumentation.org/packages/classInt/versions/0.4-8/topics/classIntervals>

style = pretty: Rounds interval boundaries to whole numbers. Default setting.

style = equal: Splits the variable into intervals of equal length. Should only be used if the variable follows an uniform distribution.

style = quantile: Splits the variable into quantiles. Consequently there are the same number of observations in each interval.

style = jenks: Identifies groups with similar values and maximizes the difference between them.

style = cont: Displays many colors over a continuous palette.

style = cat: Colors each category individually for categorical data.

# Step 4: Compute the spatial weights

Construct the spatial weight based on the "Queen" contiguity:

\*\*polyn2b means: polygons to neighbor list

```{r}
wm_q <- poly2nb(hunan, queen=TRUE)
```

\*\*Question:\
What is the order of the poly2nb here ? How many layers of neighbors are considered here ?\
It appears poly2nb only consider the first order neighbor.

Useful Link:

-   <https://search.r-project.org/CRAN/refmans/geomerge/html/geomerge.neighbor.html>

\*\*Note: for more robust option use style B

\*\*This is because style W will create weakness for the polygon at the edges due to less neighbor

------------------------------------------------------------------------

Taken from:

-   <https://r4gdsa.netlify.app/chap04.html>

Style can take values "W", "B", "C", "U", "minmax" and "S". B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).

------------------------------------------------------------------------

Generate the row standardized weight matrix:

```{r}
rswm_q <- nb2listw(wm_q, style="W", zero.policy =TRUE)
rswm_q
```

# Step 5: Moran's I

Take not that for the Moran's I test, there are 2 methods:

-   Analytical Method:\
    This is a single step calculation.

-   Monte Carlo Method:\
    For Monte Carlo Method, we will take samples randomly with replacements to create lots and lot of datasets. For each of the datasets, we will then compute the Moran's I value. We will then plot a histogram of the values. The resultant Moran's I value should be as far as possible away from the mean for a good indication of spatial auto correlation.

Useful ink for study:

-   <https://mgimond.github.io/simple_moransI_example/>

-   <https://web.pdx.edu/~abrasch/GEOG597/Lab3_spatial_autocorrelation_AlexBrasch.html#moran%E2%80%99s_i_scatter_plot>

-   <https://rpubs.com/spring19cp6521/Week12_Wednesday1>

## Moran's I Test:

\*\*moran.test() belongs to spdep

\*\*Are we testing against randomization or normality ?

```{r}
moran.test(hunan$GDPPC, listw=rswm_q, zero.policy = TRUE, na.action = na.omit)
```

Useful Link:

-   <https://bookdown.org/lexcomber/brunsdoncomber2e/morans-i-an-index-of-autocorrelation.html> \>\> Moran' I eigen value code

-   <https://www.youtube.com/watch?v=_FtR878eic4> \>\> Moran's I explained

-   <https://www.youtube.com/watch?v=MPcNT0KUym0> \>\> Moran's I ranging with eigen values

When Moran's I is 0, it means the points are distributed randomly across the space.\
When Moran's I is 1, it means that similar values tend to cluster.\
Our P-value is 0.000001, which is really significant.

We calculate the Moran's I eigen value range:

\*\*Note: The Moran's I range is dependent on the inputs !

```{r}
moran.range <- function(lw) {
  wmat <- listw2mat(lw)
  return(range(eigen((wmat + t(wmat))/2)$values))
}
moran.range(rswm_q)
```

Our Moran's estimate is 0.300 which is closer to 1.032 than -0.733.

## Monte Carlo Moran's I:

```{r}
set.seed(1234)
bperm <- moran.mc(hunan$GDPPC, listw = rswm_q, nsim = 999, zero.policy = TRUE, na.action = na.omit)
bperm
```

Here we observe a similar Moran's I value above.\
However, the p-value is now less significant as compared to the first test.

### Plot the Monte Carlo Moran's I:

\*\*Why Monte Carlo ?

\*\*Monte Carlo is a statistical method that generates multiple datasets using random sampling.

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 
```

Plot using ggplot:

Useful Links:

-   <https://sparkbyexamples.com/r-programming/convert-list-to-r-dataframe/>

-   <https://www.projectpro.io/recipes/change-column-headers-of-dataframe-r#:~:text=How%20to%20change%20column%20headers%20of%20a%20data%2Dframe%20in,can%20be%20changed%20at%20once.>

Create a dataframe:

```{r}
xx <- data.frame(bperm$res)
```

```{r}
colnames(xx)[1]  <- "res" 
```

Plot using ggplot:

```{r}
ggplot(data=xx, aes(x= as.numeric(`res`)))+
    geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
    labs(title = "Distribution of DEPENDENCY",
      x = "Moran's I",
      y = "Frequency")
```

# Step 6: Geary's C

## Geary's C test:

```{r}
geary.test(hunan$GDPPC, listw = rswm_q)
```

Here we see a small p-value of 0.0001 which makes it statistically significant.\
For Geary's C, 1 means pure randomization. \< 1 means clustering. \> 1 means dispersed.\
Our value is 0.69, which tends towards some clustering.

## Monte Carlo Geary's C:

```{r}
set.seed(1234)
bperm=geary.mc(hunan$GDPPC, 
               listw=rswm_q, 
               nsim=999)
bperm
```

Here, we see a higher P-Value which is less statistically significant.\
The statistic value remains to be similar.

### Plot the Monte Carlo:

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Geary c")
abline(v=1, col="red") 
```

# Step 7: Spatial Correlogram

Correlogram allows us the ability to study the variation of the spatial correlation as it evolves across space. In a certain manner, it allows us to get a feel of the gradient as the lag increases. For our purposes, the lag refers mainly to the spatial distance. In other cases, the lag can be that of time. For example, the weather today may be highly correlated with the weather the next day and the day after. However, from the 4th day onward, we observe less and less correlation.

Useful Links:

-   <https://www.ecologycenter.us/vegetation-ecology/correlograms-morans-i.html>

-   <https://www.youtube.com/watch?v=Aft25mI1ffw>

## Moran's I

```{r}
MI_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="I", 
                          style="W")
plot(MI_corr)
```

```{r}
print(MI_corr)
```

As we increase the order of lag, the Moran's I value decreases. From a lag value of 3 onwards, we observe less indication of clustering.

## Geary's C

```{r}
GC_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="C", 
                          style="W")
plot(GC_corr)
```

```{r}
print(GC_corr)
```

As we increase the lag, the C value increases, which shows less clustering. From a lag of 3 onwards, we observe less clustering.

# Step 8: Cluster and Outlier Analysis

Ever wondered why the local Moran's I value is bigger than 1 ?

This has to do with the eigen values, check the useful link below:

-   <https://www.researchgate.net/post/What-about-extrem-value-of-Local-Morans-Index#:~:text=Typically%20Moran%20Index%20value%20should,of%20%2D1%20to%20%2B4.>

Compute Local Moran I:

```{r}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

```{r}
printCoefmat(data.frame(localMI[fips,], row.names=hunan$County[fips]), check.names=FALSE)
```

Append output to dataframe:

```{r}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

Map the local Moran I

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

\*\*Question, why is the Moran's I value here \> 1 ?

Map Local Moran I P-value:

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

Plot both maps together:

```{r}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

# Step 9: Creating the LISA Cluster Map:

LISA stands for "Local Indication of Spatial Association".

The first step to generating the LISA is to plot the Moran Scatterplot.

## Plot Moran's scatterplot:

Useful link:

-   <https://www.youtube.com/watch?v=G_l0xkuQUSs>

Moran's plot is interesting because it plots the variable under study as the X-Axis, while the lagged variable will be plotted as the Y-Axis. The lagged variable in our cases is the average value of the neighbor surrounding our individual polygon. If the average neighbor value is close to the own value, the point will then fall on a straight line. The straight line is our Moran's I.

Take note that the top left quadrant and the bottom right signals to us that the variable of a polygon is not similar to the values the neighbor.

```{r}
nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels=as.character(hunan$County), 
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")
```

## Plot Moran's scatterplot with standardized variable:

Why do we need to do this ? What is the use ?

```{r}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% as.vector 
```

```{r}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```

## Preparing LISA map classes:

We create a empty vector based on the number of rows in the localMI:

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

Center the variable of interest around the mean:

```{r}
DV <- hunan$GDPPC - mean(hunan$GDPPC)  
```

Center the local Moran's I around the mean:

```{r}
C_mI <- localMI[,1] - mean(localMI[,1])    
```

Set the statistical significance level for the local Moran:

```{r}
signif <- 0.05       
```

Perform the first filter:

\*\*Note the order here is questionable, need to clarify further

```{r}
quadrant[DV >0 & C_mI>0] <- 4      
quadrant[DV <0 & C_mI<0] <- 1      
quadrant[DV <0 & C_mI>0] <- 2
quadrant[DV >0 & C_mI<0] <- 3
```

Place non-significant Moran in category 0:

```{r}
quadrant[localMI[,5]>signif] <- 0
```

## Plotting the LISA Map:

Interpreting the LISA Map:

-   <https://www.e-education.psu.edu/geog586/node/673>

```{r}
hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

# Step 10: Getis & Ord's G-Statistics

Useful Link:

-   <https://www.youtube.com/watch?v=IDkH9AOpoos>

-   <https://www.youtube.com/watch?v=ZUEZUbK7K_U>

-   <https://popcenter.asu.edu/sites/default/files/conference/conferencepapers/2010/Chainey-Gi-hotSpots.pdf>

\*\*Note Gi\* includes the central point in the evaluation while Gi does not.

## Deriving Spatial Weight Matrix

### Distance Based Matrix

Get Centroid:

Value 1:

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

Value 2:

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Bind the coordinate into 1 object:

```{r}
coords <- cbind(longitude, latitude)
```

Determine the cutoff distance using the k nearest neighbors:

```{r}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

Compute the fixed distance weight matrix:

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Convert into spatial weights object

```{r}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

### Adaptive distance weight Matrix

Here we will enforce the condition that the number of neighbor for each polygon has to be 8:

```{r}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

Convert to spatial weight object:

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

## Computing Gi Statistics

### Using Fixed Distance

```{r}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

Join the data to dataframe:

```{r}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

We observe high level of significance of spatial concentration in the most central area highlighted by the red zone. However, we observe a steep change in the significance gradient of the local Gi score.

### Using adaptive distance:

Compute using adaptive weights:

```{r}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

```{r}
gdppc<- qtm(hunan, "GDPPC")

Gimap <- tm_shape(hunan.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, 
             Gimap, 
             asp=1, 
             ncol=2)
```

Again, we observe a high level of spatial concentration significance in the areas highlighted in red. However, this time, we get a larger patch and a more gentle gradient distribution.

## Thoughts:

So apparently using different measures of distance weight matrix can have quite a big effect on the interpretation of the hotspot analysis. The question then lies in the motivation for selecting the different kinds of spatial weight matrix since they can produce different results.
