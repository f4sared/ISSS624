---
title: "In Class Ex5 - Spatially Weighted Regression"
editor: visual
---

# Overview

Packages used:

-   here: used to generate the file path to a specific folder
-   tidyverse
    -   readr: for reading rectangular files
-   sf: Used to handle spatial dataframes
-   funModeling: Used for plotting and EDA
-   tmap: Use for plotting geo spatial maps
-   skimr: provides summary statistics about variables in the dataframe
-   corrplot: Used for performing correlation analysis
-   blorr: Used to generate a report for our logistic regression model
-   caret: Package for confusion matrix

# Step 1: Load the required packages

```{r}
# pacman::p_load(here,
#                sf, tidyverse, spdep,
#                funModeling, tmap, ggpubr,
#                corrplot, heatmaply, cluster, ClustGeo, factoextra, GGally,
#                blorr, skimr, caret, GWmodel,report
#                )
```

We load the packages as follow:

```{r}
pacman::p_load(here, sf, tidyverse, funModeling, tmap,
               skimr, corrplot, blorr, GWmodel, caret
              )
```

We create the boundary path with the here() function:

```{r}
boundary_path <- here("data", "dataOsun", "Osun.rds")
boundary_path
```

We create the path to the water point data:

```{r}
data_path <- here("data", "dataOsun", "Osun_wp_sf.rds")
data_path
```

Using read_rds() from readr (tidyverse):

```{r}
osun <- read_rds(boundary_path)
```

Using read_rds() from readr (tidyverse):

```{r}
osun_wp_sf <- read_rds(data_path)
```

Using freq() from funModeling, we explore the status distribution:

```{r}
osun_wp_sf %>% freq(input = 'status')
```

Using the tmap package, we will plot the functional and non-functional water points:

```{r}
#| eval: true
tmap_mode('view')
tm_shape(osun)+
  tm_polygons(alpha=0.4)+
  tm_shape(osun_wp_sf) + 
  tm_dots(col="status", alpha = 0.6) + 
  tm_view(set.zoom.limits = c(9,12))
```

# Step 2: EDA

Using the skim() from skimr package, we obtain the summary statistics as follow:

```{r}
#| eval: true
osun_wp_sf %>% skim() 
```

# Step 3: Selecting variables

Next, we will filter away the rows with na under the columns that we are interest in. We will also recode the usage_capacity as factor instead of the numerical form. This is done in preparation for the logistic regression.

We run the code as follow:

```{r}
#| eval: true
osun_wp_sf_clean <- osun_wp_sf %>% 
  filter_at(vars(status,
                 distance_to_primary_road,
                 distance_to_secondary_road,
                 distance_to_tertiary_road,
                 distance_to_city,
                 distance_to_town,
                 water_point_population,
                 local_population_1km,
                 usage_capacity,
                 is_urban,
                 water_source_clean),
            all_vars(!is.na(.))) %>% 
  mutate(usage_capacity = as.factor(usage_capacity))
```

Next we select the columns that we want:

```{r}
#| eval: true
osun_wp <- osun_wp_sf_clean %>% select(c(7,35:39,42:43,46:47,57)) %>% st_set_geometry(NULL)
```

# Step 4: Correlation Analysis:

Next, we perform correlation analysis using cor() function of corrplot:

```{r}
#| eval: true
cluster_vars.cor = cor(osun_wp[,2:7])
corrplot.mixed(cluster_vars.cor,
               lower="ellipse",
               upper = "number",
               tl.pos="lt",
               diag="l",
               tl.col="black")
```

From the corrplot above, we do not see any variables that are highly correlated. We can then proceed with building a simple logistic regression model

# Step 5: Building a simple logistic regression model

## Logistic Regression Model

Using the glm() of the R statistics, we build a logistic regression model as follow:

```{r}
#| eval: true
model <- glm(status ~ distance_to_primary_road +
               distance_to_secondary_road + 
               distance_to_tertiary_road + 
               distance_to_city + 
               distance_to_town + 
               is_urban +
               usage_capacity + 
               water_source_clean + 
               water_point_population + 
               local_population_1km,
             # data = osun_wp_sf_clean,
             data = osun_wp, 
             family = binomial(link = "logit"))
```

## Model Report

Next we use blr_regress() of blorr to provide us a report on our model:

```{r}
#| eval: true
blr_regress(model)
```

The report shows us that at 95% confidence level, all the variables are significant except distance to primary road and the distance to secondary road.

Note from class:

-   Categorical variable z value: +ve value implies above average correlation while -ve value implies a below average correlation.

-   Continuous variable z value: +ve value implies direct correlation while -ve value implies inverse correlation.

## Confusion Matrix

Next, using blr_confusion_matrix() of blorr, we generate a confusion matrix as follow:

```{r}
#| eval: true 
blr_confusion_matrix(model, cutoff=0.5)
```

Notes from class:

The cutoff value of 0.5 means that any probability above 0.5 gets classified as true, while other values get classified as false. The default value we generally use is 0.5.

-   Sensitivity: TP/(TP/FN) \>\> 0.7207

-   Specificity: TN/(TN+FP) \>\> 0.6154

-   Accuracy: (TP+TN)/(TP+FP+TN+FN)

Since sensitivity is higher than the specificity, our model is better at catching true positives than catching true negatives.

# Step 6: Spatially weighted geographical regression gwLR model

## Converting to spatial data

Notes: In the past, spatial data used to be the common currency in model building. So many functions still take in spatial data. Hence the conversion is needed. The simple features dataframe only came in recently.

First we need to convert to spatial data as follow:

```{r}
#| eval: true 
osun_wp_sp <- osun_wp_sf_clean %>% 
  select(c(status,
           distance_to_primary_road,
           distance_to_secondary_road,
           distance_to_tertiary_road,
           distance_to_city,
           distance_to_town,
           water_point_population,
           local_population_1km,
           is_urban,
           usage_capacity,
           water_source_clean)) %>% as_Spatial() 
osun_wp_sp
```

## Determine the fixed bandwidth

Using bw.ggwr() from GWmodel package, we will next determine the fixed bandwidth:

```{r}
#| eval: false
bw.fixed <- bw.ggwr(status ~ 
                      distance_to_primary_road + 
                      distance_to_secondary_road+
                      distance_to_tertiary_road +
                      distance_to_city+
                      distance_to_town+
                      water_point_population+
                      local_population_1km+
                      is_urban+
                      usage_capacity+
                      water_source_clean,
                    data=osun_wp_sp,
                    family="binomial",
                    approach="AIC",
                    kernel = "gaussian",
                    adaptive = FALSE,
                    longlat = FALSE)
```

```{r}
#| eval: false
bw.fixed
```

## Creating the model

using ggwr.basic() from the GWmodel, we will build the model as follow:

```{r}
#| eval: true
gwlr.fixed <- ggwr.basic(status ~
                           distance_to_primary_road + 
                           distance_to_secondary_road + 
                           distance_to_tertiary_road + 
                           distance_to_city + 
                           distance_to_town + 
                           water_point_population + 
                           local_population_1km + 
                           is_urban + 
                           usage_capacity + 
                           water_source_clean,
                         data=osun_wp_sp,
                         bw=2599.672,
                         family = "binomial",
                         kernel = "gaussian",
                         adaptive = FALSE,
                         longlat = FALSE)
```

We get the results as follow:

```{r}
#| eval: true
gwlr.fixed
```

A lower AIC indicated a better fit model.

## Confusion Matrix

We will convert the SDF object to a dataframe first:

```{r}
#| eval: true
gwr.fixed <- as.data.frame(gwlr.fixed$SDF)
```

Next, we will change the probability to True or False:

```{r}
#| eval: true
gwr.fixed <- gwr.fixed %>% mutate(most=ifelse(gwr.fixed$yhat >= 0.5, T, F))
```

Using confusionMatrix() of the caret package we run the following code:

```{r}
#| eval: true
gwr.fixed$y <- as.factor(gwr.fixed$y)
gwr.fixed$most <- as.factor(gwr.fixed$most)
CM <- confusionMatrix(data=gwr.fixed$most, reference = gwr.fixed$y, positive = "TRUE")
CM
```

Here we see a big improvement in accuracy, sensitivity & specificity. Thus by incorporating the geographical weights, we have now obtained a better model with better excitability.

# Step 7: Visualizing the results

First we will select the required columns:

```{r}
#| eval: true
osun_wp_sf_selected <- osun_wp_sf_clean %>% select(c(ADM2_EN, ADM2_PCODE,
                                                     ADM1_EN, ADM1_PCODE,
                                                     status))
```

Next we will cbind the earlier model results to get a new dataframe for plotting:

```{r}
#| eval: true
gwr_sf.fixed <- cbind(osun_wp_sf_selected, gwr.fixed)
```

We plot the map as follow:

```{r}
#| eval: true
tmap_mode("view")
prob_T <- tm_shape(osun) + 
  tm_polygons(alpha=0.1) + 
  tm_shape(gwr_sf.fixed) + 
  tm_dots(col="yhat",
          border.col = "gray60",
          border.lwd = 1) + 
  tm_view(set.zoom.limits = c(9,14))

actual <- tm_shape(osun) + 
  tm_polygons(alpha=0.1) + 
  tm_shape(gwr_sf.fixed) + 
  tm_dots(col="status",
          border.col = "gray60",
          border.lwd = 1) + 
  tm_view(set.zoom.limits = c(9,14))

tmap_arrange(actual, prob_T, 
             asp = 1, ncol = 2, sync = TRUE)
```

## Show only false results

We perform a simple filter:

```{r}
#| eval: true
false_results <- gwr_sf.fixed %>% filter(status == "FALSE")
```

Next we plot as normal:

```{r}
#| eval: true
tmap_mode("view")
prob_T_false <- tm_shape(osun) + 
  tm_polygons(alpha=0.1) + 
  tm_shape(false_results) + 
  tm_dots(col="yhat",
          border.col = "gray60",
          border.lwd = 1) + 
  tm_view(set.zoom.limits = c(9,14))

actual <- tm_shape(osun) + 
  tm_polygons(alpha=0.1) + 
  tm_shape(false_results) + 
  tm_dots(col="status",
          border.col = "gray60",
          border.lwd = 1) + 
  tm_view(set.zoom.limits = c(9,14))

tmap_arrange(actual, prob_T_false, 
             asp = 1, ncol = 2, sync = TRUE)
```

Here we can see that among the false results, there are quite a few false negatives.

# Step 8: gwlr with only statistically significant variables

## Determine new fixed bandwidth

```{r}
#| eval: false
bw.fixed_new <- bw.ggwr(status ~ 
#                     distance_to_primary_road + 
#                     distance_to_secondary_road+
                      distance_to_tertiary_road +
                      distance_to_city+
                      distance_to_town+
                      water_point_population+
                      local_population_1km+
                      is_urban+
                      usage_capacity+
                      water_source_clean,
                    data=osun_wp_sp,
                    family="binomial",
                    approach="AIC",
                    kernel = "gaussian",
                    adaptive = FALSE,
                    longlat = FALSE)
```

```{r}
#| eval: false
bw.fixed_new
```

## Creating the new model

Using the new bandwidth, we create the new model

```{r}
#| eval: true
gwlr.fixed_new <- ggwr.basic(status ~
                           distance_to_tertiary_road + 
                           distance_to_city + 
                           distance_to_town + 
                           water_point_population + 
                           local_population_1km + 
                           is_urban + 
                           usage_capacity + 
                           water_source_clean,
                         data=osun_wp_sp,
                         bw=2377.371,
                         family = "binomial",
                         kernel = "gaussian",
                         adaptive = FALSE,
                         longlat = FALSE)
```

```{r}
#| eval: true
gwlr.fixed_new
```

## Confusion Matrix

Next we will make a dataframe from the earlier created model:

```{r}
#| eval: true
gwlr.fixed_new <- as.data.frame(gwlr.fixed_new$SDF)
```

We will then assign TRUE or FALSE based on the output probability:

```{r}
#| eval: true
gwr.fixed_new <- gwlr.fixed_new %>% mutate(most=ifelse(gwlr.fixed_new$yhat >= 0.5, T, F))
```

Then we can plot the confusion matrix as follow:

```{r}
#| eval: true
gwr.fixed_new$y <- as.factor(gwr.fixed_new$y)
gwr.fixed_new$most <- as.factor(gwr.fixed_new$most)
CM <- confusionMatrix(data=gwr.fixed_new$most, reference = gwr.fixed_new$y, positive = "TRUE")
CM
```

From the results, we can see that by taking geographical relationships into account, we are then able to obtain a better model with higher accuracy. The improvement in the models ability to explain is also shown in the improvement in the sensitivity and specificity values.

# Step 9: Visualizing the new results

Let's then combine the earlier results with the region boundary data in order to plot:

```{r}
gwr_sf.fixed_new <- cbind(osun_wp_sf_selected, gwr.fixed_new)
```

```{r}
#| eval: true
tmap_mode("view")
prob_T_new <- tm_shape(osun) + 
  tm_polygons(alpha=0.1) + 
  tm_shape(gwr_sf.fixed_new) + 
  tm_dots(col="yhat",
          border.col = "gray60",
          border.lwd = 1) + 
  tm_view(set.zoom.limits = c(9,14))

actual <- tm_shape(osun) + 
  tm_polygons(alpha=0.1) + 
  tm_shape(gwr_sf.fixed_new) + 
  tm_dots(col="status",
          border.col = "gray60",
          border.lwd = 1) + 
  tm_view(set.zoom.limits = c(9,14))

tmap_arrange(actual, prob_T_new, 
             asp = 1, ncol = 2, sync = TRUE)
```

## Show only false results

We perform a simple filter for only false results

```{r}
#| eval: true
false_results_new <- gwr_sf.fixed_new %>% filter(status == "FALSE")
```

Next we visualize the plot:

```{r}
#| eval: true
tmap_mode("view")
prob_T_false_new <- tm_shape(osun) + 
  tm_polygons(alpha=0.1) + 
  tm_shape(false_results_new) + 
  tm_dots(col="yhat",
          border.col = "gray60",
          border.lwd = 1) + 
  tm_view(set.zoom.limits = c(9,14))

tmap_arrange(prob_T_false, prob_T_false_new, 
             asp = 1, ncol = 2, sync = TRUE)
```

In the above plot, only the false results are plotted. Since all are false results, in the ideal world, we should only be seeing the white color dots instead of the darker color dots. The left plot is the original prediction from the earlier model while the right plot is the result from the new models with insignificant variables removed.

We see that for certain water points on the right plot, the color intensity actually decreased which shows the improvement of the model's explain ability.

However, it is clear that for certain waterpoints, the false positive is still high. This means that additional data may still be needed to fully explain the results.
