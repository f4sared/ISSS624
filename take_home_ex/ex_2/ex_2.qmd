---
title: "Take Home Ex 2"
editor: visual
---

# Overview

[**Files required for Take Home Ex 2:**]{.underline}

Water point attribute data (exported as CSV file):\
<https://www.waterpointdata.org/access-data/>\
Click on the button "Access WPdx+ Global Data Repository"\
Then click export button & download as CSV file

Nigeria Administrative Level 2 Boundary File:\
<https://www.geoboundaries.org/>\
Enter "Nigeria" in the name filter column.\
Download Nigeria-NGA-ADM2-2022 under the column "geoBoundaries"

Column Description can be found at:\
<https://www.waterpointdata.org/wp-content/uploads/2021/04/WPDx_Data_Standard.pdf>

# Step 1: Importing the required packages

The following packages are imported:

-   here: We use this to generate a path to the file stored at the root directory

-   sf: We use this for manipulation of simple features

-   tmap: We use for thematic plotting

-   tidyverse (<https://www.tidyverse.org/>)

    -   ggplot2

    -   dplyr: Used for data manipulation (e.g. mutate() )

    -   readr: We use this for reading rectangular data like csv

-   corrplot: For plotting of the correlation object

```{r}
pacman::p_load(here,
               sf, tidyverse, dplyr, 
               funModeling, tmap,
               corrplot
               )
```

# Step 2: Shrinking the CSV file

Since the CSV file is really huge, we need to shrink it down first so we can store a copy of it on github. To do this, we will import the CSV file and then only select the rows that we are keen to keep using the select() function. The CSV will initially be imported as a tibble file format, thereafter once we select our referred columns, we also need to convert geometry coordinate before finally saving it as a rds file.

Using the here() function, we will generate a path to where the large csv file is stored:

```{r}
#| eval: true
csv_path <- here("data", "dataNigeria_2", "waterpoint", "wpdx.csv")
csv_path
```

We will use the read_csv() of the readr package to ingest the CSV file:

```{r}
#| eval: false
wp_nga <- read_csv(csv_path) %>% filter(`#clean_country_name` == "Nigeria")
```

We will use the select() to keep only columns of interest:

```{r}
#| eval: false
wp_nga_out <- wp_nga %>% select(7:10, 13:14, 22, 46:47, 62)
```

Using st_as_sfc() of the sf package, we derive a new "Geometry" column based on \`New Georeferenced Column\`. This is because the column is as actually holding data in textual format.

We run the code as follow:

```{r}
#| eval: false
wp_nga_out$Geometry = st_as_sfc(wp_nga_out$`New Georeferenced Column`)
```

Next using st_sf() of the sf package, we will convert the current object to sf dataframe:

```{r}
#| eval: false
wp_nga_out <- st_sf(wp_nga_out, crs=4326) 
```

Since the column \`New Georeferenced Column\` is no longer needed, we exclude it:

```{r}
#| eval: false
wp_nga_out <- wp_nga_out %>% select(1:9, 11)
```

To save the file, we need to generate a save path:

```{r}
#| eval: true
savefile_path <- here("data", "dataNigeria_2", "waterpoint", "wp_nga_v2.rds")
savefile_path
```

We then save the dataframe as a rds file:

```{r}
#| eval: false
write_rds(wp_nga_out, savefile_path)
```

# Step 3: Loading the data

## Load the water point data:

Now, using the read_rds of the readr package, we load the data as follow:\
(we will rename all the columns for ease of work)\
(we will also replace all N/A values of the status with "Unknown")

```{r}
wp_nga <- read_rds(savefile_path) %>%
    rename(`status`=`#status_clean`) %>%
    rename(`adm1`=`#clean_adm1`) %>%
    rename(`adm2`=`#clean_adm2`) %>% 
    rename(`tech_clean`=`#water_tech_clean`) %>%
    rename(`tech_category`=`#water_tech_category`) %>%
    mutate(status = replace_na(status, "Unknown")) %>%
    mutate(tech_category = replace_na(tech_category, "Unknown")) %>% 
    mutate(tech_clean = replace_na(tech_clean, "Unknown"))
```

We will now use the st_geometry of the sf package to look at our data info:

```{r}
st_geometry(wp_nga)
```

## Load the Geo Boundary data:

Once again, we need to generate the path as follow:

```{r}
boundary_path <- here("data", "dataNigeria_2", "boundary")
boundary_path
```

Using the st_read() function of the sf package, we will load the boundary file:

```{r}
nga <- st_read(dsn = boundary_path,
               layer = "geoBoundaries-NGA-ADM2",
               crs = 4326) %>% select(shapeName)
```

## Handling Repeated Names

We refer to our classmates' method:\
<https://jordan-isss624-geospatial.netlify.app/posts/geo/geospatial_exercise/#data-wrangling>

Get the index of the rows that are duplicated

```{r}
bool_list <- duplicated(nga$shapeName)
duplicated_names <- nga$shapeName[bool_list]
index_rows <- which(nga$shapeName %in% duplicated_names)
index_rows
```

Select rows that are duplicated

```{r}
dup_rows <- nga %>% filter(nga$shapeName %in% duplicated_names)
dup_rows$shapeName
```

Plot the areas that are duplicated:

```{r}
#| eval: false
tmap_mode("view")
tm_shape(dup_rows) + tm_polygons()
```

Rename the duplicated areas

```{r}
nga$shapeName[index_rows] <- c("Bassa_1", "Bassa_2", 
                               "Ifelodun_1", "Ifelodun_2",
                               "Irepodun_1", "Irepodun_2",
                               "Nasarawa_1", "Nasarawa_2",
                               "Obi_1", "Obi_2",
                               "Surulere_1","Surulere_2")
```

Check to see if there are any repeated rows again:

```{r}
bool_list <- duplicated(nga$shapeName)
duplicated_names <- nga$shapeName[bool_list]
index_rows <- which(nga$shapeName %in% duplicated_names)
index_rows
```

# Step 4: Data Wrangling

## Status of water point

Using the freq() from funModeling, we will check the distribution of status of the water points:

```{r}
freq(data=wp_nga, input = 'status')
```

### Functional water point

```{r}
wpt_functional <- wp_nga %>%
  filter(status %in%
           c("Functional",
             "Functional but not in use",
             "Functional but needs repair"))
```

```{r}
#| eval: false
freq(data=wpt_functional, 
     input = 'status')
```

### Non Functional water point

```{r}
wpt_nonfunctional <- wp_nga %>%
  filter(status %in%
           c("Abandoned/Decommissioned", 
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
```

```{r}
#| eval: false
freq(data=wpt_nonfunctional, 
     input = 'status')
```

### Unknown

```{r}
wpt_unknown <- wp_nga %>% filter(status == "Unknown")
```

## Water point Technology

```{r}
wpt_hand_pump <- wp_nga %>% filter(tech_category == "Hand Pump")
```

```{r}
#| eval: false
freq(data=wp_nga, input = 'tech_category')
```

## Usage Capacity

```{r}
wpt_1000 <- wp_nga %>% filter(usage_capacity < 1000)
```

```{r}
#| eval: false
freq(data=wp_nga, input = 'usage_capacity')
```

## Rural waterpoints

```{r}
wpt_rural <- wp_nga %>% filter(is_urban == FALSE)
```

```{r}
#| eval: false
freq(data=wp_nga, input = 'is_urban')
```

## Point-in-Polygon

Point in polygon

```{r}
#| eval: true
nga_wp <- nga %>%
  mutate(`total_wpt` = lengths(
    st_intersects(nga, wp_nga))) %>%
  mutate(`wpt_functional` = lengths(
    st_intersects(nga, wpt_functional))) %>%
  mutate(`wpt_non_functional` = lengths(
    st_intersects(nga, wpt_nonfunctional))) %>%
  mutate(`wpt_unknown` = lengths(
    st_intersects(nga, wpt_unknown))) %>% 
  mutate(`wpt_hand_pump` = lengths(
    st_intersects(nga, wpt_hand_pump))) %>%
  mutate(`wpt_1000` = lengths(
    st_intersects(nga, wpt_1000))) %>% 
  mutate(`wpt_rural` = lengths(
    st_intersects(nga, wpt_rural))) 
```

Calculate Percentage

```{r}
#| eval: true
nga_wp <- nga_wp %>%
  mutate(pct_functional = `wpt_functional`/`total_wpt`) %>%
  mutate(`pct_non_functional` = `wpt_non_functional`/`total_wpt`) %>% 
  mutate(`pct_hand_pump` = `wpt_hand_pump`/`total_wpt`) %>% 
  mutate(`pct_1000` = `wpt_1000`/`total_wpt`) %>%
  mutate(`pct_rural` = `wpt_rural`/`total_wpt`)
```

Replace NaN with 0

```{r}
#| eval: true
NaN_list <- is.nan(nga_wp$pct_functional)
nga_wp$pct_functional[NaN_list] <- 0

NaN_list <- is.nan(nga_wp$pct_non_functional)
nga_wp$pct_non_functional[NaN_list] <- 0

NaN_list <- is.nan(nga_wp$pct_hand_pump)
nga_wp$pct_hand_pump[NaN_list] <- 0

NaN_list <- is.nan(nga_wp$pct_hand_pump)
nga_wp$pct_hand_pump[NaN_list] <- 0

NaN_list <- is.nan(nga_wp$pct_less_1000)
nga_wp$pct_1000[NaN_list] <- 0

NaN_list <- is.nan(nga_wp$pct_rural)
nga_wp$pct_rural[NaN_list] <- 0
```

```{r}
#| eval: false
qtm(nga_wp, fill = "wpt hand pump") + 
    tm_layout(legend.height = 0.4,legend.width = 0.4)
```

# Step 6: Correlation Analysis

Get correlation variables as follow:

```{r}
corr_data <- nga_wp[,c(4:5, 10:14)] %>% st_set_geometry(NULL)
```

In order to perform correlation analysis, we need to get the correlation matrix using cor() from the base R package, then we can plot it using the corrplot.mixed() function from corrplot package.

Perform correlation analysis:

```{r}
#| eval: false
cluster_vars.cor = cor(corr_data)
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

From the correlation plot above, we notice that the percentage of hand pump is highly negatively correlated with the percentage of well with 1000 capacity. Because the value is not that high extremely high, we always include it in the analysis at another time.

# Step 7: Hierarchy Cluster Analysis

# Playing Test

get the clustering variables

```{r}
#| eval: false
cluster_vars <- nga_wp %>%
  st_set_geometry(NULL) %>%
  select("shapeName", "wpt_functional", "wpt_non_functional",
         "pct_functional", "pct_non_functional", 
         "pct_hand_pump", )
head(cluster_vars,10)
```

```{r}
#| eval: false
row.names(cluster_vars) <- cluster_vars$"shapeName"
head(cluster_vars,10)
```

```{r}
#| eval: false
cluster_vars_o <- select(cluster_vars, c(2:6))
head(cluster_vars_o, 10)
```

```{r}
#| eval: false
fun <- cor(cluster_vars_o)
corrplot.mixed(fun,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```
